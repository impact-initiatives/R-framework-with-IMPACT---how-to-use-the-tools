[
  {
    "objectID": "03-composition/03-composition-02-review.html",
    "href": "03-composition/03-composition-02-review.html",
    "title": "02 - Review indicators",
    "section": "",
    "text": "Reviewing indicators will compare 2 indicators together and present the differences. It will not check how the indicator was created nor check for inconsistencies. That mean, to review an indicator, it is necessary to create one and compare them. The functions review_one_variable and review_variables will focus on the latter.\n\nlibrary(impactR4PHU)\nlibrary(dplyr)\n\nmy_data &lt;- impactR4PHU::impactR4PHU_data_template |&gt;  \n  filter(respondent_consent != \"no\") \nmy_data_with_indicators &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\"\n) %&gt;%\n  add_hhs(\n  )\n\n\nFirst, a new dataset can be created for the review.\n\nreview_df &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  ) %&gt;%\n  select(uuid, fsl_fcs_score, fsl_fcs_cat)\n\nThen the dataset to be reviewed and the new dataset can be binded together.\n\nbinded_df &lt;- my_data_with_indicators %&gt;%\n  full_join(review_df, by = \"uuid\")\n\n\n\n\n\n\n\n\nNote\n\n\n\nI would advice to use a full_join rather than a left/right_join. That way if any computation has missing value they will be spotted.\n\n\n\n\n\n\n\nNote\n\n\n\nWith the join_* if the names are the same .x and .y will added to the names.\n\n\n\n\n\n\n\n\nreview_*\n\n\n\n\nreview_* functions will review an object by comparing it to standards or another object and flags differences, e.g.Â reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n\n\nlibrary(addindicators)\n\n\nreview_one_var &lt;- review_variables(binded_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\n\nreview_one_var %&gt;% \n  names()\n\n[1] \"dataset\"      \"review_table\"\n\n\nIt is a list with the dataset and a review table.\n\nreview_one_var$review_table %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nvariable\nreview_check\nreview_comment\n\n\n\n14c3baf8-d4b0-43484c-8d8e8f-a5fd7134982e\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1a8de690-60af-45494a-8b8487-78f45ec16b39\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1d7ca542-5ebf-434e44-949e9a-d3687ef9c145\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1ecfd059-c215-4d4746-94999b-87920feb4a6c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n\n\n\n\nThe review table can be summarised to have a quicker overview.\n\nreview_one_var$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\nTRUE\nSame results\n81\n\n\n\n\n\nTo see how differences are shown, some noise is introduced to the dataset.\n\njittered_df &lt;- binded_df\nset.seed(123)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(124)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(125)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- NA\nset.seed(1236)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- NA\nset.seed(1237)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_score.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_score.x), 5, T)\n\n\nreview_one_variable_jittered &lt;- review_variables(jittered_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\nreview_one_variable_jittered$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\n\nFALSE\nDifferent results\n9\n\n\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nTRUE\nSame results\n62\n\n\n\n\n\n\nThe dataset has new columns to help filtering for further investigation.\n\nreview_one_variable_jittered$dataset[, tail(names(review_one_variable_jittered$dataset), 5)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\nfsl_hhs_cat\nfsl_fcs_score.y\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\nLittle to No\n32.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.0\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n62.5\nAcceptable\nTRUE\nSame results\n\n\nLittle to No\n29.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n40.0\nBorderline\nFALSE\nDifferent results\n\n\n\n\n\n\n\nreview_one_variable_jittered$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_check_fsl_fcs_cat.x, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nFALSE\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nFALSE\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nFALSE\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\nIf there are more than one variable to review, pair-wise vectors can be used.\n\nmy_review &lt;- review_variables(jittered_df,\n  columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\"),\n  columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\")\n)\n\n\nmy_review$review_table %&gt;%\n  group_by(variable, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nvariable\nreview_check\nreview_comment\nn\n\n\n\nfsl_fcs_cat.x\nFALSE\nDifferent results\n9\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nfsl_fcs_cat.x\nTRUE\nSame results\n62\n\n\nfsl_fcs_score.x\nFALSE\nDifferent results\n5\n\n\nfsl_fcs_score.x\nTRUE\nSame results\n76\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_score.x) %&gt;%\n  select(uuid, fsl_fcs_score.x, fsl_fcs_score.y, review_comment_fsl_fcs_score.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_score.x\nfsl_fcs_score.y\nreview_comment_fsl_fcs_score.x\n\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\n22.5\n23.5\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\n40.0\n29.0\nDifferent results\n\n\n5b04c362-1637-4c464d-9f9a97-ed918b7f0a43\n60.5\n12.0\nDifferent results\n\n\n65d0f41e-fb96-424b41-96919a-2de546c7f9a0\n92.5\n19.5\nDifferent results\n\n\nf09a3541-f9a5-4a4644-9c9895-90ea2cfd6548\n42.5\n27.5\nDifferent results",
    "crumbs": [
      "Composition - Add indicators",
      "02 - Review indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-02-review.html#review_variables",
    "href": "03-composition/03-composition-02-review.html#review_variables",
    "title": "02 - Review indicators",
    "section": "",
    "text": "First, a new dataset can be created for the review.\n\nreview_df &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  ) %&gt;%\n  select(uuid, fsl_fcs_score, fsl_fcs_cat)\n\nThen the dataset to be reviewed and the new dataset can be binded together.\n\nbinded_df &lt;- my_data_with_indicators %&gt;%\n  full_join(review_df, by = \"uuid\")\n\n\n\n\n\n\n\n\nNote\n\n\n\nI would advice to use a full_join rather than a left/right_join. That way if any computation has missing value they will be spotted.\n\n\n\n\n\n\n\nNote\n\n\n\nWith the join_* if the names are the same .x and .y will added to the names.\n\n\n\n\n\n\n\n\nreview_*\n\n\n\n\nreview_* functions will review an object by comparing it to standards or another object and flags differences, e.g.Â reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n\n\nlibrary(addindicators)\n\n\nreview_one_var &lt;- review_variables(binded_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\n\nreview_one_var %&gt;% \n  names()\n\n[1] \"dataset\"      \"review_table\"\n\n\nIt is a list with the dataset and a review table.\n\nreview_one_var$review_table %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nvariable\nreview_check\nreview_comment\n\n\n\n14c3baf8-d4b0-43484c-8d8e8f-a5fd7134982e\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1a8de690-60af-45494a-8b8487-78f45ec16b39\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1d7ca542-5ebf-434e44-949e9a-d3687ef9c145\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1ecfd059-c215-4d4746-94999b-87920feb4a6c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n\n\n\n\nThe review table can be summarised to have a quicker overview.\n\nreview_one_var$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\nTRUE\nSame results\n81\n\n\n\n\n\nTo see how differences are shown, some noise is introduced to the dataset.\n\njittered_df &lt;- binded_df\nset.seed(123)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(124)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(125)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- NA\nset.seed(1236)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- NA\nset.seed(1237)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_score.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_score.x), 5, T)\n\n\nreview_one_variable_jittered &lt;- review_variables(jittered_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\nreview_one_variable_jittered$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\n\nFALSE\nDifferent results\n9\n\n\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nTRUE\nSame results\n62\n\n\n\n\n\n\nThe dataset has new columns to help filtering for further investigation.\n\nreview_one_variable_jittered$dataset[, tail(names(review_one_variable_jittered$dataset), 5)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\nfsl_hhs_cat\nfsl_fcs_score.y\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\nLittle to No\n32.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.0\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n62.5\nAcceptable\nTRUE\nSame results\n\n\nLittle to No\n29.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n40.0\nBorderline\nFALSE\nDifferent results\n\n\n\n\n\n\n\nreview_one_variable_jittered$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_check_fsl_fcs_cat.x, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nFALSE\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nFALSE\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nFALSE\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\nIf there are more than one variable to review, pair-wise vectors can be used.\n\nmy_review &lt;- review_variables(jittered_df,\n  columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\"),\n  columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\")\n)\n\n\nmy_review$review_table %&gt;%\n  group_by(variable, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nvariable\nreview_check\nreview_comment\nn\n\n\n\nfsl_fcs_cat.x\nFALSE\nDifferent results\n9\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nfsl_fcs_cat.x\nTRUE\nSame results\n62\n\n\nfsl_fcs_score.x\nFALSE\nDifferent results\n5\n\n\nfsl_fcs_score.x\nTRUE\nSame results\n76\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_score.x) %&gt;%\n  select(uuid, fsl_fcs_score.x, fsl_fcs_score.y, review_comment_fsl_fcs_score.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_score.x\nfsl_fcs_score.y\nreview_comment_fsl_fcs_score.x\n\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\n22.5\n23.5\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\n40.0\n29.0\nDifferent results\n\n\n5b04c362-1637-4c464d-9f9a97-ed918b7f0a43\n60.5\n12.0\nDifferent results\n\n\n65d0f41e-fb96-424b41-96919a-2de546c7f9a0\n92.5\n19.5\nDifferent results\n\n\nf09a3541-f9a5-4a4644-9c9895-90ea2cfd6548\n42.5\n27.5\nDifferent results",
    "crumbs": [
      "Composition - Add indicators",
      "02 - Review indicators"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html",
    "href": "01-cleaning/01-cleaning-01-checks.html",
    "title": "01 - Checks",
    "section": "",
    "text": "The following section will present some introduction about the composition.\n\n\nlibrary(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\n\n\n\n\ncheck_*\n\n\n\n\ncheck_* functions will flag values based on a specific check. It will return them in a log. A *check_** will return a list: the checked dataset, and the log.\ncheck_* functions are used only in the cleaning step.\n\n\n\n\nmy_log1 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\")\n\nIn this example, there are:\n\n\nchecked_dataset: the raw dataset (with extra variables if needed)\n\npotential_outliers: a log of potential outliers\n\n\ntypeof(my_log1)\n\n[1] \"list\"\n\nmy_log1 %&gt;% \n  names()\n\n[1] \"checked_dataset\"    \"potential_outliers\"\n\n\nThe log has at least 4 columns:\n\n\nuuid: the unique identifier\n\nissue: the issue being flagged\n\nquestion: the name of the question\n\nold_value: the value being flagged\n\n\nmy_log1$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutliers are defined as +/- 3 standard deviation from the mean.\nFor log outliers, log(x + 1) is used.\n\n\n\nmy_log2 &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\nmy_log2$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue\n\n\n\n\n\n\nThere is no duplicate. The log is empty.\n\n\n\n\n\n\n\nPipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 check_* functions are piped.\n\n\n\nmy_log3 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\") %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\n\nnames(my_log3)\n\n[1] \"checked_dataset\"    \"potential_outliers\" \"duplicate_log\"     \n\n\n\nmy_log3$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\nmy_log3$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue\n\n\n\n\n\n\n\nThis an example of more checks that exist.\n\nmore_logs &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\") %&gt;% \n  check_soft_duplicates(uuid_column = \"X_uuid\", kobo_survey = my_kobo_survey, sm_separator = \".\") %&gt;%\n  check_outliers(uuid_column = \"X_uuid\") %&gt;%\n  check_value(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#check_outliers",
    "href": "01-cleaning/01-cleaning-01-checks.html#check_outliers",
    "title": "01 - Checks",
    "section": "",
    "text": "my_log1 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\")\n\nIn this example, there are:\n\n\nchecked_dataset: the raw dataset (with extra variables if needed)\n\npotential_outliers: a log of potential outliers\n\n\ntypeof(my_log1)\n\n[1] \"list\"\n\nmy_log1 %&gt;% \n  names()\n\n[1] \"checked_dataset\"    \"potential_outliers\"\n\n\nThe log has at least 4 columns:\n\n\nuuid: the unique identifier\n\nissue: the issue being flagged\n\nquestion: the name of the question\n\nold_value: the value being flagged\n\n\nmy_log1$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutliers are defined as +/- 3 standard deviation from the mean.\nFor log outliers, log(x + 1) is used.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#check_duplicate",
    "href": "01-cleaning/01-cleaning-01-checks.html#check_duplicate",
    "title": "01 - Checks",
    "section": "",
    "text": "my_log2 &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\nmy_log2$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue\n\n\n\n\n\n\nThere is no duplicate. The log is empty.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#pipe-able",
    "href": "01-cleaning/01-cleaning-01-checks.html#pipe-able",
    "title": "01 - Checks",
    "section": "",
    "text": "Pipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 check_* functions are piped.\n\n\n\nmy_log3 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\") %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\n\nnames(my_log3)\n\n[1] \"checked_dataset\"    \"potential_outliers\" \"duplicate_log\"     \n\n\n\nmy_log3$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\nmy_log3$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#more-checks",
    "href": "01-cleaning/01-cleaning-01-checks.html#more-checks",
    "title": "01 - Checks",
    "section": "",
    "text": "This an example of more checks that exist.\n\nmore_logs &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\") %&gt;% \n  check_soft_duplicates(uuid_column = \"X_uuid\", kobo_survey = my_kobo_survey, sm_separator = \".\") %&gt;%\n  check_outliers(uuid_column = \"X_uuid\") %&gt;%\n  check_value(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html",
    "href": "02-cleaning/02-cleaning-04-practice.html",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\nExport the cleaning log you have created previously. The previous log is loaded below.\n\n\nprevious_exercise_log &lt;- readRDS(\"../inputs/03 - exercise - previous_log.RDS\")\n\nprevious_exercise_log %&gt;% names()\n\n[1] \"checked_dataset\"        \"percentage_missing_log\" \"potential_PII\"         \n[4] \"logical_all\"           \n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_combined_log\n\n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_xlsx_cleaning_log\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nprevious_exercise_log %&gt;% \n  create_combined_log() %&gt;%\n  create_xlsx_cleaning_log(output_path = \"../outputs/03 - correction - cleaning_log.xlsx\", \n                           kobo_survey = my_kobo_survey,\n                           kobo_choices = my_kobo_choice,\n                           sm_dropdown_type = \"logical\",\n                           use_dropdown = TRUE)\n\n\n\n\n\n\nCreate the clean data from the raw dataset and the filled cleaning.\n\n\nexercise_filled_log &lt;- readxl::read_excel(\"../inputs/04 - exercise - cleaning_log - filled.xlsx\", sheet = \"cleaning_log\")\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function create_clean_data\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function recreate_parent_column\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_clean_dataset &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                            raw_data_uuid_column = \"X_uuid\",\n                                            cleaning_log = exercise_filled_log, \n                                            cleaning_log_uuid_column = \"uuid\",\n                                            cleaning_log_question_column = \"question\",\n                                            cleaning_log_new_value_column = \"new_value\",\n                                            cleaning_log_change_type_column = \"change_type\")\n\n\nexercise_clean_dataset2 &lt;- recreate_parent_column(exercise_clean_dataset,\n                                                  uuid_column = \"X_uuid\", \n                                                  kobo_survey = my_kobo_survey,\n                                                  kobo_choices = my_kobo_choice,\n                                                  cleaning_log_to_append = exercise_filled_log)\n\n\n\n\n\n\nReview the cleaning below, if there is someone else doing the exercise, you can try to review someoneâs cleaning.\n\n\nexercise3_clean_dataset &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\")\n\nexercise3_cleaning_log &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\", sheet = 2)\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_cleaning\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you separate the cleaning log?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise3_deletion_log &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type == \"remove_survey\")\n\nexercise3_log_no_deletion &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type != \"remove_survey\") %&gt;% \n  filter(!uuid %in% exercise3_deletion_log$uuid)\n\nreview_of_cleaning &lt;- review_cleaning(raw_dataset = my_raw_dataset,\n                                      raw_dataset_uuid_column = \"X_uuid\", \n                                      clean_dataset = exercise3_clean_dataset,\n                                      clean_dataset_uuid_column = \"X_uuid\",\n                                      cleaning_log = exercise3_log_no_deletion, \n                                      cleaning_log_uuid_column = \"uuid\",\n                                      cleaning_log_question_column = \"question\",\n                                      cleaning_log_new_value_column = \"new_value\",\n                                      cleaning_log_change_type_column = \"change_type\", \n                                      cleaning_log_old_value_column = \"old_value\", \n                                      deletion_log = exercise3_deletion_log, \n                                      deletion_log_uuid_column = \"uuid\"\n)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#practice-1",
    "href": "02-cleaning/02-cleaning-04-practice.html#practice-1",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "Export the cleaning log you have created previously. The previous log is loaded below.\n\n\nprevious_exercise_log &lt;- readRDS(\"../inputs/03 - exercise - previous_log.RDS\")\n\nprevious_exercise_log %&gt;% names()\n\n[1] \"checked_dataset\"        \"percentage_missing_log\" \"potential_PII\"         \n[4] \"logical_all\"           \n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_combined_log\n\n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_xlsx_cleaning_log\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nprevious_exercise_log %&gt;% \n  create_combined_log() %&gt;%\n  create_xlsx_cleaning_log(output_path = \"../outputs/03 - correction - cleaning_log.xlsx\", \n                           kobo_survey = my_kobo_survey,\n                           kobo_choices = my_kobo_choice,\n                           sm_dropdown_type = \"logical\",\n                           use_dropdown = TRUE)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#practice-2",
    "href": "02-cleaning/02-cleaning-04-practice.html#practice-2",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "Create the clean data from the raw dataset and the filled cleaning.\n\n\nexercise_filled_log &lt;- readxl::read_excel(\"../inputs/04 - exercise - cleaning_log - filled.xlsx\", sheet = \"cleaning_log\")\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function create_clean_data\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function recreate_parent_column\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_clean_dataset &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                            raw_data_uuid_column = \"X_uuid\",\n                                            cleaning_log = exercise_filled_log, \n                                            cleaning_log_uuid_column = \"uuid\",\n                                            cleaning_log_question_column = \"question\",\n                                            cleaning_log_new_value_column = \"new_value\",\n                                            cleaning_log_change_type_column = \"change_type\")\n\n\nexercise_clean_dataset2 &lt;- recreate_parent_column(exercise_clean_dataset,\n                                                  uuid_column = \"X_uuid\", \n                                                  kobo_survey = my_kobo_survey,\n                                                  kobo_choices = my_kobo_choice,\n                                                  cleaning_log_to_append = exercise_filled_log)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#practice-3",
    "href": "02-cleaning/02-cleaning-04-practice.html#practice-3",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "Review the cleaning below, if there is someone else doing the exercise, you can try to review someoneâs cleaning.\n\n\nexercise3_clean_dataset &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\")\n\nexercise3_cleaning_log &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\", sheet = 2)\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_cleaning\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you separate the cleaning log?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise3_deletion_log &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type == \"remove_survey\")\n\nexercise3_log_no_deletion &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type != \"remove_survey\") %&gt;% \n  filter(!uuid %in% exercise3_deletion_log$uuid)\n\nreview_of_cleaning &lt;- review_cleaning(raw_dataset = my_raw_dataset,\n                                      raw_dataset_uuid_column = \"X_uuid\", \n                                      clean_dataset = exercise3_clean_dataset,\n                                      clean_dataset_uuid_column = \"X_uuid\",\n                                      cleaning_log = exercise3_log_no_deletion, \n                                      cleaning_log_uuid_column = \"uuid\",\n                                      cleaning_log_question_column = \"question\",\n                                      cleaning_log_new_value_column = \"new_value\",\n                                      cleaning_log_change_type_column = \"change_type\", \n                                      cleaning_log_old_value_column = \"old_value\", \n                                      deletion_log = exercise3_deletion_log, \n                                      deletion_log_uuid_column = \"uuid\"\n)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html",
    "title": "01 - Create a cleaning log",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\nThis section continues with the cleaning step.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_combined_log",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_combined_log",
    "title": "01 - Create a cleaning log",
    "section": "create_combined_log",
    "text": "create_combined_log\ncreate_combined_log will combined all the logs from a list into one. It will also add 2 columns that will be used for the cleaning.\n\nnames(more_logs)\n\n[1] \"checked_dataset\"    \"duplicate_log\"      \"soft_duplicate_log\"\n[4] \"potential_outliers\" \"flaged_value\"       \"duration_log\"      \n[7] \"other_log\"          \"logical_all\"       \n\nmy_combined_log &lt;- create_combined_log(more_logs)\n\nList of element to combine- checked_dataset, duplicate_log, soft_duplicate_log, potential_outliers, flaged_value, duration_log, other_log, logical_all\n\ntypeof(my_combined_log)\n\n[1] \"list\"\n\nnames(my_combined_log)\n\n[1] \"checked_dataset\" \"cleaning_log\"   \n\nmy_combined_log$cleaning_log %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nold_value\nquestion\nissue\ncheck_id\ncheck_binding\nchange_type\nnew_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\n86\nage_respondent_r\noutlier (normal distribution)\nNA\nage_respondent_r / b5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\nNA\nNA\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\n84\nage_respondent_r\noutlier (normal distribution)\nNA\nage_respondent_r / 956b5ed0-5a62-41b7-aec3-af93fbc5b494\nNA\nNA\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\n18\nage_respondent_r\noutlier (log distribution)\nNA\nage_respondent_r / 97ad6294-30c6-454e-a0b3-42126415b767\nNA\nNA\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\n18\nage_respondent_r\noutlier (log distribution)\nNA\nage_respondent_r / e005e719-57c4-44a3-ac2f-5d6d1ff68831\nNA\nNA\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\n19\nnum_hh_member\noutlier (normal distribution)\nNA\nnum_hh_member / c9aaa542-118f-4e42-93de-fb0916572541\nNA\nNA\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\n19\nnum_hh_member\noutlier (normal distribution)\nNA\nnum_hh_member / 48e8896b-d1be-4600-8839-2d8b994ebcfb\nNA\nNA\n\n\n\n\n\n\nThe cleaning log contains all the columns from all the logs from more_logs with in addition:\n\ncheck_binding is filled for all rows.\nchange_type (empty)\nnew_value (empty)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#add_info_to_cleaning_log",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#add_info_to_cleaning_log",
    "title": "01 - Create a cleaning log",
    "section": "add_info_to_cleaning_log",
    "text": "add_info_to_cleaning_log\nIf more information from the dataset should be added, the function add_info_to_cleaning_log can help.\n\n\n\n\n\n\nadd_*\n\n\n\n\nadd_* functions will add a variable (column) to the dataset. For example, to add the duration of a survey, to add the food consumption score category, etc.\nadd_* function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nFor example, to check the duration of a survey, there is only the start and end, but not the duration column.\n\n\n\nmy_combined_log &lt;- my_combined_log %&gt;% \n  add_info_to_cleaning_log(dataset_uuid_column = \"X_uuid\", \n                           information_to_add = \"enumerator_num\")\n\nmy_combined_log$cleaning_log %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nold_value\nquestion\nissue\ncheck_id\ncheck_binding\nchange_type\nnew_value\nenumerator_num\n\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nÙØ§ Ø§Ø¹ÙÙ\nwater_supply_other_neighbourhoods_why\nrecode other\nNA\nwater_supply_other_neighbourhoods_why / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nÙØ§ Ø§Ø±Ù Ø¬Ø¯ÙÙ ÙÙ Ø°ÙÙ\nprefer_not_engage_other\nrecode other\nNA\nprefer_not_engage_other / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nØ§ÙØ³ÙØ·Ø§Øª ÙÙØ³Øª ÙÙØªÙØ© Ø¨Ø§ÙØ®Ø¯ÙØ§Øª\ntrust_water_office_why_not\nrecode other\nNA\ntrust_water_office_why_not / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\n247.20\nduration\nDuration is lower or higher than the thresholds\nNA\nduration / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n03183d24-0275-43fe-8976-d076f29de590\nØ¹Ø¯Ù ØªÙÙÙØ± Ø®Ø¯ÙÙ Ø§ÙÙÙØ§Ù ÙÙ Ø§ÙÙÙØ·ÙÙ ÙØ¶Ø¹Ù ÙÙ ØªØ²ÙÙØ¯ Ø®Ø¯ÙÙ ÙØ¹Ø¯Ø¯ Ø³Ø§Ø¹Ø§Øª Ø§ÙÙ ØªØ¬ÙÙØ² ÙÙØ¨ÙÙØª\nwater_supply_other_neighbourhoods_why\nrecode other\nNA\nwater_supply_other_neighbourhoods_why / 03183d24-0275-43fe-8976-d076f29de590\nNA\nNA\n2\n\n\n03183d24-0275-43fe-8976-d076f29de590\n10\npay_water_charges_amount\noutlier (log distribution)\nNA\npay_water_charges_amount / 03183d24-0275-43fe-8976-d076f29de590\nNA\nNA\n2",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_xlsx_cleaning_log",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_xlsx_cleaning_log",
    "title": "01 - Create a cleaning log",
    "section": "create_xlsx_cleaning_log",
    "text": "create_xlsx_cleaning_log\n\ncreate_xlsx_cleaning_log(my_combined_log,\n                         sm_dropdown_type = \"logical\",\n                         output_path =  \"../outputs/01 - example - cleaning-log-no-kobo.xlsx\")\n\ncreate_xlsx_cleaning_log will write an excel file with:\n\nchecked_dataset tab: the checked dataset, with additional columns if any.\ncleaning_log tab: the combined log with the change_type column with a data validation rules.\nreadme tab: change_type values definition.\n\nThere are 4 actions possible:\n\nchange_response: Change the response to new.value\nblank_response: Remove and NA the response\nremove_survey: Delete the survey\nno_action: No action to take.\n\nThis log will have to be filled in with actions to take and new value if needed.\n\ncreate_xlsx_cleaning_log(my_combined_log,\n                         kobo_survey = my_kobo_survey,\n                         kobo_choices = my_kobo_choice,\n                         use_dropdown = T,\n                         sm_dropdown_type = \"logical\",\n                         output_path =  \"../outputs/02 - example - cleaning-log-with-kobo.xlsx\")\n\nIf the KOBO information are provided and the use_dropdown argument is set to TRUE, new_value will have a data validation rule based on the KOBO options.\n\n\n\n\n\n\nNote\n\n\n\nSelect multiple dummy columns (TRUE/FALSE or 1/0) are flagged and used later for the cleaning, not the parent column.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-03-logical-with-lists.html",
    "href": "01-cleaning/01-cleaning-03-logical-with-lists.html",
    "title": "03 - Checks with logical list",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "03 - Checks with logical list"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-03-logical-with-lists.html#check_logical_with_list",
    "href": "01-cleaning/01-cleaning-03-logical-with-lists.html#check_logical_with_list",
    "title": "03 - Checks with logical list",
    "section": "check_logical_with_list",
    "text": "check_logical_with_list\nIn other cases, the check is specific and should be tailored to the dataset, for example, check_logical_with_list. All the logical checks can be recorded in an excel file.\n\nlogical_check_list &lt;- readxl::read_excel(\"../inputs/01 - example - check_list.xlsx\")\nlogical_check_list\n\n\n\n\n\n\n\n\n\n\ncheck_id\ndescription\ncheck_to_perform\ncolumns_to_clean\n\n\n\ncheck_1\nprimary_livelihood is employment but expenses less than 200000\nprimary_livelihood.employment == 1 & tot_expenses &lt; 200000\nprimary_livelihood.employment,\n\n\ntot_expenses\n\n\n\n\n\ncheck_2\nacces water and tank emptied\naccess_water_enough == âtotally_insufficientâ & tank_emptied == âabout_halfâ\naccess_water_enough, tank_emptied\n\n\n\n\n\n\nThe check list has 4 columns:\n\ncheck_id : the name of the check\ndescription: the description of the check\ncheck_to_perform: the check to perform. The format for the check to be performed should take the format based on tidyverse. That format is as if a new indicator is create with a mutate. That new indicator should be a logical (i.e.Â TRUE or FALSE) with TRUE being the value to flag.\ncolumns_to_clean: the list of column names that are used for the logical check.\n\nThis list can then be used with check_logical_with_list.\n\nexample_logic &lt;- my_raw_dataset %&gt;% \n  check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = logical_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\nexample_logic$logical_all %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nquestion\nold_value\nissue\ncheck_id\ncheck_binding\n\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nprimary_livelihood.employment\nTRUE\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\ntot_expenses\n125000\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\n\n\ne9f8b44c-c507-45a1-8d76-66d886437b8f\nprimary_livelihood.employment\nTRUE\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / e9f8b44c-c507-45a1-8d76-66d886437b8f\n\n\ne9f8b44c-c507-45a1-8d76-66d886437b8f\ntot_expenses\n175000\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / e9f8b44c-c507-45a1-8d76-66d886437b8f\n\n\n994a60b8-e640-425c-9774-160651d7af04\nprimary_livelihood.employment\nTRUE\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / 994a60b8-e640-425c-9774-160651d7af04\n\n\n994a60b8-e640-425c-9774-160651d7af04\ntot_expenses\n175000\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / 994a60b8-e640-425c-9774-160651d7af04\n\n\n\n\n\n\nThe log returns :\n\nuuid\nquestion: for all variables in columns_to_clean\n\nold value: for all variables in columns_to_clean\n\nissue\ncheck_id: logical check identifier\ncheck_binding: the combination of the check_id and the uuid.\n\nOne check can be flagged in several rows, in the example above, for each uuid, the primary_livelihood and tot_expenses are flagged.\nFormat for the check_to_perform should take the format based on tidyverse. That format is as if a new indicator is create with a mutate. That new indicator should be a logical (i.e.Â TRUE or FALSE) with TRUE being the value to flag.\n\nmy_raw_dataset %&gt;% \n  dplyr::mutate(xxx =  primary_livelihood.employment == 1 & tot_expenses &lt; 200000) %&gt;% \n  dplyr::select(X_uuid, xxx, primary_livelihood.employment, tot_expenses) %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nX_uuid\nxxx\nprimary_livelihood.employment\ntot_expenses\n\n\n\ndcf2753a-6ea2-40f5-b493-3527931ef96c\nFALSE\nFALSE\n250000\n\n\n8790ce5c-1c35-41a2-b3c0-538f937d5397\nFALSE\nTRUE\n750000\n\n\nbb818e04-9c40-408e-919f-6b40ff1fdbb3\nFALSE\nFALSE\n250000\n\n\n28b90cbb-2cf0-41c5-9ee1-1c719c0d4c02\nFALSE\nTRUE\n600000\n\n\n7f2a0c6a-529b-481f-963f-a96dca2ec034\nFALSE\nTRUE\n500000\n\n\nb4f92064-12ea-4970-b0f5-fd309de1dda3\nFALSE\nFALSE\n650000\n\n\n\n\n\n\nThe checked dataset will be return with extra columns, i.e.Â a logical variable with the name of the check_id.\n\nexample_logic$checked_dataset[1:6,tail(names(example_logic$checked_dataset))]\n\n\n\n\nX_notes\nX_status\nX_submitted_by\nX_index\ncheck_1\ncheck_2\n\n\n\n[]\nsubmitted_via_web\nreach_irq\n1\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n2\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n3\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n4\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n5\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n6\nFALSE\nFALSE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you donât include columns_to_clean the check_logical_with_list function will try to guess the variables. Not guarantee it will read or pick the correct names.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "03 - Checks with logical list"
    ]
  },
  {
    "objectID": "03-composition/03-composition-01-add.html",
    "href": "03-composition/03-composition-01-add.html",
    "title": "01 - Add indicators",
    "section": "",
    "text": "The framework is built around 4 steps: cleaning, composition, analysis, outputs\n\n\nCleaning: any manipulation to go from the raw data to the clean data\n\nComposition: any manipulation before the analysis e.g.Â adding indicators, adding information from loop or main, aok aggregation, etc.\n\nAnalysis: any manipulation regarding only the analysis\n\nOutputs: any manipulation to format the outputs.\n\nThe following section will present some introduction about the composition.\n\n\nlibrary(impactR4PHU)\nlibrary(dplyr)\n\nmy_data &lt;- impactR4PHU::impactR4PHU_data_template |&gt;  \n  filter(respondent_consent != \"no\") \n\n\n\n\n\n\n\nadd_*\n\n\n\n\nadd_* functions will add a variable (column) to the dataset. For example, to add the duration of a survey, to add the food consumption score category, etc.\nadd_* function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nFor example, to check the duration of a survey, there is only the start and end, but not the duration column.\nWith addindicators some intermediate columns can be added if they are used to create the new indicator.\n\n\n\n\nmy_data_with_fcs &lt;- my_data %&gt;% add_fcs(\n  cutoffs = \"normal\"\n)\n\nmy_data_with_fcs[, tail(names(my_data_with_fcs), 10)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfcs_weight_cereal1\nfcs_weight_legume2\nfcs_weight_dairy3\nfcs_weight_meat4\nfcs_weight_veg5\nfcs_weight_fruit6\nfcs_weight_oil7\nfcs_weight_sugar8\nfsl_fcs_score\nfsl_fcs_cat\n\n\n\n6\n6\n8\n8\n1\n2\n0.5\n1.0\n32.5\nBorderline\n\n\n4\n6\n4\n4\n1\n2\n1.0\n1.0\n23.0\nBorderline\n\n\n4\n3\n8\n4\n1\n2\n0.5\n1.0\n23.5\nBorderline\n\n\n4\n9\n24\n16\n0\n3\n3.0\n3.5\n62.5\nAcceptable\n\n\n14\n3\n8\n0\n0\n0\n2.5\n2.0\n29.5\nBorderline\n\n\n4\n12\n8\n0\n5\n6\n2.0\n3.0\n40.0\nAcceptable\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can learn more about food security indicators here.\n\n\n\n\n\n\n\n\nPipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 add_* functions are piped.\n\n\n\nmy_data_with_indicators &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\"\n) %&gt;%\n  add_hhs(\n  )\n\nmy_data_with_indicators[, tail(names(my_data_with_indicators), 14)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfsl_fcs_score\nfsl_fcs_cat\nfsl_hhs_nofoodhh_recoded\nfsl_hhs_nofoodhh_freq_recoded\nfsl_hhs_sleephungry_recoded\nfsl_hhs_sleephungry_freq_recoded\nfsl_hhs_alldaynight_recoded\nfsl_hhs_alldaynight_freq_recoded\nfsl_hhs_comp1\nfsl_hhs_comp2\nfsl_hhs_comp3\nfsl_hhs_score\nfsl_hhs_cat_ipc\nfsl_hhs_cat\n\n\n\n32.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.0\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n62.5\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n29.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n40.0\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No",
    "crumbs": [
      "Composition - Add indicators",
      "01 - Add indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-01-add.html#add_fcs",
    "href": "03-composition/03-composition-01-add.html#add_fcs",
    "title": "01 - Add indicators",
    "section": "",
    "text": "my_data_with_fcs &lt;- my_data %&gt;% add_fcs(\n  cutoffs = \"normal\"\n)\n\nmy_data_with_fcs[, tail(names(my_data_with_fcs), 10)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfcs_weight_cereal1\nfcs_weight_legume2\nfcs_weight_dairy3\nfcs_weight_meat4\nfcs_weight_veg5\nfcs_weight_fruit6\nfcs_weight_oil7\nfcs_weight_sugar8\nfsl_fcs_score\nfsl_fcs_cat\n\n\n\n6\n6\n8\n8\n1\n2\n0.5\n1.0\n32.5\nBorderline\n\n\n4\n6\n4\n4\n1\n2\n1.0\n1.0\n23.0\nBorderline\n\n\n4\n3\n8\n4\n1\n2\n0.5\n1.0\n23.5\nBorderline\n\n\n4\n9\n24\n16\n0\n3\n3.0\n3.5\n62.5\nAcceptable\n\n\n14\n3\n8\n0\n0\n0\n2.5\n2.0\n29.5\nBorderline\n\n\n4\n12\n8\n0\n5\n6\n2.0\n3.0\n40.0\nAcceptable\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can learn more about food security indicators here.",
    "crumbs": [
      "Composition - Add indicators",
      "01 - Add indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-01-add.html#add_hhs",
    "href": "03-composition/03-composition-01-add.html#add_hhs",
    "title": "01 - Add indicators",
    "section": "",
    "text": "Pipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 add_* functions are piped.\n\n\n\nmy_data_with_indicators &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\"\n) %&gt;%\n  add_hhs(\n  )\n\nmy_data_with_indicators[, tail(names(my_data_with_indicators), 14)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfsl_fcs_score\nfsl_fcs_cat\nfsl_hhs_nofoodhh_recoded\nfsl_hhs_nofoodhh_freq_recoded\nfsl_hhs_sleephungry_recoded\nfsl_hhs_sleephungry_freq_recoded\nfsl_hhs_alldaynight_recoded\nfsl_hhs_alldaynight_freq_recoded\nfsl_hhs_comp1\nfsl_hhs_comp2\nfsl_hhs_comp3\nfsl_hhs_score\nfsl_hhs_cat_ipc\nfsl_hhs_cat\n\n\n\n32.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.0\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n62.5\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n29.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n40.0\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No",
    "crumbs": [
      "Composition - Add indicators",
      "01 - Add indicators"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-05-extra.html",
    "href": "02-cleaning/02-cleaning-05-extra.html",
    "title": "05 - Review templates",
    "section": "",
    "text": "Review templates\nThere are some project templates that can be used to review the cleaning. More information on this repository.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "05 - Review templates"
    ]
  },
  {
    "objectID": "00-intro.html",
    "href": "00-intro.html",
    "title": "01 - R framework with IMPACT Initiatives",
    "section": "",
    "text": "IMPACT R framework\n\nThe IMPACT R framework has been developed to meet the requirements of the IMPACT research cycle.  The ecosystem is a modular framework with two dimensions:\n\na horizontal dimension that focuses on the outcome of a given step, and\na vertical dimension that focuses on the content of a given step.\n\nThe framework is built around:\n\n4 steps:\n\nCleaning: any manipulation to go from the raw data to the clean data\nComposition: any manipulation before the analysis e.g.Â adding indicators, adding information from loop or main, aok aggregation, etc.\nAnalysis: any manipulation regarding only the analysis\nOutputs: any manipulation to format the outputs.\n\n4 verbs:\n\nAdd: functions that will add a variable (column) to the dataset.\nCheck: functions that will flag values based on a specific check. It will return them in a log. A check_* will return a list: the checked dataset, and the log. The function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nCreate: functions that will create, transform something, e.g.Â creating a cleaning log with the checks to be filled, create analysis results table, create an output. Outputs from create_* functions outputs can be in different shape, format, etc.\nReview: functions that will review an object by comparing it to standards or another object and flags differences, e.g.Â reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n2 adjectives:\n\nPipe-able: In the framework, functions of the same family should be pipe-able. In the following case, 2 check_* functions are piped.\nIndependent: At any given step, the user can change tool. Each input and each output of a step should follow the same format and definition.\n\n\nThese elements will help to improve cooperation and collaboration between different teams while allowing modularity to adapt to each context and assessment.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "03-composition/03-composition-04-extra.html",
    "href": "03-composition/03-composition-04-extra.html",
    "title": "04 - impactR4PHU and humind",
    "section": "",
    "text": "impactR4PHU and humind\nThe functions about public health checks and indicators are more updated on the impactR4PHU. More information on this repository. The functions about the Multi Sector Needs Index are in humind. More information on this repository.",
    "crumbs": [
      "Composition - Add indicators",
      "04 - impactR4PHU and humind"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-02-add-duration-others.html",
    "href": "01-cleaning/01-cleaning-02-add-duration-others.html",
    "title": "02 - Add, durations and others",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\nmore_logs &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\") %&gt;% \n  check_soft_duplicates(uuid_column = \"X_uuid\", kobo_survey = my_kobo_survey, sm_separator = \".\") %&gt;%\n  check_outliers(uuid_column = \"X_uuid\") %&gt;%\n  check_value(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "02 - Add, durations and others"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-02-add-duration-others.html#add_duration",
    "href": "01-cleaning/01-cleaning-02-add-duration-others.html#add_duration",
    "title": "02 - Add, durations and others",
    "section": "add_duration",
    "text": "add_duration\n\n\n\n\n\n\nadd_*\n\n\n\n\nadd_* functions will add a variable (column) to the dataset. For example, to add the duration of a survey, to add the food consumption score category, etc.\nadd_* function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nFor example, to check the duration of a survey, there is only the start and end, but not the duration column.\n\n\n\nmore_logs$checked_dataset &lt;- more_logs$checked_dataset %&gt;% \n  add_duration(uuid_column = \"X_uuid\", start_column = \"X.U.FEFF.start\", end_column = \"end\")\nmore_logs$checked_dataset[1:6, c(\"start_date\", \"start_time\", \"end_date\", \"end_time\", \"days_diff\", \"duration\")]\n\n\n\n\n\n\n\n\n\n\n\n\nstart_date\nstart_time\nend_date\nend_time\ndays_diff\nduration\n\n\n\n2021-07-05\n658.57 mins\n2021-07-05\n696.68 mins\n0 days\n38.11\n\n\n2021-07-05\n608.90 mins\n2021-07-05\n641.92 mins\n0 days\n33.02\n\n\n2021-07-05\n682.23 mins\n2021-07-05\n726.43 mins\n0 days\n44.20\n\n\n2021-07-04\n1342.98 mins\n2021-07-04\n1380.15 mins\n0 days\n37.17\n\n\n2021-07-04\n1391.62 mins\n2021-07-05\n18.88 mins\n1 days\n67.26\n\n\n2021-07-05\n617.38 mins\n2021-07-05\n756.52 mins\n0 days\n139.14\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe duration is added to the checked_dataset in the list, not in the my_raw_dataset dataframe. The check_* functions are used in a pipe, so it needs the current dataset to be modified.\n\n\n\n\n\n\n\nWarning\n\n\n\nAt the moment, add_duration takes very specific format. It will change in the future to become more robust and using lubridate.\n\n\ncheck_duration can now be used with the previous checks.\n\nmore_logs &lt;- more_logs %&gt;% \n  check_duration(column_to_check = \"duration\", uuid_column = \"X_uuid\")\n\nAs much as possible, check_* functions take default argument or the functions will be able to guess some information, e.g.Â the check_outliers function guesses some numerical values. Some functions need more information.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "02 - Add, durations and others"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-02-add-duration-others.html#othertext-columns",
    "href": "01-cleaning/01-cleaning-02-add-duration-others.html#othertext-columns",
    "title": "02 - Add, durations and others",
    "section": "other/text columns",
    "text": "other/text columns\ncheck_other needs the list of columns to be checked. It currently, it cannot detect the open text question. KOBO tool can be used.\n\nother_columns_to_check &lt;- my_kobo_survey %&gt;% \n  dplyr::filter(type == \"text\") %&gt;% \n  dplyr::filter(name %in% names(my_raw_dataset)) %&gt;%\n  dplyr::pull(name) \n\nmore_logs &lt;- more_logs %&gt;% \n  check_others(uuid_column = \"X_uuid\", columns_to_check = other_columns_to_check)",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "02 - Add, durations and others"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html",
    "title": "03 - Review cleaning",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\nmy_filled_log &lt;- readxl::read_excel(\"../inputs/02 - example - cleaning-log-with-kobo - filled.xlsx\", sheet = 2)\n\nmy_clean_data &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                   raw_data_uuid_column = \"X_uuid\",\n                                   cleaning_log = my_filled_log, \n                                   cleaning_log_uuid_column = \"uuid\",\n                                   cleaning_log_question_column = \"question\",\n                                   cleaning_log_new_value_column = \"new_value\",\n                                   cleaning_log_change_type_column = \"change_type\")\nmy_clean_data2 &lt;- recreate_parent_column(dataset = my_clean_data,\n                                         uuid_column = \"X_uuid\",\n                                         kobo_survey = my_kobo_survey,\n                                         kobo_choices = my_kobo_choice,\n                                         sm_separator = \".\", \n                                         cleaning_log_to_append = my_filled_log)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html#review_others",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html#review_others",
    "title": "03 - Review cleaning",
    "section": "review_others",
    "text": "review_others\nIn the cleaning log, some opentext values are changed to blank. Some open text questions are linked some skip logic, i.e.Â what is X? Other, please specify. In some cases, values some values should be changed.\nIn the example below, the value for water_supply_other_neighbourhoods_why for the uuid 019bc718-c06a-46b8-bba8-c84f6c6efbd5 was changed to NA.\n\nmy_filled_log %&gt;% \n  filter(question == \"water_supply_other_neighbourhoods_why\", \n         change_type == \"blank_response\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nold_value\nquestion\nissue\ncheck_id\ncheck_binding\nchange_type\nnew_value\nenumerator_num\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nÙØ§ Ø§Ø¹ÙÙ\nwater_supply_other_neighbourhoods_why\nrecode other\nNA\nwater_supply_other_neighbourhoods_why / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nblank_response\nNA\n12\n\n\n\n\n\nThe kobo show a skip logic based on water_supply_other_neighbourhoods.\n\nmy_kobo_survey %&gt;% \n  filter(name == \"water_supply_other_neighbourhoods_why\") %&gt;% \n  select(type, name, relevant)\n\n\n\n\n\n\n\n\n\ntype\nname\nrelevant\n\n\ntext\nwater_supply_other_neighbourhoods_why\nselected(\\({water_supply_other_neighbourhoods},'somewhat_worse') or selected(\\){water_supply_other_neighbourhoods},âmuch_worseâ)\n\n\n\n\n\n\nmy_clean_data %&gt;% \n  filter(X_uuid == \"019bc718-c06a-46b8-bba8-c84f6c6efbd5\") %&gt;% \n  select(water_supply_other_neighbourhoods, water_supply_other_neighbourhoods_why   )\n\n\n\n\n\n\n\n\nwater_supply_other_neighbourhoods\nwater_supply_other_neighbourhoods_why\n\n\nsomewhat_worse\nNA\n\n\n\n\n\nShould the value of water_supply_other_neighbourhoods be changed? It depends on the question and skip logic but it important to flag those so a decision can be taken.\n\nreview_other_log &lt;- review_others(dataset = my_clean_data2$data_with_fix_concat,\n                                  uuid_column = \"X_uuid\", \n                                  kobo_survey = my_kobo_survey, \n                                  columns_not_to_check = \"consent_telephone_number\")\n\nWarning in create_logic_for_other(kobo_survey = kobo_survey,\ncompare_with_dataset = TRUE, : The following parent names: well_quality,\nspring_quality, rainwater_quality, surface_quality, why_not_connected were not\nfound in the dataset. The function is ignoring them.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html#review_cleaning",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html#review_cleaning",
    "title": "03 - Review cleaning",
    "section": "review_cleaning",
    "text": "review_cleaning\n\nmy_deletion_log &lt;- my_clean_data2$cleaning_log %&gt;% \n  filter(change_type == \"remove_survey\")\n\nmy_filled_log_no_deletion &lt;- my_clean_data2$cleaning_log %&gt;% \n  filter(change_type != \"remove_survey\") %&gt;% \n  filter(!uuid %in% my_deletion_log$uuid)\n\nreview_of_cleaning &lt;- review_cleaning(raw_dataset = my_raw_dataset,\n                    raw_dataset_uuid_column = \"X_uuid\", \n                    clean_dataset = my_clean_data2$data_with_fix_concat,\n                    clean_dataset_uuid_column = \"X_uuid\",\n                    cleaning_log = my_filled_log_no_deletion, \n                    cleaning_log_uuid_column = \"uuid\",\n                    cleaning_log_question_column = \"question\",\n                    cleaning_log_new_value_column = \"new_value\",\n                    cleaning_log_change_type_column = \"change_type\", \n                    cleaning_log_old_value_column = \"old_value\", \n                    deletion_log = my_deletion_log, \n                    deletion_log_uuid_column = \"uuid\"\n                    )\n\n\nreview_of_cleaning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\ndf.question\ndf.change_type\ndf.new_value\ncl.new_value\ndf.old_value\ncl.old_value\ncomment",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html",
    "title": "02 - Creating a clean dataset",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#review_cleaning_log",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#review_cleaning_log",
    "title": "02 - Creating a clean dataset",
    "section": "review_cleaning_log",
    "text": "review_cleaning_log\nreview_cleaning_log will review the filled cleaning log.\n\nmy_filled_log &lt;- readxl::read_excel(\"../inputs/02 - example - cleaning-log-with-kobo - filled.xlsx\", sheet = 2)\n\ncheck_log_results &lt;- review_cleaning_log(raw_dataset = my_raw_dataset,\n                                        raw_data_uuid_column = \"X_uuid\",\n                                        cleaning_log = my_filled_log, \n                                        cleaning_log_uuid_column = \"uuid\",\n                                        cleaning_log_question_column = \"question\",\n                                        cleaning_log_new_value_column = \"new_value\",\n                                        cleaning_log_change_type_column = \"change_type\",\n                                        change_response_value = \"change_response\")\ncheck_log_results\n\n[1] \"no issues in cleaning log found\"",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#create_clean_data",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#create_clean_data",
    "title": "02 - Creating a clean dataset",
    "section": "create_clean_data",
    "text": "create_clean_data\nTo create the clean dataset, create_clean_data will use the raw dataset and the filled cleaning log.\n\nmy_clean_data &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                   raw_data_uuid_column = \"X_uuid\",\n                                   cleaning_log = my_filled_log, \n                                   cleaning_log_uuid_column = \"uuid\",\n                                   cleaning_log_question_column = \"question\",\n                                   cleaning_log_new_value_column = \"new_value\",\n                                   cleaning_log_change_type_column = \"change_type\")\n\n[1] \"water_supply_other_neighbourhoods_why\"\n[1] \"trust_water_office_why_not\"\n[1] \"pay_water_charges_amount\"\n[1] \"connection_fees_amount\"\n[1] \"connection_fees_amount\"\n[1] \"primary_livelihood.employment\"\n[1] \"primary_livelihood.employment\"\n[1] \"primary_livelihood.employment\"\n[1] \"tank_emptied\"\n[1] \"access_water_enough\"",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#recreate_parent_column",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#recreate_parent_column",
    "title": "02 - Creating a clean dataset",
    "section": "recreate_parent_column",
    "text": "recreate_parent_column\nIn the cleaning log, some select multiple are changed, but only the dummy.\n\nmy_filled_log %&gt;% \n  filter(question == \"primary_livelihood.employment\", \n         change_type == \"change_response\") %&gt;% \n  select(uuid, question, old_value, new_value)\n\n\n\n\n\n\n\n\n\n\nuuid\nquestion\nold_value\nnew_value\n\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nprimary_livelihood.employment\nTRUE\nFALSE\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nprimary_livelihood.employment\nTRUE\nFALSE\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nprimary_livelihood.employment\nTRUE\nFALSE\n\n\n\n\n\n\nThe parent column did not change, in the following example employment still appears in the parent column.\n\nmy_clean_data %&gt;% \n  filter(X_uuid %in% c(\"eb3b9935-fa0b-4d54-8058-3b629f1421ad\", \"eec1f630-15d5-475e-a344-32bba74b32ea\", \"f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\")) %&gt;% \n  select(X_uuid,primary_livelihood, primary_livelihood.employment)\n\n\n\n\n\n\n\n\n\nX_uuid\nprimary_livelihood\nprimary_livelihood.employment\n\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nemployment\nFALSE\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nemployment ngo\nFALSE\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nemployment\nFALSE\n\n\n\n\n\n\nrecreate_parent_column will recode the parent columns based on the dummies.\n\nmy_clean_data2 &lt;- recreate_parent_column(dataset = my_clean_data,\n                                         uuid_column = \"X_uuid\",\n                                         kobo_survey = my_kobo_survey,\n                                         kobo_choices = my_kobo_choice,\n                                         sm_separator = \".\", \n                                         cleaning_log_to_append = my_filled_log)\n\nThe parent are corrected, employment does not appear in the parent column.\n\nmy_clean_data2$data_with_fix_concat %&gt;% \n  filter(X_uuid %in% c(\"eb3b9935-fa0b-4d54-8058-3b629f1421ad\", \"eec1f630-15d5-475e-a344-32bba74b32ea\", \"f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\")) %&gt;% \n  select(X_uuid,primary_livelihood, primary_livelihood.employment)\n\n\n\n\n\n\n\n\n\nX_uuid\nprimary_livelihood\nprimary_livelihood.employment\n\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nNA\nFALSE\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nngo\nFALSE\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nNA\nFALSE\n\n\n\n\n\n\nThe changes were added to the cleaning log.\n\nmy_clean_data2$cleaning_log %&gt;% \n  filter(question == \"primary_livelihood\", \n         uuid %in% c(\"eb3b9935-fa0b-4d54-8058-3b629f1421ad\", \"eec1f630-15d5-475e-a344-32bba74b32ea\", \"f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\")) %&gt;% \n  select(uuid, question, old_value, new_value)\n\n\n\n\n\n\n\n\n\n\nuuid\nquestion\nold_value\nnew_value\n\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nprimary_livelihood\nemployment ngo\nngo\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nprimary_livelihood\nemployment\nNA\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nprimary_livelihood\nemployment\nNA",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html",
    "href": "01-cleaning/01-cleaning-04-practice.html",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Try the following with a dataset:\n\nPerform a check to spot personal identifiable information\n\n\nlibrary(cleaningtools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_pii\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")\n\n\n\n\n\n\nPerform a check that will look at the percentages of missing value per observation and that will spot any observation that is different.\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try to add a new column with add_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_data_with_missing &lt;- my_raw_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\n  \nmy_data_with_missing %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")\n\nOr if using a log already\n\na_log &lt;- my_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")\na_log$checked_dataset &lt;- a_log$checked_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\na_log %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")\n\n\n\n\n\n\nFill the excel checklist to do the following checks:\n\nhousehold number (variable: num_hh_member) is above 8.\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and the household always treat the drinking water (variable: treat_drink_water, value: always_treat).\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and one of the main reason for the the household to not meet its water needs is the water pressure (variable: access_water_enough_why_not, value: water_pressure, this is a select multiple)\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\ntype\n\n\n\nnum_hh_member\nHow many members are there in your household (including you)?\ninteger\n\n\nwater_source_drinking\nWhat is the main source of water used by your household for drinking?\nselect_one water_sources\n\n\ntreat_drink_water\nDoes your household treat this water in any way to make it safer to drink?\nselect_one treat\n\n\naccess_water_enough_why_not\nWhat are the main reasons your household is not able to meet its water needs?\nselect_multiple barriers_water_needs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\nlist_name\n\n\n\nbottled\nBottled or sachet water\nwater_sources\n\n\nalways_treat\nYes, always treat it before drinking\ntreat\n\n\nwater_pressure\nWater pressure is not high enough/pumps required\nbarriers_water_needs\n\n\n\n\n\n\n\nexercise_check_list &lt;- readxl::read_excel(\"../inputs/01 - example - check_list.xlsx\")\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = exercise_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_check_list &lt;- data.frame(check_id = c(\"check_household number\", \"check_water_treatment\", \"check_3\"),\n                            description = c(\"num_hh_member is big\",\"using bottled water and always treat\",\"using bottled water and main reason is water pressure\"),\n                            check_to_perform = c(\"num_hh_member &gt; 8\",\"water_source_drinking == \\\"bottled\\\" & treat_drink_water == \\\"always_treat\\\"\",\"water_source_drinking == \\\"bottled\\\" & access_water_enough_why_not.water_pressure == TRUE\"),\n                            columns_to_clean = c(\"num_hh_member\",\"water_source_drinking, treat_drink_water\",\"water_source_drinking, access_water_enough_why_not.water_pressure\"))\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = my_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\n\n\n\n\nTry to add duration with audit files.\n\n\n\n\n\n\n\nExpand to get a tip\n\n\n\n\n\nTry create_audit_list() and add_duration_from_audit()",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#practice-1",
    "href": "01-cleaning/01-cleaning-04-practice.html#practice-1",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Try the following with a dataset:\n\nPerform a check to spot personal identifiable information\n\n\nlibrary(cleaningtools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_pii\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#practice-2",
    "href": "01-cleaning/01-cleaning-04-practice.html#practice-2",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Perform a check that will look at the percentages of missing value per observation and that will spot any observation that is different.\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try to add a new column with add_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_data_with_missing &lt;- my_raw_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\n  \nmy_data_with_missing %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")\n\nOr if using a log already\n\na_log &lt;- my_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")\na_log$checked_dataset &lt;- a_log$checked_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\na_log %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#practice-3",
    "href": "01-cleaning/01-cleaning-04-practice.html#practice-3",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Fill the excel checklist to do the following checks:\n\nhousehold number (variable: num_hh_member) is above 8.\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and the household always treat the drinking water (variable: treat_drink_water, value: always_treat).\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and one of the main reason for the the household to not meet its water needs is the water pressure (variable: access_water_enough_why_not, value: water_pressure, this is a select multiple)\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\ntype\n\n\n\nnum_hh_member\nHow many members are there in your household (including you)?\ninteger\n\n\nwater_source_drinking\nWhat is the main source of water used by your household for drinking?\nselect_one water_sources\n\n\ntreat_drink_water\nDoes your household treat this water in any way to make it safer to drink?\nselect_one treat\n\n\naccess_water_enough_why_not\nWhat are the main reasons your household is not able to meet its water needs?\nselect_multiple barriers_water_needs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\nlist_name\n\n\n\nbottled\nBottled or sachet water\nwater_sources\n\n\nalways_treat\nYes, always treat it before drinking\ntreat\n\n\nwater_pressure\nWater pressure is not high enough/pumps required\nbarriers_water_needs\n\n\n\n\n\n\n\nexercise_check_list &lt;- readxl::read_excel(\"../inputs/01 - example - check_list.xlsx\")\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = exercise_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_check_list &lt;- data.frame(check_id = c(\"check_household number\", \"check_water_treatment\", \"check_3\"),\n                            description = c(\"num_hh_member is big\",\"using bottled water and always treat\",\"using bottled water and main reason is water pressure\"),\n                            check_to_perform = c(\"num_hh_member &gt; 8\",\"water_source_drinking == \\\"bottled\\\" & treat_drink_water == \\\"always_treat\\\"\",\"water_source_drinking == \\\"bottled\\\" & access_water_enough_why_not.water_pressure == TRUE\"),\n                            columns_to_clean = c(\"num_hh_member\",\"water_source_drinking, treat_drink_water\",\"water_source_drinking, access_water_enough_why_not.water_pressure\"))\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = my_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#extra",
    "href": "01-cleaning/01-cleaning-04-practice.html#extra",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Try to add duration with audit files.\n\n\n\n\n\n\n\nExpand to get a tip\n\n\n\n\n\nTry create_audit_list() and add_duration_from_audit()",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html",
    "href": "03-composition/03-composition-03-practice.html",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "library(impactR4PHU)\nlibrary(addindicators)\nlibrary(dplyr)\n\n\n\nAdd the food consumption matrix score to the dataset. The food consumption matrix score is a food security indicator that uses the food consumption score, household hunger score and the reduced coping strategy index.\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::english\ntype\n\n\n\nrCSILessQlty\nDuring the last 7 days, were there days (and, if so, how many) when your household had to rely on less preferred and less expensive food to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIBorrow\nDuring the last 7 days, were there days (and, if so, how many) when your household had to borrow food or rely on help from a relative or friend to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealSize\nDuring the last 7 days, were there days (and, if so, how many) when your household had to limit portion size of meals at meal times to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealAdult\nDuring the last 7 days, were there days (and, if so, how many) when your household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealNb\nDuring the last 7 days, were there days (and, if so, how many) when your household had to reduce number of meals eaten in a day to cope with a lack of food or money to buy it?\ninteger\n\n\n\n\n\n\n\nlibrary(impactR4PHU)\nlibrary(addindicators)\nlibrary(dplyr)\n\n\nexercise_data &lt;- addindicators::addindicators_MSNA_template_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  )\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function add_fcm_phase?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nThe food consumption matrix needs 3 indicators, FCS, rCSI, HHS.\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHave you used the correct HHS category variable?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_answer &lt;- exercise_data %&gt;% \n  add_rcsi(\n    fsl_rcsi_lessquality = \"rCSILessQlty\",\n    fsl_rcsi_borrow = \"rCSIBorrow\",\n    fsl_rcsi_mealsize = \"rCSIMealSize\",\n    fsl_rcsi_mealadult = \"rCSIMealAdult\",\n    fsl_rcsi_mealnb = \"rCSIMealNb\"\n  ) %&gt;%\n  add_fcm_phase(\n  )\n\n\n\n\n\n\n\nYou receive a dataset, you need to review the following four indicators.\n\nFood Consumption Score: fsl_fcs_score, fsl_fcs_cat\n\nHousehold Hunger Score: hhs_score, hhs_cat\n\n\n\n\nDonât forget to write the review.\n\ndataset_to_review &lt;- read.csv(\"../inputs/06 - exercise - dataset_to_review.csv\")\n\ndataset_without_indicators &lt;- addindicators::addindicators_MSNA_template_data\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_variables\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was the FSC created?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was coded the category for the HHS? Names in the dataset are: âhhs_catâ, âhhs_scoreâ Names created with add_hhs are: âfsl_hhs_catâ, âfsl_hhs_scoreâ\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_review &lt;- dataset_without_indicators %&gt;% \n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  ) %&gt;% \n  select(uuid, fsl_fcs_cat, fsl_fcs_score, fsl_hhs_cat, fsl_hhs_score)\ndataset_to_review &lt;- full_join(dataset_to_review, my_review, by = \"uuid\")\n\nreview &lt;- dataset_to_review %&gt;% \n  review_variables(columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\", \"hhs_cat\", \"hhs_score\"),\n                   columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\", \"fsl_hhs_cat\", \"fsl_hhs_score\"))\n\nreview$review_table %&gt;% \n  group_by(variable,review_check,review_comment) %&gt;% \n  tally()\n\n\nThere are 10 fcs categories that are different.\nThere are 100 HHS categories that are different\n\n\nreview$dataset %&gt;% \n  filter(!review_check_fsl_fcs_cat.x) %&gt;% \n  select(uuid, review_comment_fsl_fcs_cat.x, fsl_fcs_score.x, fsl_fcs_cat.x, fsl_fcs_cat.y)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nreview_comment_fsl_fcs_cat.x\nfsl_fcs_score.x\nfsl_fcs_cat.x\nfsl_fcs_cat.y\n\n\n\nf1b9ec67-20db-47404d-a3ada0-1a37e5c49d02\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\ne21a34f5-1a46-42404b-b7b6be-7bc9286d0f13\nDifferent results\n36.0\nBorderline\nAcceptable\n\n\n42dc8573-e2d0-43484b-aaada2-c37ef865d041\nDifferent results\n39.0\nBorderline\nAcceptable\n\n\nfcd69a08-498f-4c4b47-989799-743cbe5fd960\nDifferent results\n36.5\nBorderline\nAcceptable\n\n\n4d1cae02-49e0-484c4e-8f8d8c-a97dec246310\nDifferent results\n41.0\nBorderline\nAcceptable\n\n\na8319ceb-857c-434142-b9b8bc-7905684fc1d3\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\n6d1acb45-cfb6-4b4441-87888f-e2a4756d30f9\nDifferent results\n38.0\nBorderline\nAcceptable\n\n\n0dea8527-2ab9-4e4844-88868e-8379e514ca2b\nDifferent results\n40.0\nBorderline\nAcceptable\n\n\n7e94afc5-af0b-4a4c46-bebcb7-9f60d1e53a47\nDifferent results\n37.0\nBorderline\nAcceptable\n\n\nb719ef08-bdf5-474240-858d8a-a12bc65d349e\nDifferent results\n41.5\nBorderline\nAcceptable\n\n\n\n\n\n\n\nFood Consumption Score have different categories, what threshold were used to compute the FCS? Maybe 28-42?\n\n\nreview$dataset %&gt;% \n  filter(!review_check_hhs_cat) %&gt;% \n  select(hhs_cat, fsl_hhs_cat) %&gt;% \n  table(useNA = \"ifany\")\n\n              fsl_hhs_cat\nhhs_cat        Little to No Moderate Severe\n  moderate                0       29      0\n  no_or_little           58        0      0\n  severe                  0        0     13\n\n\n\nHHS is fine. Labeling is different",
    "crumbs": [
      "Composition - Add indicators",
      "03 - Practice (3)"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html#practice-1",
    "href": "03-composition/03-composition-03-practice.html#practice-1",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "Add the food consumption matrix score to the dataset. The food consumption matrix score is a food security indicator that uses the food consumption score, household hunger score and the reduced coping strategy index.\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::english\ntype\n\n\n\nrCSILessQlty\nDuring the last 7 days, were there days (and, if so, how many) when your household had to rely on less preferred and less expensive food to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIBorrow\nDuring the last 7 days, were there days (and, if so, how many) when your household had to borrow food or rely on help from a relative or friend to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealSize\nDuring the last 7 days, were there days (and, if so, how many) when your household had to limit portion size of meals at meal times to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealAdult\nDuring the last 7 days, were there days (and, if so, how many) when your household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealNb\nDuring the last 7 days, were there days (and, if so, how many) when your household had to reduce number of meals eaten in a day to cope with a lack of food or money to buy it?\ninteger\n\n\n\n\n\n\n\nlibrary(impactR4PHU)\nlibrary(addindicators)\nlibrary(dplyr)\n\n\nexercise_data &lt;- addindicators::addindicators_MSNA_template_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  )\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function add_fcm_phase?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nThe food consumption matrix needs 3 indicators, FCS, rCSI, HHS.\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHave you used the correct HHS category variable?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_answer &lt;- exercise_data %&gt;% \n  add_rcsi(\n    fsl_rcsi_lessquality = \"rCSILessQlty\",\n    fsl_rcsi_borrow = \"rCSIBorrow\",\n    fsl_rcsi_mealsize = \"rCSIMealSize\",\n    fsl_rcsi_mealadult = \"rCSIMealAdult\",\n    fsl_rcsi_mealnb = \"rCSIMealNb\"\n  ) %&gt;%\n  add_fcm_phase(\n  )",
    "crumbs": [
      "Composition - Add indicators",
      "03 - Practice (3)"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html#practice-2",
    "href": "03-composition/03-composition-03-practice.html#practice-2",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "You receive a dataset, you need to review the following four indicators.\n\nFood Consumption Score: fsl_fcs_score, fsl_fcs_cat\n\nHousehold Hunger Score: hhs_score, hhs_cat\n\n\n\n\nDonât forget to write the review.\n\ndataset_to_review &lt;- read.csv(\"../inputs/06 - exercise - dataset_to_review.csv\")\n\ndataset_without_indicators &lt;- addindicators::addindicators_MSNA_template_data\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_variables\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was the FSC created?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was coded the category for the HHS? Names in the dataset are: âhhs_catâ, âhhs_scoreâ Names created with add_hhs are: âfsl_hhs_catâ, âfsl_hhs_scoreâ\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_review &lt;- dataset_without_indicators %&gt;% \n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  ) %&gt;% \n  select(uuid, fsl_fcs_cat, fsl_fcs_score, fsl_hhs_cat, fsl_hhs_score)\ndataset_to_review &lt;- full_join(dataset_to_review, my_review, by = \"uuid\")\n\nreview &lt;- dataset_to_review %&gt;% \n  review_variables(columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\", \"hhs_cat\", \"hhs_score\"),\n                   columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\", \"fsl_hhs_cat\", \"fsl_hhs_score\"))\n\nreview$review_table %&gt;% \n  group_by(variable,review_check,review_comment) %&gt;% \n  tally()\n\n\nThere are 10 fcs categories that are different.\nThere are 100 HHS categories that are different\n\n\nreview$dataset %&gt;% \n  filter(!review_check_fsl_fcs_cat.x) %&gt;% \n  select(uuid, review_comment_fsl_fcs_cat.x, fsl_fcs_score.x, fsl_fcs_cat.x, fsl_fcs_cat.y)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nreview_comment_fsl_fcs_cat.x\nfsl_fcs_score.x\nfsl_fcs_cat.x\nfsl_fcs_cat.y\n\n\n\nf1b9ec67-20db-47404d-a3ada0-1a37e5c49d02\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\ne21a34f5-1a46-42404b-b7b6be-7bc9286d0f13\nDifferent results\n36.0\nBorderline\nAcceptable\n\n\n42dc8573-e2d0-43484b-aaada2-c37ef865d041\nDifferent results\n39.0\nBorderline\nAcceptable\n\n\nfcd69a08-498f-4c4b47-989799-743cbe5fd960\nDifferent results\n36.5\nBorderline\nAcceptable\n\n\n4d1cae02-49e0-484c4e-8f8d8c-a97dec246310\nDifferent results\n41.0\nBorderline\nAcceptable\n\n\na8319ceb-857c-434142-b9b8bc-7905684fc1d3\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\n6d1acb45-cfb6-4b4441-87888f-e2a4756d30f9\nDifferent results\n38.0\nBorderline\nAcceptable\n\n\n0dea8527-2ab9-4e4844-88868e-8379e514ca2b\nDifferent results\n40.0\nBorderline\nAcceptable\n\n\n7e94afc5-af0b-4a4c46-bebcb7-9f60d1e53a47\nDifferent results\n37.0\nBorderline\nAcceptable\n\n\nb719ef08-bdf5-474240-858d8a-a12bc65d349e\nDifferent results\n41.5\nBorderline\nAcceptable\n\n\n\n\n\n\n\nFood Consumption Score have different categories, what threshold were used to compute the FCS? Maybe 28-42?\n\n\nreview$dataset %&gt;% \n  filter(!review_check_hhs_cat) %&gt;% \n  select(hhs_cat, fsl_hhs_cat) %&gt;% \n  table(useNA = \"ifany\")\n\n              fsl_hhs_cat\nhhs_cat        Little to No Moderate Severe\n  moderate                0       29      0\n  no_or_little           58        0      0\n  severe                  0        0     13\n\n\n\nHHS is fine. Labeling is different",
    "crumbs": [
      "Composition - Add indicators",
      "03 - Practice (3)"
    ]
  }
]