[
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html",
    "title": "02 - Creating a clean dataset",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#review_cleaning_log",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#review_cleaning_log",
    "title": "02 - Creating a clean dataset",
    "section": "review_cleaning_log",
    "text": "review_cleaning_log\nreview_cleaning_log will review the filled cleaning log.\n\nmy_filled_log &lt;- readxl::read_excel(\"../inputs/02 - example - cleaning-log-with-kobo - filled.xlsx\", sheet = 2)\n\ncheck_log_results &lt;- review_cleaning_log(raw_dataset = my_raw_dataset,\n                                        raw_data_uuid_column = \"X_uuid\",\n                                        cleaning_log = my_filled_log, \n                                        cleaning_log_uuid_column = \"uuid\",\n                                        cleaning_log_question_column = \"question\",\n                                        cleaning_log_new_value_column = \"new_value\",\n                                        cleaning_log_change_type_column = \"change_type\",\n                                        change_response_value = \"change_response\")\ncheck_log_results\n\n[1] \"no issues in cleaning log found\"",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#create_clean_data",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#create_clean_data",
    "title": "02 - Creating a clean dataset",
    "section": "create_clean_data",
    "text": "create_clean_data\nTo create the clean dataset, create_clean_data will use the raw dataset and the filled cleaning log.\n\nmy_clean_data &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                   raw_data_uuid_column = \"X_uuid\",\n                                   cleaning_log = my_filled_log, \n                                   cleaning_log_uuid_column = \"uuid\",\n                                   cleaning_log_question_column = \"question\",\n                                   cleaning_log_new_value_column = \"new_value\",\n                                   cleaning_log_change_type_column = \"change_type\")\n\n[1] \"water_supply_other_neighbourhoods_why\"\n[1] \"trust_water_office_why_not\"\n[1] \"pay_water_charges_amount\"\n[1] \"connection_fees_amount\"\n[1] \"connection_fees_amount\"\n[1] \"primary_livelihood.employment\"\n[1] \"primary_livelihood.employment\"\n[1] \"primary_livelihood.employment\"\n[1] \"tank_emptied\"\n[1] \"access_water_enough\"",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#recreate_parent_column",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#recreate_parent_column",
    "title": "02 - Creating a clean dataset",
    "section": "recreate_parent_column",
    "text": "recreate_parent_column\nIn the cleaning log, some select multiple are changed, but only the dummy.\n\nmy_filled_log %&gt;% \n  filter(question == \"primary_livelihood.employment\", \n         change_type == \"change_response\") %&gt;% \n  select(uuid, question, old_value, new_value)\n\n\n\n\n\n\n\n\n\n\nuuid\nquestion\nold_value\nnew_value\n\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nprimary_livelihood.employment\nTRUE\nFALSE\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nprimary_livelihood.employment\nTRUE\nFALSE\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nprimary_livelihood.employment\nTRUE\nFALSE\n\n\n\n\n\n\nThe parent column did not change, in the following example employment still appears in the parent column.\n\nmy_clean_data %&gt;% \n  filter(X_uuid %in% c(\"eb3b9935-fa0b-4d54-8058-3b629f1421ad\", \"eec1f630-15d5-475e-a344-32bba74b32ea\", \"f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\")) %&gt;% \n  select(X_uuid,primary_livelihood, primary_livelihood.employment)\n\n\n\n\n\n\n\n\n\nX_uuid\nprimary_livelihood\nprimary_livelihood.employment\n\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nemployment\nFALSE\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nemployment ngo\nFALSE\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nemployment\nFALSE\n\n\n\n\n\n\nrecreate_parent_column will recode the parent columns based on the dummies.\n\nmy_clean_data2 &lt;- recreate_parent_column(dataset = my_clean_data,\n                                         uuid_column = \"X_uuid\",\n                                         kobo_survey = my_kobo_survey,\n                                         kobo_choices = my_kobo_choice,\n                                         sm_separator = \".\", \n                                         cleaning_log_to_append = my_filled_log)\n\nThe parent are corrected, employment does not appear in the parent column.\n\nmy_clean_data2$data_with_fix_concat %&gt;% \n  filter(X_uuid %in% c(\"eb3b9935-fa0b-4d54-8058-3b629f1421ad\", \"eec1f630-15d5-475e-a344-32bba74b32ea\", \"f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\")) %&gt;% \n  select(X_uuid,primary_livelihood, primary_livelihood.employment)\n\n\n\n\n\n\n\n\n\nX_uuid\nprimary_livelihood\nprimary_livelihood.employment\n\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nNA\nFALSE\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nngo\nFALSE\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nNA\nFALSE\n\n\n\n\n\n\nThe changes were added to the cleaning log.\n\nmy_clean_data2$cleaning_log %&gt;% \n  filter(question == \"primary_livelihood\", \n         uuid %in% c(\"eb3b9935-fa0b-4d54-8058-3b629f1421ad\", \"eec1f630-15d5-475e-a344-32bba74b32ea\", \"f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\")) %&gt;% \n  select(uuid, question, old_value, new_value)\n\n\n\n\n\n\n\n\n\n\nuuid\nquestion\nold_value\nnew_value\n\n\n\neb3b9935-fa0b-4d54-8058-3b629f1421ad\nprimary_livelihood\nemployment ngo\nngo\n\n\neec1f630-15d5-475e-a344-32bba74b32ea\nprimary_livelihood\nemployment\nNA\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nprimary_livelihood\nemployment\nNA",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-02-create-clean-dataset.html#downloads",
    "href": "02-cleaning/02-cleaning-02-create-clean-dataset.html#downloads",
    "title": "02 - Creating a clean dataset",
    "section": "Downloads",
    "text": "Downloads\n\n02 - example - cleaning-log-with-kobo - filled",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "02 - Creating a clean dataset"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-05-extra.html",
    "href": "02-cleaning/02-cleaning-05-extra.html",
    "title": "05 - Review templates",
    "section": "",
    "text": "Review templates\nThere are some project templates that can be used to review the cleaning. More information on this repository.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "05 - Review templates"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html",
    "title": "03 - Review cleaning",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\nmy_filled_log &lt;- readxl::read_excel(\"../inputs/02 - example - cleaning-log-with-kobo - filled.xlsx\", sheet = 2)\n\nmy_clean_data &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                   raw_data_uuid_column = \"X_uuid\",\n                                   cleaning_log = my_filled_log, \n                                   cleaning_log_uuid_column = \"uuid\",\n                                   cleaning_log_question_column = \"question\",\n                                   cleaning_log_new_value_column = \"new_value\",\n                                   cleaning_log_change_type_column = \"change_type\")\nmy_clean_data2 &lt;- recreate_parent_column(dataset = my_clean_data,\n                                         uuid_column = \"X_uuid\",\n                                         kobo_survey = my_kobo_survey,\n                                         kobo_choices = my_kobo_choice,\n                                         sm_separator = \".\", \n                                         cleaning_log_to_append = my_filled_log)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html#review_others",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html#review_others",
    "title": "03 - Review cleaning",
    "section": "review_others",
    "text": "review_others\nIn the cleaning log, some opentext values are changed to blank. Some open text questions are linked some skip logic, i.e. what is X? Other, please specify. In some cases, values some values should be changed.\nIn the example below, the value for water_supply_other_neighbourhoods_why for the uuid 019bc718-c06a-46b8-bba8-c84f6c6efbd5 was changed to NA.\n\nmy_filled_log %&gt;% \n  filter(question == \"water_supply_other_neighbourhoods_why\", \n         change_type == \"blank_response\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nold_value\nquestion\nissue\ncheck_id\ncheck_binding\nchange_type\nnew_value\nenumerator_num\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nلا اعلم\nwater_supply_other_neighbourhoods_why\nrecode other\nNA\nwater_supply_other_neighbourhoods_why / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nblank_response\nNA\n12\n\n\n\n\n\nThe kobo show a skip logic based on water_supply_other_neighbourhoods.\n\nmy_kobo_survey %&gt;% \n  filter(name == \"water_supply_other_neighbourhoods_why\") %&gt;% \n  select(type, name, relevant)\n\n\n\n\n\n\n\n\n\ntype\nname\nrelevant\n\n\ntext\nwater_supply_other_neighbourhoods_why\nselected(\\({water_supply_other_neighbourhoods},'somewhat_worse') or selected(\\){water_supply_other_neighbourhoods},‘much_worse’)\n\n\n\n\n\n\nmy_clean_data %&gt;% \n  filter(X_uuid == \"019bc718-c06a-46b8-bba8-c84f6c6efbd5\") %&gt;% \n  select(water_supply_other_neighbourhoods, water_supply_other_neighbourhoods_why   )\n\n\n\n\n\n\n\n\nwater_supply_other_neighbourhoods\nwater_supply_other_neighbourhoods_why\n\n\nsomewhat_worse\nNA\n\n\n\n\n\nShould the value of water_supply_other_neighbourhoods be changed? It depends on the question and skip logic but it important to flag those so a decision can be taken.\n\nreview_other_log &lt;- review_others(dataset = my_clean_data2$data_with_fix_concat,\n                                  uuid_column = \"X_uuid\", \n                                  kobo_survey = my_kobo_survey, \n                                  columns_not_to_check = \"consent_telephone_number\")\n\nWarning in create_logic_for_other(kobo_survey = kobo_survey,\ncompare_with_dataset = TRUE, : The following parent names: well_quality,\nspring_quality, rainwater_quality, surface_quality, why_not_connected were not\nfound in the dataset. The function is ignoring them.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html#review_cleaning",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html#review_cleaning",
    "title": "03 - Review cleaning",
    "section": "review_cleaning",
    "text": "review_cleaning\n\nmy_deletion_log &lt;- my_clean_data2$cleaning_log %&gt;% \n  filter(change_type == \"remove_survey\")\n\nmy_filled_log_no_deletion &lt;- my_clean_data2$cleaning_log %&gt;% \n  filter(change_type != \"remove_survey\") %&gt;% \n  filter(!uuid %in% my_deletion_log$uuid)\n\nreview_of_cleaning &lt;- review_cleaning(raw_dataset = my_raw_dataset,\n                    raw_dataset_uuid_column = \"X_uuid\", \n                    clean_dataset = my_clean_data2$data_with_fix_concat,\n                    clean_dataset_uuid_column = \"X_uuid\",\n                    cleaning_log = my_filled_log_no_deletion, \n                    cleaning_log_uuid_column = \"uuid\",\n                    cleaning_log_question_column = \"question\",\n                    cleaning_log_new_value_column = \"new_value\",\n                    cleaning_log_change_type_column = \"change_type\", \n                    cleaning_log_old_value_column = \"old_value\", \n                    deletion_log = my_deletion_log, \n                    deletion_log_uuid_column = \"uuid\"\n                    )\n\n\nreview_of_cleaning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\ndf.question\ndf.change_type\ndf.new_value\ncl.new_value\ndf.old_value\ncl.old_value\ncomment",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-03-review-cleaning.html#downloads",
    "href": "02-cleaning/02-cleaning-03-review-cleaning.html#downloads",
    "title": "03 - Review cleaning",
    "section": "Downloads",
    "text": "Downloads\n\n02 - example - cleaning-log-with-kobo - filled",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "03 - Review cleaning"
    ]
  },
  {
    "objectID": "04-analysis/04-analysis-02-practice.html",
    "href": "04-analysis/04-analysis-02-practice.html",
    "title": "02 - Practice (4)",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nexercise_data &lt;- analysistools_MSNA_template_data\n\nonly_nas &lt;- exercise_data %&gt;%\n  summarise(across(.cols = everything(), .fns = function(x) {\n    sum(is.na(x)) == nrow(exercise_data)\n  })) %&gt;%\n  do.call(c, .)\n\nexercise_data_shorter &lt;- exercise_data[, !only_nas] %&gt;%\n  select(!grep(\"other\", names(exercise_data), value = T))\n\nexercise_data_shorter &lt;- exercise_data_shorter[,1:30]\n\nWith the dataset exercise_data, please do the following:\n\nCreate a results table at the level respondent_gender. Keep the strata at admin1\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument group_var in create_analysis ?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_exercise_design &lt;- srvyr::as_survey_design(exercise_data_shorter, strata = \"admin1\") \n\nmy_answer_analysis &lt;- create_analysis(my_exercise_design, group_var = \"respondent_gender\", sm_separator = \"/\")\n\n\n\n\n\n\nThe analysis should be weighted, this is the sampling frame. Re-do the analysis at the overall level.\n\n\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\nsampling_frame\n\n\n\n\nstrata\npopulation\n\n\n\nadmin1a\n1e+05\n\n\nadmin1b\n2e+05\n\n\nadmin1c\n3e+05\n\n\n\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function add_weights ?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you modify your design object?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_data_shorter_weigthed &lt;- exercise_data_shorter %&gt;% \n  add_weights(sample_data = sampling_frame, strata_column_dataset = \"admin1\", strata_column_sample = \"strata\", population_column = \"population\")\n\nmy_exercise_design_weigthed &lt;- srvyr::as_survey_design(exercise_data_shorter_weigthed, strata = \"admin1\", weights = \"weights\") \n\nmy_answer_analysis_weighted &lt;- create_analysis(my_exercise_design_weigthed, sm_separator = \"/\")",
    "crumbs": [
      "Analysis - Simple analysis",
      "02 - Practice (4)"
    ]
  },
  {
    "objectID": "04-analysis/04-analysis-02-practice.html#practice-1",
    "href": "04-analysis/04-analysis-02-practice.html#practice-1",
    "title": "02 - Practice (4)",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nexercise_data &lt;- analysistools_MSNA_template_data\n\nonly_nas &lt;- exercise_data %&gt;%\n  summarise(across(.cols = everything(), .fns = function(x) {\n    sum(is.na(x)) == nrow(exercise_data)\n  })) %&gt;%\n  do.call(c, .)\n\nexercise_data_shorter &lt;- exercise_data[, !only_nas] %&gt;%\n  select(!grep(\"other\", names(exercise_data), value = T))\n\nexercise_data_shorter &lt;- exercise_data_shorter[,1:30]\n\nWith the dataset exercise_data, please do the following:\n\nCreate a results table at the level respondent_gender. Keep the strata at admin1\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument group_var in create_analysis ?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_exercise_design &lt;- srvyr::as_survey_design(exercise_data_shorter, strata = \"admin1\") \n\nmy_answer_analysis &lt;- create_analysis(my_exercise_design, group_var = \"respondent_gender\", sm_separator = \"/\")",
    "crumbs": [
      "Analysis - Simple analysis",
      "02 - Practice (4)"
    ]
  },
  {
    "objectID": "04-analysis/04-analysis-02-practice.html#practice-2",
    "href": "04-analysis/04-analysis-02-practice.html#practice-2",
    "title": "02 - Practice (4)",
    "section": "",
    "text": "The analysis should be weighted, this is the sampling frame. Re-do the analysis at the overall level.\n\n\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\nsampling_frame\n\n\n\n\nstrata\npopulation\n\n\n\nadmin1a\n1e+05\n\n\nadmin1b\n2e+05\n\n\nadmin1c\n3e+05\n\n\n\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function add_weights ?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you modify your design object?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_data_shorter_weigthed &lt;- exercise_data_shorter %&gt;% \n  add_weights(sample_data = sampling_frame, strata_column_dataset = \"admin1\", strata_column_sample = \"strata\", population_column = \"population\")\n\nmy_exercise_design_weigthed &lt;- srvyr::as_survey_design(exercise_data_shorter_weigthed, strata = \"admin1\", weights = \"weights\") \n\nmy_answer_analysis_weighted &lt;- create_analysis(my_exercise_design_weigthed, sm_separator = \"/\")",
    "crumbs": [
      "Analysis - Simple analysis",
      "02 - Practice (4)"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-01-labels.html",
    "href": "07-outputs-part1/07-outputs-01-labels.html",
    "title": "01 - Labels",
    "section": "",
    "text": "library(presentresults)\nlibrary(dplyr)\n# load dataset and kobo\nresults_table &lt;- presentresults_MSNA2024_results_table\n\nkobo_survey &lt;- presentresults_MSNA2024_kobotool_template$kobo_survey\nkobo_choices &lt;- presentresults_MSNA2024_kobotool_template$kobo_choices\nMost of the time, the information in a dataset will be using coding label, not very easy to read by a human. For example, in the following results table.\nresults_table[c(1,9), c(\"analysis_var\", \"group_var\", \"group_var_value\")]\n\n\n\n\nanalysis_var\ngroup_var\ngroup_var_value\n\n\n\nsnfi_fds_cannot_n\nadmin1\nPCODE1\n\n\nsnfi_fds_cannot_n\nresp_gender\nfemale\nWith KOBO tool, the survey and choices sheets always always have at least one column label to show how the questions and choices should be read. It can be used to label the results table.\nkobo_survey |&gt;\n  tail() |&gt;\n  select(type, name, `label::english`)\n\n\n\n\ntype\nname\nlabel::english\n\n\n\nselect_one l_1_to_5\ncomp_prot\nSectoral composite - Protection\n\n\nselect_one l_1_to_5\ncomp_edu\nSectoral composite - Education\n\n\nselect_one l_1_to_5\ncomp_foodsec\nSectoral composite - Food security\n\n\nselect_one l_1_to_5\ncomp_wash\nSectoral composite - WASH\n\n\nselect_one l_1_to_5\ncomp_snfi\nSectoral composite - Shelter\n\n\nselect_one l_1_to_5\nmsni\nMulti-Sectoral Needs Index (MSNI)\nkobo_choices |&gt;\n  tail() |&gt;\n  select(list_name, name, `label::english`)\n\n\n\n\nlist_name\nname\nlabel::english\n\n\n\nNA\nNA\nNA\n\n\nl_1_to_5\n1\n1\n\n\nl_1_to_5\n2\n2\n\n\nl_1_to_5\n3\n3\n\n\nl_1_to_5\n4\n4\n\n\nl_1_to_5\n5\n4+\nAdding the labels to the results table will be done in three steps:",
    "crumbs": [
      "Outputs - part 1",
      "01 - Labels"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-01-labels.html#review-kobo-tool",
    "href": "07-outputs-part1/07-outputs-01-labels.html#review-kobo-tool",
    "title": "01 - Labels",
    "section": "Review KOBO tool",
    "text": "Review KOBO tool\nFirst the KOBO tool should be review to see if there is any duplicated label, names, etc. This will cause issues later one. In the following example, using review_kobo_labels with passing the results table will look at the variables names presents in the results, not all variables\n\n\n\n\n\n\n\nNote\n\n\n\nCurrent version looks for all choices, instead of just the one present in the table. It will be ammended later.\n\n\nreview_kobo_labels_results &lt;- review_kobo_labels(kobo_survey,\n  kobo_choices,\n  results_table = results_table\n)\nreview_kobo_labels_results\n\n\n\n\n\n\n\n\n\n\n\ncomments\nname\nlist_name\nlabel::english\nn\n\n\n\nKobo survey sheet has duplicated labels.\nNA\nNA\nHow often did this happen in the past [4 weeks/30 days]?\n3\n\n\nKobo choices sheet has duplicated names in the same list_name.\nnone\nl_snfi_shelter_type\nNA\n2\n\n\nKobo choices sheet has duplicated names in the same list_name.\nsurface_water\nl_wash_drinking_water_source\nNA\n2\n\n\nKobo choices sheet has duplicated labels in the same list_name.\nNA\nl_admin1\nTo be updated by country\n2\n\n\nKobo choices sheet has duplicated labels in the same list_name.\nNA\nl_admin2\nTo be updated by country\n3\n\n\nKobo choices sheet has duplicated labels in the same list_name.\nNA\nl_admin3\nTo be updated by country\n4\n\n\nKobo choices sheet has duplicated labels in the same list_name.\nNA\nl_admin4\nTo be updated by country\n4\n\n\nKobo choices sheet has duplicated labels in the same list_name.\nNA\nl_cluster_id\nTo be updated by country\n4\n\n\nKobo choices sheet has duplicated labels in the same list_name.\nNA\nl_edu_level_grade\nTo be updated by country\n5\n\n\n\n\n\n\nIn this case we have the HHS frequency question repeated, to remove the duplication, I will add which one they are referring to.\n\nkobo_survey_fixed &lt;- kobo_survey\nkobo_survey_fixed[\n  which(kobo_survey_fixed[[\"label::english\"]] == \"How often did this happen in the past [4 weeks/30 days]?\"),\n  \"label::english\"\n] &lt;- paste(\n  \"How often did this happen in the past [4 weeks/30 days]? ---\",\n  c(\n    \"In the past 4 weeks (30 days), was there ever no food to eat of any kind in your house because of lack of resources to get food?\",\n    \"In the past 4 weeks (30 days), did you or any household member go to sleep at night hungry because there was not enough food?\",\n    \"In the past 4 weeks (30 days), did you or any household member go a whole day or night without eating anything at all because there was not enough food?\"\n  )\n)\n\nIn the choices sheet, there are 2 flags:\n\nKobo choices sheet has duplicated names in the same list_name.\n\nKobo choices sheet has duplicated labels in the same list_name.\n\nFor the duplicated names in the same list name, these were added with the composite indicators. I will just keep one.\n\nkobo_choices_fixed &lt;- kobo_choices |&gt;\n  filter(!`label::english` %in% c(\n    \"No shelter (sleeping in the open)\",\n    \"Surface water (river, dam, lake, pond, stream, canal, irrigation channel)\"\n  ))\n\nduplicated_listname_label &lt;- review_kobo_labels_results |&gt; filter(comments == \"Kobo choices sheet has duplicated labels in the same list_name.\")\n\nFor the duplicated labels, these are because of the template. I will just add a number based on their order.\n\nkobo_choices_fixed &lt;- kobo_choices_fixed |&gt;\n  group_by(list_name)  |&gt; \n  mutate(`label::english` = case_when(\n    list_name %in% duplicated_listname_label$list_name ~ paste(`label::english`, row_number()),\n    TRUE ~ `label::english`\n  ))  |&gt; \n  ungroup()\n\nI can review again.\n\nreview_kobo_labels(kobo_survey_fixed, kobo_choices_fixed, results_table = results_table)\n\n\n\n\ncomments\nname\nlist_name\nlabel::english\nn",
    "crumbs": [
      "Outputs - part 1",
      "01 - Labels"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-01-labels.html#label-dictionary",
    "href": "07-outputs-part1/07-outputs-01-labels.html#label-dictionary",
    "title": "01 - Labels",
    "section": "Label dictionary",
    "text": "Label dictionary\nI can now create a dictionary that will be used to create labels.\n\nlabel_dictionary &lt;- create_label_dictionary(kobo_survey_fixed, kobo_choices_fixed, results_table = results_table)\n\nlabel_dictionary |&gt;  names()\n\n[1] \"dictionary_survey\"        \"dictionary_choices\"      \n[3] \"analysis_type_dictionary\"\n\n\nIt will return a list with:\n\ndictionary_survey: the dictionary to be used for the names of variables\n\n\nlabel_dictionary$dictionary_survey |&gt; head(10)\n\n\n\n\nname\nlabel::english\n\n\n\naudit\nNA\n\n\nstart\nNA\n\n\nend\nNA\n\n\ntoday\nNA\n\n\ndeviceid\nNA\n\n\ninstance_name\nNA\n\n\nintroduction\nIntroduction\n\n\nsurvey_modality\nSurvey modality\n\n\nenum_id\nEnumerator id\n\n\nenum_gender\nWhat is the enumerator’s gender?\n\n\n\n\n\n\n\ndictionary_choices: the dictionary to be used for the value of the variables,\n\n\nlabel_dictionary$dictionary_choices |&gt; head(10)\n\n\n\n\nname_survey\nname_choices\nlabel::english_choices\n\n\n\nsurvey_modality\nremote\nRemote\n\n\nsurvey_modality\nin_person\nIn person\n\n\nenum_id\nid_1\nid_1\n\n\nenum_id\nid_2\nid_2\n\n\nenum_id\nid_3\nid_3\n\n\nenum_gender\nmale\nMale / man\n\n\nenum_gender\nfemale\nFemale / woman\n\n\nenum_gender\nother\nOther\n\n\nenum_gender\npnta\nPrefer not to answer\n\n\nadmin1\nPCODE1\nTo be updated by country 1\n\n\n\n\n\n\n\nanalysis_type_dictionary: the dictionary to be used for the analysis_type column.\n\n\nlabel_dictionary$analysis_type_dictionary |&gt; head(10)\n\n\n\n\nanalysis_type\nlabel_analysis_type\n\n\n\nprop_select_one\nProportion (single choice)\n\n\nprop_select_multiple\nProportion (multiple choice)\n\n\nmean\nMean\n\n\nratio\nRatio\n\n\nmedian\nMedian\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nanalysis_type_dictionary will always come in English, if you want to modify it please check the example of the function.",
    "crumbs": [
      "Outputs - part 1",
      "01 - Labels"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-01-labels.html#add-the-label",
    "href": "07-outputs-part1/07-outputs-01-labels.html#add-the-label",
    "title": "01 - Labels",
    "section": "Add the label",
    "text": "Add the label\nFinally, using add_label_columns_to_results_table will add the label columns to the results table.\n\nresults_table_labeled &lt;- add_label_columns_to_results_table(\n  results_table,\n  label_dictionary\n)\n\nJoining with `by = join_by(analysis_type)`\nJoining with `by = join_by(analysis_key)`\n\nresults_table_labeled [1,] |&gt; \n  t()\n\n                         [,1]                                                                                                                               \nanalysis_type            \"prop_select_one\"                                                                                                                  \nanalysis_var             \"snfi_fds_cannot_n\"                                                                                                                \nanalysis_var_value       \"1\"                                                                                                                                \ngroup_var                \"admin1\"                                                                                                                           \ngroup_var_value          \"PCODE1\"                                                                                                                           \nstat                     \"0.2857143\"                                                                                                                        \nstat_low                 \"-0.06981812\"                                                                                                                      \nstat_upp                 \"0.6412467\"                                                                                                                        \nn                        \"2\"                                                                                                                                \nn_total                  \"7\"                                                                                                                                \nn_w                      \"2\"                                                                                                                                \nn_w_total                \"7\"                                                                                                                                \nanalysis_key             \"prop_select_one @/@ snfi_fds_cannot_n %/% 1 @/@ admin1 %/% PCODE1\"                                                                \ntheme                    \"SNFI\"                                                                                                                             \nmodule                   NA                                                                                                                                 \nindicator                \"% of households by number of domestic tasks that cannot be performed\"                                                             \nlabel_analysis_var       \"Number of domestic tasks that cannot be performed\"                                                                                \nlabel_analysis_var_value \"1\"                                                                                                                                \nlabel_group_var          \"Admin 1\"                                                                                                                          \nlabel_group_var_value    \"To be updated by country 1\"                                                                                                       \nlabel_analysis_type      \"Proportion (single choice)\"                                                                                                       \nlabel_analysis_key       \"Proportion (single choice) @/@ Number of domestic tasks that cannot be performed %/% 1 @/@ Admin 1 %/% To be updated by country 1\"\n\n\nThis is section comes from this vignette.",
    "crumbs": [
      "Outputs - part 1",
      "01 - Labels"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-02-tables.html",
    "href": "07-outputs-part1/07-outputs-02-tables.html",
    "title": "02 - Tables",
    "section": "",
    "text": "library(presentresults)\n\nmy_results_table &lt;- presentresults::presentresults_resultstable\n\nThe framework is built around 4 steps: cleaning, composition, analysis, outputs\n\n\nCleaning: Any manipulation to go from the raw data to the clean data\n\nComposition: Any manipulation before the analysis e.g. adding indicators, adding information from loop, main dataset, or any other dataset (e.g. previous round), aok aggregation, etc.\n\nAnalysis: Any manipulation regarding only the analysis.\n\nOutputs: Any manipulation to format the outputs. Outputs are created from the results table, from the stat + analysis key\n\nThe following section will present some introduction about the outputs.\n\nThere are currently two types of table:\n\none that have the variables in the rows and the disagregation in the columns,\none that have the disagregation in the rows and the variables in the columns.\n\nThere are two steps to turn a results table:\n\nTurn the long results table to a large results table.\nFormat and export it to Excel.\n\n\n\n\n\n\n\ncreate_*\n\n\n\n\ncreate_* functions will create, transform something, e.g. creating a cleaning log with the checks to be filled, create analysis results table, create an output.\nOutputs from create_* functions outputs can be in different shape, format, etc.\ncreate_* function is catch-all.\n\n\n\nWide table with the groups in the rows and the variables in the columns.\n\nmy_results_table %&gt;% \n  create_table_group_x_variable() %&gt;% \n  create_xlsx_group_x_variable(file_path = \"../outputs/04 - example - group_x_variable.xlsx\", overwrite = T)\n\n\n\nWide table with the variables in the rows and the groups in the columns.\n\nmy_results_table %&gt;% \n  create_table_variable_x_group() %&gt;%\n  create_xlsx_variable_x_group(file_path = \"../outputs/05 - example - variable_x_group.xlsx\", overwrite = T)\n\n\n\n\n04 - example - group_x_variable\n05 - example - variable_x_group",
    "crumbs": [
      "Outputs - part 1",
      "02 - Tables"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-02-tables.html#create__group_x_variable",
    "href": "07-outputs-part1/07-outputs-02-tables.html#create__group_x_variable",
    "title": "02 - Tables",
    "section": "",
    "text": "Wide table with the groups in the rows and the variables in the columns.\n\nmy_results_table %&gt;% \n  create_table_group_x_variable() %&gt;% \n  create_xlsx_group_x_variable(file_path = \"../outputs/04 - example - group_x_variable.xlsx\", overwrite = T)",
    "crumbs": [
      "Outputs - part 1",
      "02 - Tables"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-02-tables.html#create__variable_x_group",
    "href": "07-outputs-part1/07-outputs-02-tables.html#create__variable_x_group",
    "title": "02 - Tables",
    "section": "",
    "text": "Wide table with the variables in the rows and the groups in the columns.\n\nmy_results_table %&gt;% \n  create_table_variable_x_group() %&gt;%\n  create_xlsx_variable_x_group(file_path = \"../outputs/05 - example - variable_x_group.xlsx\", overwrite = T)",
    "crumbs": [
      "Outputs - part 1",
      "02 - Tables"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-02-tables.html#downloads",
    "href": "07-outputs-part1/07-outputs-02-tables.html#downloads",
    "title": "02 - Tables",
    "section": "",
    "text": "04 - example - group_x_variable\n05 - example - variable_x_group",
    "crumbs": [
      "Outputs - part 1",
      "02 - Tables"
    ]
  },
  {
    "objectID": "03-composition/03-composition-02-review.html",
    "href": "03-composition/03-composition-02-review.html",
    "title": "02 - Review indicators",
    "section": "",
    "text": "Reviewing indicators will compare 2 indicators together and present the differences. It will not check how the indicator was created nor check for inconsistencies. That mean, to review an indicator, it is necessary to create one and compare them. The functions review_one_variable and review_variables will focus on the latter.\n\nlibrary(impactR4PHU)\nlibrary(dplyr)\n\nmy_data &lt;- impactR4PHU::impactR4PHU_data_template |&gt;  \n  filter(respondent_consent != \"no\") \nmy_data_with_indicators &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\"\n) %&gt;%\n  add_hhs(\n  )\n\n\nFirst, a new dataset can be created for the review.\n\nreview_df &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  ) %&gt;%\n  select(uuid, fsl_fcs_score, fsl_fcs_cat)\n\nThen the dataset to be reviewed and the new dataset can be binded together.\n\nbinded_df &lt;- my_data_with_indicators %&gt;%\n  full_join(review_df, by = \"uuid\")\n\n\n\n\n\n\n\n\nNote\n\n\n\nI would advice to use a full_join rather than a left/right_join. That way if any computation has missing value they will be spotted.\n\n\n\n\n\n\n\nNote\n\n\n\nWith the join_* if the names are the same .x and .y will added to the names.\n\n\n\n\n\n\n\n\nreview_*\n\n\n\n\nreview_* functions will review an object by comparing it to standards or another object and flags differences, e.g. reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n\n\nlibrary(addindicators)\n\n\nreview_one_var &lt;- review_variables(binded_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\n\nreview_one_var %&gt;% \n  names()\n\n[1] \"dataset\"      \"review_table\"\n\n\nIt is a list with the dataset and a review table.\n\nreview_one_var$review_table %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nvariable\nreview_check\nreview_comment\n\n\n\n14c3baf8-d4b0-43484c-8d8e8f-a5fd7134982e\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1a8de690-60af-45494a-8b8487-78f45ec16b39\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1d7ca542-5ebf-434e44-949e9a-d3687ef9c145\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1ecfd059-c215-4d4746-94999b-87920feb4a6c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n\n\n\n\nThe review table can be summarised to have a quicker overview.\n\nreview_one_var$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\nTRUE\nSame results\n81\n\n\n\n\n\nTo see how differences are shown, some noise is introduced to the dataset.\n\njittered_df &lt;- binded_df\nset.seed(123)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(124)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(125)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- NA\nset.seed(1236)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- NA\nset.seed(1237)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_score.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_score.x), 5, T)\n\n\nreview_one_variable_jittered &lt;- review_variables(jittered_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\nreview_one_variable_jittered$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\n\nFALSE\nDifferent results\n9\n\n\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nTRUE\nSame results\n62\n\n\n\n\n\n\nThe dataset has new columns to help filtering for further investigation.\n\nreview_one_variable_jittered$dataset[, tail(names(review_one_variable_jittered$dataset), 5)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\nfsl_hhs_cat\nfsl_fcs_score.y\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\nLittle to No\n32.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.0\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n62.5\nAcceptable\nTRUE\nSame results\n\n\nLittle to No\n29.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n40.0\nBorderline\nFALSE\nDifferent results\n\n\n\n\n\n\n\nreview_one_variable_jittered$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_check_fsl_fcs_cat.x, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nFALSE\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nFALSE\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nFALSE\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\nIf there are more than one variable to review, pair-wise vectors can be used.\n\nmy_review &lt;- review_variables(jittered_df,\n  columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\"),\n  columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\")\n)\n\n\nmy_review$review_table %&gt;%\n  group_by(variable, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nvariable\nreview_check\nreview_comment\nn\n\n\n\nfsl_fcs_cat.x\nFALSE\nDifferent results\n9\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nfsl_fcs_cat.x\nTRUE\nSame results\n62\n\n\nfsl_fcs_score.x\nFALSE\nDifferent results\n5\n\n\nfsl_fcs_score.x\nTRUE\nSame results\n76\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_score.x) %&gt;%\n  select(uuid, fsl_fcs_score.x, fsl_fcs_score.y, review_comment_fsl_fcs_score.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_score.x\nfsl_fcs_score.y\nreview_comment_fsl_fcs_score.x\n\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\n22.5\n23.5\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\n40.0\n29.0\nDifferent results\n\n\n5b04c362-1637-4c464d-9f9a97-ed918b7f0a43\n60.5\n12.0\nDifferent results\n\n\n65d0f41e-fb96-424b41-96919a-2de546c7f9a0\n92.5\n19.5\nDifferent results\n\n\nf09a3541-f9a5-4a4644-9c9895-90ea2cfd6548\n42.5\n27.5\nDifferent results",
    "crumbs": [
      "Composition - Adding indicators",
      "02 - Review indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-02-review.html#review_variables",
    "href": "03-composition/03-composition-02-review.html#review_variables",
    "title": "02 - Review indicators",
    "section": "",
    "text": "First, a new dataset can be created for the review.\n\nreview_df &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  ) %&gt;%\n  select(uuid, fsl_fcs_score, fsl_fcs_cat)\n\nThen the dataset to be reviewed and the new dataset can be binded together.\n\nbinded_df &lt;- my_data_with_indicators %&gt;%\n  full_join(review_df, by = \"uuid\")\n\n\n\n\n\n\n\n\nNote\n\n\n\nI would advice to use a full_join rather than a left/right_join. That way if any computation has missing value they will be spotted.\n\n\n\n\n\n\n\nNote\n\n\n\nWith the join_* if the names are the same .x and .y will added to the names.\n\n\n\n\n\n\n\n\nreview_*\n\n\n\n\nreview_* functions will review an object by comparing it to standards or another object and flags differences, e.g. reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n\n\nlibrary(addindicators)\n\n\nreview_one_var &lt;- review_variables(binded_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\n\nreview_one_var %&gt;% \n  names()\n\n[1] \"dataset\"      \"review_table\"\n\n\nIt is a list with the dataset and a review table.\n\nreview_one_var$review_table %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nvariable\nreview_check\nreview_comment\n\n\n\n14c3baf8-d4b0-43484c-8d8e8f-a5fd7134982e\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1a8de690-60af-45494a-8b8487-78f45ec16b39\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1d7ca542-5ebf-434e44-949e9a-d3687ef9c145\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n1ecfd059-c215-4d4746-94999b-87920feb4a6c\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nfsl_fcs_cat.x\nTRUE\nSame results\n\n\n\n\n\n\nThe review table can be summarised to have a quicker overview.\n\nreview_one_var$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\nTRUE\nSame results\n81\n\n\n\n\n\nTo see how differences are shown, some noise is introduced to the dataset.\n\njittered_df &lt;- binded_df\nset.seed(123)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(124)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- sample(unique(jittered_df$fsl_fcs_cat.y), 5, T)\nset.seed(125)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.x\"] &lt;- NA\nset.seed(1236)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_cat.y\"] &lt;- NA\nset.seed(1237)\njittered_df[sample(1:nrow(jittered_df), 5), \"fsl_fcs_score.x\"] &lt;- sample(unique(jittered_df$fsl_fcs_score.x), 5, T)\n\n\nreview_one_variable_jittered &lt;- review_variables(jittered_df,\n  columns_to_review = \"fsl_fcs_cat.x\",\n  columns_to_compare_with = \"fsl_fcs_cat.y\")\n\nreview_one_variable_jittered$review_table %&gt;%\n  group_by(review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\n\nFALSE\nDifferent results\n9\n\n\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nTRUE\nSame results\n62\n\n\n\n\n\n\nThe dataset has new columns to help filtering for further investigation.\n\nreview_one_variable_jittered$dataset[, tail(names(review_one_variable_jittered$dataset), 5)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\nfsl_hhs_cat\nfsl_fcs_score.y\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\nLittle to No\n32.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.0\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n23.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n62.5\nAcceptable\nTRUE\nSame results\n\n\nLittle to No\n29.5\nBorderline\nTRUE\nSame results\n\n\nLittle to No\n40.0\nBorderline\nFALSE\nDifferent results\n\n\n\n\n\n\n\nreview_one_variable_jittered$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_check_fsl_fcs_cat.x, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_check_fsl_fcs_cat.x\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nFALSE\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nFALSE\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nFALSE\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nFALSE\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nFALSE\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nFALSE\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nFALSE\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\nIf there are more than one variable to review, pair-wise vectors can be used.\n\nmy_review &lt;- review_variables(jittered_df,\n  columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\"),\n  columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\")\n)\n\n\nmy_review$review_table %&gt;%\n  group_by(variable, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nvariable\nreview_check\nreview_comment\nn\n\n\n\nfsl_fcs_cat.x\nFALSE\nDifferent results\n9\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.x\n5\n\n\nfsl_fcs_cat.x\nFALSE\nMissing in fsl_fcs_cat.y\n5\n\n\nfsl_fcs_cat.x\nTRUE\nSame results\n62\n\n\nfsl_fcs_score.x\nFALSE\nDifferent results\n5\n\n\nfsl_fcs_score.x\nTRUE\nSame results\n76\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_cat.x) %&gt;%\n  select(uuid, fsl_fcs_cat.x, fsl_fcs_cat.y, review_comment_fsl_fcs_cat.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_cat.x\nfsl_fcs_cat.y\nreview_comment_fsl_fcs_cat.x\n\n\n\n205d37b1-5a6f-44484d-b3b1ba-4eafbdc50873\nAcceptable\nBorderline\nDifferent results\n\n\n3aef5849-5ca7-4c4841-8a8584-e64b1a8d0c92\nAcceptable\nBorderline\nDifferent results\n\n\n3b6948fe-3409-4f4143-b3bab2-86301b529fc7\nAcceptable\nBorderline\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n492705a8-d2c4-4c4f48-acaea1-a6bf1239e5c4\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\n4b038c2e-25a6-484641-aca6a7-cf387e4b29d1\nPoor\nAcceptable\nDifferent results\n\n\n58f3eb24-46bc-404f4e-82878b-df5413c0be2a\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\n60d81329-6dc0-484e4b-9c9e99-7e34af59b61d\nAcceptable\nPoor\nDifferent results\n\n\n761c2a9e-6f40-454042-8d8184-79a5f36d8e12\nPoor\nAcceptable\nDifferent results\n\n\n7b4261fa-61a5-4a4948-999093-13bc7e9f0658\nPoor\nBorderline\nDifferent results\n\n\n82ed0b7c-e364-4b4244-9e9594-e9d52104b7a6\nBorderline\nPoor\nDifferent results\n\n\n98fdb3a2-2c1a-4f424b-8d8782-b21d683ea94f\nPoor\nAcceptable\nDifferent results\n\n\n9b4805ec-845b-46404f-afa9a6-5fe6cdb917a0\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nc659423a-d572-42404f-83848e-f74b92a531e6\nAcceptable\nNA\nMissing in fsl_fcs_cat.y\n\n\nc8bf561e-be90-424448-838c85-d623901e8c5f\nNA\nAcceptable\nMissing in fsl_fcs_cat.x\n\n\nef07451b-a7c5-474c46-84838e-dcf9a350e2b7\nNA\nBorderline\nMissing in fsl_fcs_cat.x\n\n\nef2963c7-ef67-4e4446-bab5b7-7e9d0431fa8c\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\nf362a49c-10e7-4d4744-a1a0a6-4f9d2b73c0e5\nPoor\nNA\nMissing in fsl_fcs_cat.y\n\n\nf9b06cd4-62db-434748-bfbbba-5f0681e493b7\nBorderline\nNA\nMissing in fsl_fcs_cat.y\n\n\n\n\n\n\n\nmy_review$dataset %&gt;%\n  filter(!review_check_fsl_fcs_score.x) %&gt;%\n  select(uuid, fsl_fcs_score.x, fsl_fcs_score.y, review_comment_fsl_fcs_score.x)\n\n\n\n\n\n\n\n\n\n\nuuid\nfsl_fcs_score.x\nfsl_fcs_score.y\nreview_comment_fsl_fcs_score.x\n\n\n\n1c92baf4-107e-474c46-a3a8a5-6b2e815ad30c\n22.5\n23.5\nDifferent results\n\n\n3e02914b-eb25-484243-909498-dcfa793514b2\n40.0\n29.0\nDifferent results\n\n\n5b04c362-1637-4c464d-9f9a97-ed918b7f0a43\n60.5\n12.0\nDifferent results\n\n\n65d0f41e-fb96-424b41-96919a-2de546c7f9a0\n92.5\n19.5\nDifferent results\n\n\nf09a3541-f9a5-4a4644-9c9895-90ea2cfd6548\n42.5\n27.5\nDifferent results",
    "crumbs": [
      "Composition - Adding indicators",
      "02 - Review indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-01-add.html",
    "href": "03-composition/03-composition-01-add.html",
    "title": "01 - Add indicators",
    "section": "",
    "text": "The framework is built around 4 steps: cleaning, composition, analysis, outputs\n\n\nCleaning: any manipulation to go from the raw data to the clean data\n\nComposition: any manipulation before the analysis e.g. adding indicators, adding information from loop or main, aok aggregation, etc.\n\nAnalysis: any manipulation regarding only the analysis\n\nOutputs: any manipulation to format the outputs.\n\nThe following section will present some introduction about the composition.\n\n\nlibrary(impactR4PHU)\nlibrary(dplyr)\n\nmy_data &lt;- impactR4PHU::impactR4PHU_data_template |&gt;  \n  filter(respondent_consent != \"no\") \n\n\n\n\n\n\n\nadd_*\n\n\n\n\nadd_* functions will add a variable (column) to the dataset. For example, to add the duration of a survey, to add the food consumption score category, etc.\nadd_* function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nFor example, to check the duration of a survey, there is only the start and end, but not the duration column.\nWith addindicators some intermediate columns can be added if they are used to create the new indicator.\n\n\n\n\nmy_data_with_fcs &lt;- my_data %&gt;% add_fcs(\n  cutoffs = \"normal\"\n)\n\nmy_data_with_fcs[, tail(names(my_data_with_fcs), 10)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfcs_weight_cereal1\nfcs_weight_legume2\nfcs_weight_dairy3\nfcs_weight_meat4\nfcs_weight_veg5\nfcs_weight_fruit6\nfcs_weight_oil7\nfcs_weight_sugar8\nfsl_fcs_score\nfsl_fcs_cat\n\n\n\n6\n6\n8\n8\n1\n2\n0.5\n1.0\n32.5\nBorderline\n\n\n4\n6\n4\n4\n1\n2\n1.0\n1.0\n23.0\nBorderline\n\n\n4\n3\n8\n4\n1\n2\n0.5\n1.0\n23.5\nBorderline\n\n\n4\n9\n24\n16\n0\n3\n3.0\n3.5\n62.5\nAcceptable\n\n\n14\n3\n8\n0\n0\n0\n2.5\n2.0\n29.5\nBorderline\n\n\n4\n12\n8\n0\n5\n6\n2.0\n3.0\n40.0\nAcceptable\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can learn more about food security indicators here.\n\n\n\n\n\n\n\n\nPipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 add_* functions are piped.\n\n\n\nmy_data_with_indicators &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\"\n) %&gt;%\n  add_hhs(\n  )\n\nmy_data_with_indicators[, tail(names(my_data_with_indicators), 14)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfsl_fcs_score\nfsl_fcs_cat\nfsl_hhs_nofoodhh_recoded\nfsl_hhs_nofoodhh_freq_recoded\nfsl_hhs_sleephungry_recoded\nfsl_hhs_sleephungry_freq_recoded\nfsl_hhs_alldaynight_recoded\nfsl_hhs_alldaynight_freq_recoded\nfsl_hhs_comp1\nfsl_hhs_comp2\nfsl_hhs_comp3\nfsl_hhs_score\nfsl_hhs_cat_ipc\nfsl_hhs_cat\n\n\n\n32.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.0\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n62.5\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n29.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n40.0\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No",
    "crumbs": [
      "Composition - Adding indicators",
      "01 - Add indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-01-add.html#add_fcs",
    "href": "03-composition/03-composition-01-add.html#add_fcs",
    "title": "01 - Add indicators",
    "section": "",
    "text": "my_data_with_fcs &lt;- my_data %&gt;% add_fcs(\n  cutoffs = \"normal\"\n)\n\nmy_data_with_fcs[, tail(names(my_data_with_fcs), 10)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfcs_weight_cereal1\nfcs_weight_legume2\nfcs_weight_dairy3\nfcs_weight_meat4\nfcs_weight_veg5\nfcs_weight_fruit6\nfcs_weight_oil7\nfcs_weight_sugar8\nfsl_fcs_score\nfsl_fcs_cat\n\n\n\n6\n6\n8\n8\n1\n2\n0.5\n1.0\n32.5\nBorderline\n\n\n4\n6\n4\n4\n1\n2\n1.0\n1.0\n23.0\nBorderline\n\n\n4\n3\n8\n4\n1\n2\n0.5\n1.0\n23.5\nBorderline\n\n\n4\n9\n24\n16\n0\n3\n3.0\n3.5\n62.5\nAcceptable\n\n\n14\n3\n8\n0\n0\n0\n2.5\n2.0\n29.5\nBorderline\n\n\n4\n12\n8\n0\n5\n6\n2.0\n3.0\n40.0\nAcceptable\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can learn more about food security indicators here.",
    "crumbs": [
      "Composition - Adding indicators",
      "01 - Add indicators"
    ]
  },
  {
    "objectID": "03-composition/03-composition-01-add.html#add_hhs",
    "href": "03-composition/03-composition-01-add.html#add_hhs",
    "title": "01 - Add indicators",
    "section": "",
    "text": "Pipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 add_* functions are piped.\n\n\n\nmy_data_with_indicators &lt;- my_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\"\n) %&gt;%\n  add_hhs(\n  )\n\nmy_data_with_indicators[, tail(names(my_data_with_indicators), 14)] %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfsl_fcs_score\nfsl_fcs_cat\nfsl_hhs_nofoodhh_recoded\nfsl_hhs_nofoodhh_freq_recoded\nfsl_hhs_sleephungry_recoded\nfsl_hhs_sleephungry_freq_recoded\nfsl_hhs_alldaynight_recoded\nfsl_hhs_alldaynight_freq_recoded\nfsl_hhs_comp1\nfsl_hhs_comp2\nfsl_hhs_comp3\nfsl_hhs_score\nfsl_hhs_cat_ipc\nfsl_hhs_cat\n\n\n\n32.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.0\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n23.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n62.5\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n29.5\nBorderline\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No\n\n\n40.0\nAcceptable\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nNone\nLittle to No",
    "crumbs": [
      "Composition - Adding indicators",
      "01 - Add indicators"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-03-practice.html",
    "href": "05-analysis-extended/05-analysis-03-practice.html",
    "title": "03 - Practice (5)",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\nmy_data &lt;- analysistools::analysistools_MSNA_template_data\n\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\n\nCreate the analysis for the following indicators:\n\n% of households having/had soap at home\n% of households by type of primary source of drinking water\n% of households by self-reported barriers to accessing health care\n\nAverage household income over the 30 days prior to data collection (total)\nMedian household income over the 30 days prior to data collection (total)\nAverage household expenditures in the 6 months prior to data collection (health)\nMedian household expenditures in the 6 months prior to data collection (health)\nRatio household expenditures on health in the 6 months prior to data collection and the household income over the 30 days prior to data collection.\n% of households per number of days when the household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it.\n\nThe analysis should be at admin1 level (the strata).\n\n\n\n\n\n\n\n\n\n\nname\nlabel::english\ntype\n\n\n\nincome_v2_total\nCan you estimate your household’s total income (in local currency) over the last 30 days from all sources? Please only report income received in the form of money, not items or services.\ninteger\n\n\nexpenditure_health\n3. Health-related expenditures (healthcare, medicine, etc.)\ninteger\n\n\nrCSIMealAdult\nDuring the last 7 days, were there days (and, if so, how many) when your household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it?\ninteger\n\n\nwash_drinkingwatersource\nWhat is the main source of drinking water for members of your household?\nselect_one wash_drinkingwatersource\n\n\nwash_soap\nDo you have soap or detergent in your household for washing hands? [if not remote] Can you show it to me?\nselect_one wash_soap\n\n\nhealth_barriers\nWhat are your barriers to access health care?\nselect_multiple health_barriers\n\n\n\n\n\n\n\nexercise_data &lt;- analysistools::analysistools_MSNA_template_data\n\nexercise_sampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\n\ntemplate_loa &lt;- readxl::read_excel(\"../inputs/08 - exercise - template loa.xlsx\")\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nrCSIMealAdult should be analysed as a categorical variable not a numerical variable to get the proportion per day.\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_data &lt;- exercise_data %&gt;%\n  add_weights(\n    exercise_sampling_frame,\n    \"admin1\", \"strata\", \"population\"\n  )\n\nexercise_design &lt;- srvyr::as_survey_design(exercise_data, weights = \"weights\", strata = \"admin1\")\n\nexercise_loa &lt;- readxl::read_excel(\"../inputs/09 - correction - loa.xlsx\")\n\nexercise_results &lt;- create_analysis(exercise_design, loa = exercise_loa, sm_separator = \"/\")\n\n\n\n\n\n\n08 - exercise - template loa\n09 - correction - loa",
    "crumbs": [
      "Analysis - Extended analysis",
      "03 - Practice (5)"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-03-practice.html#practice-1",
    "href": "05-analysis-extended/05-analysis-03-practice.html#practice-1",
    "title": "03 - Practice (5)",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\nmy_data &lt;- analysistools::analysistools_MSNA_template_data\n\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\n\nCreate the analysis for the following indicators:\n\n% of households having/had soap at home\n% of households by type of primary source of drinking water\n% of households by self-reported barriers to accessing health care\n\nAverage household income over the 30 days prior to data collection (total)\nMedian household income over the 30 days prior to data collection (total)\nAverage household expenditures in the 6 months prior to data collection (health)\nMedian household expenditures in the 6 months prior to data collection (health)\nRatio household expenditures on health in the 6 months prior to data collection and the household income over the 30 days prior to data collection.\n% of households per number of days when the household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it.\n\nThe analysis should be at admin1 level (the strata).\n\n\n\n\n\n\n\n\n\n\nname\nlabel::english\ntype\n\n\n\nincome_v2_total\nCan you estimate your household’s total income (in local currency) over the last 30 days from all sources? Please only report income received in the form of money, not items or services.\ninteger\n\n\nexpenditure_health\n3. Health-related expenditures (healthcare, medicine, etc.)\ninteger\n\n\nrCSIMealAdult\nDuring the last 7 days, were there days (and, if so, how many) when your household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it?\ninteger\n\n\nwash_drinkingwatersource\nWhat is the main source of drinking water for members of your household?\nselect_one wash_drinkingwatersource\n\n\nwash_soap\nDo you have soap or detergent in your household for washing hands? [if not remote] Can you show it to me?\nselect_one wash_soap\n\n\nhealth_barriers\nWhat are your barriers to access health care?\nselect_multiple health_barriers\n\n\n\n\n\n\n\nexercise_data &lt;- analysistools::analysistools_MSNA_template_data\n\nexercise_sampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\n\ntemplate_loa &lt;- readxl::read_excel(\"../inputs/08 - exercise - template loa.xlsx\")\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nrCSIMealAdult should be analysed as a categorical variable not a numerical variable to get the proportion per day.\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_data &lt;- exercise_data %&gt;%\n  add_weights(\n    exercise_sampling_frame,\n    \"admin1\", \"strata\", \"population\"\n  )\n\nexercise_design &lt;- srvyr::as_survey_design(exercise_data, weights = \"weights\", strata = \"admin1\")\n\nexercise_loa &lt;- readxl::read_excel(\"../inputs/09 - correction - loa.xlsx\")\n\nexercise_results &lt;- create_analysis(exercise_design, loa = exercise_loa, sm_separator = \"/\")",
    "crumbs": [
      "Analysis - Extended analysis",
      "03 - Practice (5)"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-03-practice.html#downloads",
    "href": "05-analysis-extended/05-analysis-03-practice.html#downloads",
    "title": "03 - Practice (5)",
    "section": "",
    "text": "08 - exercise - template loa\n09 - correction - loa",
    "crumbs": [
      "Analysis - Extended analysis",
      "03 - Practice (5)"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-01-review.html",
    "href": "06-analysis-review/06-analysis-01-review.html",
    "title": "01 - Review an analysis",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\nmy_data &lt;- analysistools_MSNA_template_data\nmy_results &lt;- analysistools::analysistools_MSNA_template_no_ratio_results_table\n\n\nIf the loa that was used was shared, it can be re-used. Otherwise, with the results table and the analysis key, the function create_loa_from_results will generate a loa that can be used to create the analysis for the review.\n\nmy_loa_for_review &lt;- my_results$results_table %&gt;% \n  create_loa_from_results()\n\nmy_loa_for_review\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nlevel\n\n\n\nprop_select_one\nadmin1\nNA\n0.95\n\n\nmean\nincome_v1_salaried_work\nNA\n0.95\n\n\nmedian\nincome_v1_salaried_work\nNA\n0.95\n\n\nmean\nexpenditure_debt\nNA\n0.95\n\n\nmedian\nexpenditure_debt\nNA\n0.95\n\n\nprop_select_one\nwash_drinkingwatersource\nNA\n0.95\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nNA\n0.95\n\n\nmean\nincome_v1_salaried_work\nadmin1\n0.95\n\n\nmedian\nincome_v1_salaried_work\nadmin1\n0.95\n\n\nmean\nexpenditure_debt\nadmin1\n0.95\n\n\nmedian\nexpenditure_debt\nadmin1\n0.95\n\n\nprop_select_one\nwash_drinkingwatersource\nadmin1\n0.95\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nadmin1\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncreate_loa_from_results will not guess the arguments for numerator_NA_to_0 and filter_denominator_0, they will be set to TRUE by default.\nThe confidence level will also be set to .95 by default.\n\n\n\n\n\n\n\n\nreview_*\n\n\n\n\nreview_* functions will review an object by comparing it to standards or another object and flags differences, e.g. reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n\nreview_analysis will compare 2 results together and present the differences. It will not check how the analysis was created nor check for inconsistencies. That mean, to review an analysis, it is necessary to create one and compare them.\n\nmy_design_for_review &lt;- srvyr::as_survey_design(my_data)\nanalysis_for_review &lt;- create_analysis(my_design_for_review, my_loa_for_review, sm_separator = \"/\")\n\nbinded_table &lt;- my_results$results_table %&gt;% \n  left_join(analysis_for_review$results_table, by = \"analysis_key\")\n\nThe binded table, i.e. with both results columns, can then be used to compared the 2 results. It will give back the results table and a review table.\n\nmy_review &lt;- review_analysis(binded_table)\n\ntypeof(my_review)\n\n[1] \"list\"\n\nnames(my_review)\n\n[1] \"results_table\" \"review_table\" \n\n\nThe review table will tell if there is any difference.\n\nmy_review$review_table %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_key\nstat\nreview_check\nreview_comment\nanalysis_type\nanalysis_var\ngroup_var\n\n\n\nprop_select_one @/@ admin1 %/% admin1a @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nprop_select_one\nadmin1\nNA\n\n\nprop_select_one @/@ admin1 %/% admin1b @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nprop_select_one\nadmin1\nNA\n\n\nprop_select_one @/@ admin1 %/% admin1c @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nprop_select_one\nadmin1\nNA\n\n\nmean @/@ income_v1_salaried_work %/% NA @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nmean\nincome_v1_salaried_work\nNA\n\n\nmedian @/@ income_v1_salaried_work %/% NA @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nmedian\nincome_v1_salaried_work\nNA\n\n\nmean @/@ expenditure_debt %/% NA @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nmean\nexpenditure_debt\nNA\n\n\n\n\n\n\nIt can be summarise with the group_by and tally functions\n\nmy_review$review_table %&gt;%\n  group_by(stat, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nstat\nreview_check\nreview_comment\nn\n\n\nstat.x\nTRUE\nSame results\n143\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nanalysis_key are equivalent of an unique identifier. All analysis key should be unique.\n\nThe following part adds some noise to show how difference would appear.\n\njittered_results_table &lt;- binded_table\nset.seed(123)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.x\"] &lt;- sample(unique(jittered_results_table$stat.x), 5, T)\nset.seed(124)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.y\"] &lt;- sample(unique(jittered_results_table$stat.y), 5, T)\nset.seed(125)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.x\"] &lt;- NA\nset.seed(1236)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.y\"] &lt;- NA\n\n\nmy_jittered_review &lt;- review_analysis(jittered_results_table, \n                                      stat_columns_to_review = \"stat.x\",\n                                      stat_columns_to_compare_with = \"stat.y\")\nmy_jittered_review$review_table %&gt;%\n  group_by(stat, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nstat\nreview_check\nreview_comment\nn\n\n\n\nstat.x\nFALSE\nDifferent results\n10\n\n\nstat.x\nFALSE\nMissing in stat.x\n5\n\n\nstat.x\nFALSE\nMissing in stat.y\n5\n\n\nstat.x\nTRUE\nSame results\n123\n\n\n\n\n\n\nThe results table has new columns, in particular the review_check_* and review_comment_*. They can help to filter for the differences and explore.\n\nmy_jittered_review$results_table %&gt;%\n  filter(!review_check_stat.x) %&gt;% \n  head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type.x\nanalysis_var.x\nanalysis_var_value.x\ngroup_var.x\ngroup_var_value.x\nstat.x\nstat_low.x\nstat_upp.x\nn.x\nn_total.x\nn_w.x\nn_w_total.x\nanalysis_key\nanalysis_type.y\nanalysis_var.y\nanalysis_var_value.y\ngroup_var.y\ngroup_var_value.y\nstat.y\nstat_low.y\nstat_upp.y\nn.y\nn_total.y\nn_w.y\nn_w_total.y\nreview_check_stat.x\nreview_comment_stat.x\n\n\n\nprop_select_one\nwash_drinkingwatersource\nbottled_water\nNA\nNA\nNA\n0.0258984\n0.1341016\n8\n100\n8\n100\nprop_select_one @/@ wash_drinkingwatersource %/% bottled_water @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\nbottled_water\nNA\nNA\n0.0800000\n0.0258984\n0.1341016\n8\n100\n8\n100\nFALSE\nMissing in stat.x\n\n\nprop_select_one\nwash_drinkingwatersource\npiped_into_dwelling\nNA\nNA\n0.3809524\n0.0126401\n0.1073599\n6\n100\n6\n100\nprop_select_one @/@ wash_drinkingwatersource %/% piped_into_dwelling @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\npiped_into_dwelling\nNA\nNA\n0.0600000\n0.0126401\n0.1073599\n6\n100\n6\n100\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\nsachet_water\nNA\nNA\n0.0600000\n0.0126401\n0.1073599\n6\n100\n6\n100\nprop_select_one @/@ wash_drinkingwatersource %/% sachet_water @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\nsachet_water\nNA\nNA\n20.1290323\n0.0126401\n0.1073599\n6\n100\n6\n100\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\ntanker_trucks\nNA\nNA\n0.0700000\n0.0191182\n0.1208818\n7\n100\n7\n100\nprop_select_one @/@ wash_drinkingwatersource %/% tanker_trucks @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\ntanker_trucks\nNA\nNA\n20.0000000\n0.0191182\n0.1208818\n7\n100\n7\n100\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\nunprotected_well\nNA\nNA\nNA\n-0.0040187\n0.0640187\n3\n100\n3\n100\nprop_select_one @/@ wash_drinkingwatersource %/% unprotected_well @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\nunprotected_well\nNA\nNA\n0.0300000\n-0.0040187\n0.0640187\n3\n100\n3\n100\nFALSE\nMissing in stat.x\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nlack_materials\nNA\nNA\nNA\n0.3903093\n0.5896907\n49\n100\n49\n100\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% lack_materials @/@ NA %/% NA\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nlack_materials\nNA\nNA\n0.4900000\n0.3903093\n0.5896907\n49\n100\n49\n100\nFALSE\nMissing in stat.x\n\n\nmean\nincome_v1_salaried_work\nNA\nadmin1\nadmin1c\n0.4900000\n19.6729090\n20.8985196\n42\n42\n42\n42\nmean @/@ income_v1_salaried_work %/% NA @/@ admin1 %/% admin1c\nmean\nincome_v1_salaried_work\nNA\nadmin1\nadmin1c\n20.2857143\n19.6729090\n20.8985196\n42\n42\n42\n42\nFALSE\nDifferent results\n\n\nmedian\nexpenditure_debt\nNA\nadmin1\nadmin1a\n19.0000000\n21.0000000\n23.0000000\n31\n31\n31\n31\nmedian @/@ expenditure_debt %/% NA @/@ admin1 %/% admin1a\nmedian\nexpenditure_debt\nNA\nadmin1\nadmin1a\n21.0000000\n21.0000000\n23.0000000\n31\n31\n31\n31\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\ndont_know\nadmin1\nadmin1b\nNA\n-0.0354420\n0.1095161\n1\n27\n1\n27\nprop_select_one @/@ wash_drinkingwatersource %/% dont_know @/@ admin1 %/% admin1b\nprop_select_one\nwash_drinkingwatersource\ndont_know\nadmin1\nadmin1b\n0.0370370\n-0.0354420\n0.1095161\n1\n27\n1\n27\nFALSE\nMissing in stat.x\n\n\nprop_select_one\nwash_drinkingwatersource\npiped_into_compound\nadmin1\nadmin1b\n0.0740741\n-0.0264363\n0.1745845\n2\n27\n2\n27\nprop_select_one @/@ wash_drinkingwatersource %/% piped_into_compound @/@ admin1 %/% admin1b\nprop_select_one\nwash_drinkingwatersource\npiped_into_compound\nadmin1\nadmin1b\n0.5238095\n-0.0264363\n0.1745845\n2\n27\n2\n27\nFALSE\nDifferent results",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "01 - Review an analysis"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-01-review.html#create_loa_from_results",
    "href": "06-analysis-review/06-analysis-01-review.html#create_loa_from_results",
    "title": "01 - Review an analysis",
    "section": "",
    "text": "If the loa that was used was shared, it can be re-used. Otherwise, with the results table and the analysis key, the function create_loa_from_results will generate a loa that can be used to create the analysis for the review.\n\nmy_loa_for_review &lt;- my_results$results_table %&gt;% \n  create_loa_from_results()\n\nmy_loa_for_review\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nlevel\n\n\n\nprop_select_one\nadmin1\nNA\n0.95\n\n\nmean\nincome_v1_salaried_work\nNA\n0.95\n\n\nmedian\nincome_v1_salaried_work\nNA\n0.95\n\n\nmean\nexpenditure_debt\nNA\n0.95\n\n\nmedian\nexpenditure_debt\nNA\n0.95\n\n\nprop_select_one\nwash_drinkingwatersource\nNA\n0.95\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nNA\n0.95\n\n\nmean\nincome_v1_salaried_work\nadmin1\n0.95\n\n\nmedian\nincome_v1_salaried_work\nadmin1\n0.95\n\n\nmean\nexpenditure_debt\nadmin1\n0.95\n\n\nmedian\nexpenditure_debt\nadmin1\n0.95\n\n\nprop_select_one\nwash_drinkingwatersource\nadmin1\n0.95\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nadmin1\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncreate_loa_from_results will not guess the arguments for numerator_NA_to_0 and filter_denominator_0, they will be set to TRUE by default.\nThe confidence level will also be set to .95 by default.",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "01 - Review an analysis"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-01-review.html#review_analysis",
    "href": "06-analysis-review/06-analysis-01-review.html#review_analysis",
    "title": "01 - Review an analysis",
    "section": "",
    "text": "review_*\n\n\n\n\nreview_* functions will review an object by comparing it to standards or another object and flags differences, e.g. reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n\nreview_analysis will compare 2 results together and present the differences. It will not check how the analysis was created nor check for inconsistencies. That mean, to review an analysis, it is necessary to create one and compare them.\n\nmy_design_for_review &lt;- srvyr::as_survey_design(my_data)\nanalysis_for_review &lt;- create_analysis(my_design_for_review, my_loa_for_review, sm_separator = \"/\")\n\nbinded_table &lt;- my_results$results_table %&gt;% \n  left_join(analysis_for_review$results_table, by = \"analysis_key\")\n\nThe binded table, i.e. with both results columns, can then be used to compared the 2 results. It will give back the results table and a review table.\n\nmy_review &lt;- review_analysis(binded_table)\n\ntypeof(my_review)\n\n[1] \"list\"\n\nnames(my_review)\n\n[1] \"results_table\" \"review_table\" \n\n\nThe review table will tell if there is any difference.\n\nmy_review$review_table %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_key\nstat\nreview_check\nreview_comment\nanalysis_type\nanalysis_var\ngroup_var\n\n\n\nprop_select_one @/@ admin1 %/% admin1a @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nprop_select_one\nadmin1\nNA\n\n\nprop_select_one @/@ admin1 %/% admin1b @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nprop_select_one\nadmin1\nNA\n\n\nprop_select_one @/@ admin1 %/% admin1c @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nprop_select_one\nadmin1\nNA\n\n\nmean @/@ income_v1_salaried_work %/% NA @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nmean\nincome_v1_salaried_work\nNA\n\n\nmedian @/@ income_v1_salaried_work %/% NA @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nmedian\nincome_v1_salaried_work\nNA\n\n\nmean @/@ expenditure_debt %/% NA @/@ NA %/% NA\nstat.x\nTRUE\nSame results\nmean\nexpenditure_debt\nNA\n\n\n\n\n\n\nIt can be summarise with the group_by and tally functions\n\nmy_review$review_table %&gt;%\n  group_by(stat, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nstat\nreview_check\nreview_comment\nn\n\n\nstat.x\nTRUE\nSame results\n143\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nanalysis_key are equivalent of an unique identifier. All analysis key should be unique.\n\nThe following part adds some noise to show how difference would appear.\n\njittered_results_table &lt;- binded_table\nset.seed(123)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.x\"] &lt;- sample(unique(jittered_results_table$stat.x), 5, T)\nset.seed(124)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.y\"] &lt;- sample(unique(jittered_results_table$stat.y), 5, T)\nset.seed(125)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.x\"] &lt;- NA\nset.seed(1236)\njittered_results_table[sample(1:nrow(jittered_results_table), 5), \"stat.y\"] &lt;- NA\n\n\nmy_jittered_review &lt;- review_analysis(jittered_results_table, \n                                      stat_columns_to_review = \"stat.x\",\n                                      stat_columns_to_compare_with = \"stat.y\")\nmy_jittered_review$review_table %&gt;%\n  group_by(stat, review_check, review_comment) %&gt;%\n  tally()\n\n\n\n\nstat\nreview_check\nreview_comment\nn\n\n\n\nstat.x\nFALSE\nDifferent results\n10\n\n\nstat.x\nFALSE\nMissing in stat.x\n5\n\n\nstat.x\nFALSE\nMissing in stat.y\n5\n\n\nstat.x\nTRUE\nSame results\n123\n\n\n\n\n\n\nThe results table has new columns, in particular the review_check_* and review_comment_*. They can help to filter for the differences and explore.\n\nmy_jittered_review$results_table %&gt;%\n  filter(!review_check_stat.x) %&gt;% \n  head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type.x\nanalysis_var.x\nanalysis_var_value.x\ngroup_var.x\ngroup_var_value.x\nstat.x\nstat_low.x\nstat_upp.x\nn.x\nn_total.x\nn_w.x\nn_w_total.x\nanalysis_key\nanalysis_type.y\nanalysis_var.y\nanalysis_var_value.y\ngroup_var.y\ngroup_var_value.y\nstat.y\nstat_low.y\nstat_upp.y\nn.y\nn_total.y\nn_w.y\nn_w_total.y\nreview_check_stat.x\nreview_comment_stat.x\n\n\n\nprop_select_one\nwash_drinkingwatersource\nbottled_water\nNA\nNA\nNA\n0.0258984\n0.1341016\n8\n100\n8\n100\nprop_select_one @/@ wash_drinkingwatersource %/% bottled_water @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\nbottled_water\nNA\nNA\n0.0800000\n0.0258984\n0.1341016\n8\n100\n8\n100\nFALSE\nMissing in stat.x\n\n\nprop_select_one\nwash_drinkingwatersource\npiped_into_dwelling\nNA\nNA\n0.3809524\n0.0126401\n0.1073599\n6\n100\n6\n100\nprop_select_one @/@ wash_drinkingwatersource %/% piped_into_dwelling @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\npiped_into_dwelling\nNA\nNA\n0.0600000\n0.0126401\n0.1073599\n6\n100\n6\n100\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\nsachet_water\nNA\nNA\n0.0600000\n0.0126401\n0.1073599\n6\n100\n6\n100\nprop_select_one @/@ wash_drinkingwatersource %/% sachet_water @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\nsachet_water\nNA\nNA\n20.1290323\n0.0126401\n0.1073599\n6\n100\n6\n100\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\ntanker_trucks\nNA\nNA\n0.0700000\n0.0191182\n0.1208818\n7\n100\n7\n100\nprop_select_one @/@ wash_drinkingwatersource %/% tanker_trucks @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\ntanker_trucks\nNA\nNA\n20.0000000\n0.0191182\n0.1208818\n7\n100\n7\n100\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\nunprotected_well\nNA\nNA\nNA\n-0.0040187\n0.0640187\n3\n100\n3\n100\nprop_select_one @/@ wash_drinkingwatersource %/% unprotected_well @/@ NA %/% NA\nprop_select_one\nwash_drinkingwatersource\nunprotected_well\nNA\nNA\n0.0300000\n-0.0040187\n0.0640187\n3\n100\n3\n100\nFALSE\nMissing in stat.x\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nlack_materials\nNA\nNA\nNA\n0.3903093\n0.5896907\n49\n100\n49\n100\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% lack_materials @/@ NA %/% NA\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nlack_materials\nNA\nNA\n0.4900000\n0.3903093\n0.5896907\n49\n100\n49\n100\nFALSE\nMissing in stat.x\n\n\nmean\nincome_v1_salaried_work\nNA\nadmin1\nadmin1c\n0.4900000\n19.6729090\n20.8985196\n42\n42\n42\n42\nmean @/@ income_v1_salaried_work %/% NA @/@ admin1 %/% admin1c\nmean\nincome_v1_salaried_work\nNA\nadmin1\nadmin1c\n20.2857143\n19.6729090\n20.8985196\n42\n42\n42\n42\nFALSE\nDifferent results\n\n\nmedian\nexpenditure_debt\nNA\nadmin1\nadmin1a\n19.0000000\n21.0000000\n23.0000000\n31\n31\n31\n31\nmedian @/@ expenditure_debt %/% NA @/@ admin1 %/% admin1a\nmedian\nexpenditure_debt\nNA\nadmin1\nadmin1a\n21.0000000\n21.0000000\n23.0000000\n31\n31\n31\n31\nFALSE\nDifferent results\n\n\nprop_select_one\nwash_drinkingwatersource\ndont_know\nadmin1\nadmin1b\nNA\n-0.0354420\n0.1095161\n1\n27\n1\n27\nprop_select_one @/@ wash_drinkingwatersource %/% dont_know @/@ admin1 %/% admin1b\nprop_select_one\nwash_drinkingwatersource\ndont_know\nadmin1\nadmin1b\n0.0370370\n-0.0354420\n0.1095161\n1\n27\n1\n27\nFALSE\nMissing in stat.x\n\n\nprop_select_one\nwash_drinkingwatersource\npiped_into_compound\nadmin1\nadmin1b\n0.0740741\n-0.0264363\n0.1745845\n2\n27\n2\n27\nprop_select_one @/@ wash_drinkingwatersource %/% piped_into_compound @/@ admin1 %/% admin1b\nprop_select_one\nwash_drinkingwatersource\npiped_into_compound\nadmin1\nadmin1b\n0.5238095\n-0.0264363\n0.1745845\n2\n27\n2\n27\nFALSE\nDifferent results",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "01 - Review an analysis"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-02-practice.html",
    "href": "06-analysis-review/06-analysis-02-practice.html",
    "title": "02 - Practice (6)",
    "section": "",
    "text": "Review this analysis\n\nThere is no weights. The strata are admin1\n\nlibrary(analysistools)\nlibrary(dplyr)\n\nanalysis_to_review &lt;- readxl::read_excel(\"../inputs/10 - exercise - analysis_to_review.xlsx\")\ndataset_to_review &lt;- readxl::read_excel(\"../inputs/10 - exercise - analysis_to_review.xlsx\", sheet = \"dataset\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nloa_for_review &lt;- analysis_to_review %&gt;% \n  create_loa_from_results()\n\nreview_design &lt;- srvyr::as_survey_design(dataset_to_review, strata = \"admin1\")\nmy_analysis_exercise &lt;- create_analysis(review_design, loa = loa_for_review, sm_separator = \"/\")\n\nJoining with `by = join_by(admin1, respondent_gender)`\nJoining with `by = join_by(admin1, ind_gender)`\nJoining with `by = join_by(admin1, caregiver_available)`\nJoining with `by = join_by(admin1, difficulty_self_care)`\nJoining with `by = join_by(admin1, edu_modality_v2)`\n■■■■■■■■■■ 29% | ETA: 4s\nJoining with `by = join_by(admin1, liv_emerg_csi_3)`\nJoining with `by = join_by(admin1, fs_hhs_nofood_yn)`\nJoining with `by = join_by(admin1, wash_handwashingfacility_observed_water)`\nJoining with `by = join_by(admin1, wash_handwashingfacility_observed_soap)`\nJoining with `by = join_by(admin1, hoh_age)`\n\nmy_results_table_shorter &lt;- my_analysis_exercise$results_table %&gt;% \n  select(analysis_key, stat)\n\nbinded_results_table &lt;- analysis_to_review %&gt;% \n  full_join(my_results_table_shorter, by = \"analysis_key\")\n\nexercise_review &lt;- review_analysis(binded_results_table,\n                                   stat_columns_to_review = \"stat.x\",\n                                   stat_columns_to_compare_with = \"stat.y\", \n                                   analysis_key_column = \"analysis_key\")\n\nexercise_review$review_table %&gt;% \n  group_by(review_check,review_comment) %&gt;% \n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\nTRUE\nSame results\n134\n\n\n\n\n\n\n\n\n\nHow you would review an analysis that does not have an analysis key? (discussion)\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nIf the analysis is in long format, add the analysis key.\nIf the analysis is in a wide format, change to long format then add the analysis key.\n\n\n\n\n\n\n10 - exercise - analysis_to_review",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "02 - Practice (6)"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-02-practice.html#practice-1",
    "href": "06-analysis-review/06-analysis-02-practice.html#practice-1",
    "title": "02 - Practice (6)",
    "section": "",
    "text": "Review this analysis\n\nThere is no weights. The strata are admin1\n\nlibrary(analysistools)\nlibrary(dplyr)\n\nanalysis_to_review &lt;- readxl::read_excel(\"../inputs/10 - exercise - analysis_to_review.xlsx\")\ndataset_to_review &lt;- readxl::read_excel(\"../inputs/10 - exercise - analysis_to_review.xlsx\", sheet = \"dataset\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nloa_for_review &lt;- analysis_to_review %&gt;% \n  create_loa_from_results()\n\nreview_design &lt;- srvyr::as_survey_design(dataset_to_review, strata = \"admin1\")\nmy_analysis_exercise &lt;- create_analysis(review_design, loa = loa_for_review, sm_separator = \"/\")\n\nJoining with `by = join_by(admin1, respondent_gender)`\nJoining with `by = join_by(admin1, ind_gender)`\nJoining with `by = join_by(admin1, caregiver_available)`\nJoining with `by = join_by(admin1, difficulty_self_care)`\nJoining with `by = join_by(admin1, edu_modality_v2)`\n■■■■■■■■■■ 29% | ETA: 4s\nJoining with `by = join_by(admin1, liv_emerg_csi_3)`\nJoining with `by = join_by(admin1, fs_hhs_nofood_yn)`\nJoining with `by = join_by(admin1, wash_handwashingfacility_observed_water)`\nJoining with `by = join_by(admin1, wash_handwashingfacility_observed_soap)`\nJoining with `by = join_by(admin1, hoh_age)`\n\nmy_results_table_shorter &lt;- my_analysis_exercise$results_table %&gt;% \n  select(analysis_key, stat)\n\nbinded_results_table &lt;- analysis_to_review %&gt;% \n  full_join(my_results_table_shorter, by = \"analysis_key\")\n\nexercise_review &lt;- review_analysis(binded_results_table,\n                                   stat_columns_to_review = \"stat.x\",\n                                   stat_columns_to_compare_with = \"stat.y\", \n                                   analysis_key_column = \"analysis_key\")\n\nexercise_review$review_table %&gt;% \n  group_by(review_check,review_comment) %&gt;% \n  tally()\n\n\n\n\nreview_check\nreview_comment\nn\n\n\nTRUE\nSame results\n134",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "02 - Practice (6)"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-02-practice.html#extra",
    "href": "06-analysis-review/06-analysis-02-practice.html#extra",
    "title": "02 - Practice (6)",
    "section": "",
    "text": "How you would review an analysis that does not have an analysis key? (discussion)\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nIf the analysis is in long format, add the analysis key.\nIf the analysis is in a wide format, change to long format then add the analysis key.",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "02 - Practice (6)"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-02-practice.html#downloads",
    "href": "06-analysis-review/06-analysis-02-practice.html#downloads",
    "title": "02 - Practice (6)",
    "section": "",
    "text": "10 - exercise - analysis_to_review",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "02 - Practice (6)"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html",
    "href": "01-cleaning/01-cleaning-01-checks.html",
    "title": "01 - Checks",
    "section": "",
    "text": "The following section will present some introduction about the composition.\n\n\nlibrary(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\n\n\n\n\ncheck_*\n\n\n\n\ncheck_* functions will flag values based on a specific check. It will return them in a log. A *check_** will return a list: the checked dataset, and the log.\ncheck_* functions are used only in the cleaning step.\n\n\n\n\nmy_log1 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\")\n\nIn this example, there are:\n\n\nchecked_dataset: the raw dataset (with extra variables if needed)\n\npotential_outliers: a log of potential outliers\n\n\ntypeof(my_log1)\n\n[1] \"list\"\n\nmy_log1 %&gt;% \n  names()\n\n[1] \"checked_dataset\"    \"potential_outliers\"\n\n\nThe log has at least 4 columns:\n\n\nuuid: the unique identifier\n\nissue: the issue being flagged\n\nquestion: the name of the question\n\nold_value: the value being flagged\n\n\nmy_log1$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutliers are defined as +/- 3 standard deviation from the mean.\nFor log outliers, log(x + 1) is used.\n\n\n\nmy_log2 &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\nmy_log2$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue\n\n\n\n\n\n\nThere is no duplicate. The log is empty.\n\n\n\n\n\n\n\nPipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 check_* functions are piped.\n\n\n\nmy_log3 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\") %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\n\nnames(my_log3)\n\n[1] \"checked_dataset\"    \"potential_outliers\" \"duplicate_log\"     \n\n\n\nmy_log3$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\nmy_log3$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue\n\n\n\n\n\n\n\nThis an example of more checks that exist.\n\nmore_logs &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\") %&gt;% \n  check_soft_duplicates(uuid_column = \"X_uuid\", kobo_survey = my_kobo_survey, sm_separator = \".\") %&gt;%\n  check_outliers(uuid_column = \"X_uuid\") %&gt;%\n  check_value(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#check_outliers",
    "href": "01-cleaning/01-cleaning-01-checks.html#check_outliers",
    "title": "01 - Checks",
    "section": "",
    "text": "my_log1 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\")\n\nIn this example, there are:\n\n\nchecked_dataset: the raw dataset (with extra variables if needed)\n\npotential_outliers: a log of potential outliers\n\n\ntypeof(my_log1)\n\n[1] \"list\"\n\nmy_log1 %&gt;% \n  names()\n\n[1] \"checked_dataset\"    \"potential_outliers\"\n\n\nThe log has at least 4 columns:\n\n\nuuid: the unique identifier\n\nissue: the issue being flagged\n\nquestion: the name of the question\n\nold_value: the value being flagged\n\n\nmy_log1$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutliers are defined as +/- 3 standard deviation from the mean.\nFor log outliers, log(x + 1) is used.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#check_duplicate",
    "href": "01-cleaning/01-cleaning-01-checks.html#check_duplicate",
    "title": "01 - Checks",
    "section": "",
    "text": "my_log2 &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\nmy_log2$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue\n\n\n\n\n\n\nThere is no duplicate. The log is empty.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#pipe-able",
    "href": "01-cleaning/01-cleaning-01-checks.html#pipe-able",
    "title": "01 - Checks",
    "section": "",
    "text": "Pipe-able\n\n\n\nThe framework is built around 2 adjectives, pipe-able and independent. In the framework, functions of the same family should be pipe-able. In the following case, 2 check_* functions are piped.\n\n\n\nmy_log3 &lt;- my_raw_dataset %&gt;% \n  check_outliers(uuid_column = \"X_uuid\") %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\")\n\n\nnames(my_log3)\n\n[1] \"checked_dataset\"    \"potential_outliers\" \"duplicate_log\"     \n\n\n\nmy_log3$potential_outliers %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nuuid\nissue\nquestion\nold_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\noutlier (normal distribution)\nage_respondent_r\n86\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\noutlier (normal distribution)\nage_respondent_r\n84\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\noutlier (log distribution)\nage_respondent_r\n18\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\noutlier (log distribution)\nage_respondent_r\n18\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\noutlier (normal distribution)\nnum_hh_member\n19\n\n\n\n\n\n\n\nmy_log3$duplicate_log %&gt;% \n  head()\n\n\n\n\nuuid\nold_value\nquestion\nissue",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-01-checks.html#more-checks",
    "href": "01-cleaning/01-cleaning-01-checks.html#more-checks",
    "title": "01 - Checks",
    "section": "",
    "text": "This an example of more checks that exist.\n\nmore_logs &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\") %&gt;% \n  check_soft_duplicates(uuid_column = \"X_uuid\", kobo_survey = my_kobo_survey, sm_separator = \".\") %&gt;%\n  check_outliers(uuid_column = \"X_uuid\") %&gt;%\n  check_value(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "01 - Checks"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-03-logical-with-lists.html",
    "href": "01-cleaning/01-cleaning-03-logical-with-lists.html",
    "title": "03 - Checks with logical list",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "03 - Checks with logical list"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-03-logical-with-lists.html#check_logical_with_list",
    "href": "01-cleaning/01-cleaning-03-logical-with-lists.html#check_logical_with_list",
    "title": "03 - Checks with logical list",
    "section": "check_logical_with_list",
    "text": "check_logical_with_list\nIn other cases, the check is specific and should be tailored to the dataset, for example, check_logical_with_list. All the logical checks can be recorded in an excel file.\n\nlogical_check_list &lt;- readxl::read_excel(\"../inputs/01 - example - check_list.xlsx\")\nlogical_check_list\n\n\n\n\n\n\n\n\n\n\ncheck_id\ndescription\ncheck_to_perform\ncolumns_to_clean\n\n\n\ncheck_1\nprimary_livelihood is employment but expenses less than 200000\nprimary_livelihood.employment == 1 & tot_expenses &lt; 200000\nprimary_livelihood.employment,\n\n\ntot_expenses\n\n\n\n\n\ncheck_2\nacces water and tank emptied\naccess_water_enough == “totally_insufficient” & tank_emptied == “about_half”\naccess_water_enough, tank_emptied\n\n\n\n\n\n\nThe check list has 4 columns:\n\ncheck_id : the name of the check\ndescription: the description of the check\ncheck_to_perform: the check to perform. The format for the check to be performed should take the format based on tidyverse. That format is as if a new indicator is create with a mutate. That new indicator should be a logical (i.e. TRUE or FALSE) with TRUE being the value to flag.\ncolumns_to_clean: the list of column names that are used for the logical check.\n\nThis list can then be used with check_logical_with_list.\n\nexample_logic &lt;- my_raw_dataset %&gt;% \n  check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = logical_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\nexample_logic$logical_all %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nquestion\nold_value\nissue\ncheck_id\ncheck_binding\n\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\nprimary_livelihood.employment\nTRUE\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\n\n\nf1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\ntot_expenses\n125000\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / f1175d29-ce1f-43a7-b3d1-ee26cd1b8cdb\n\n\ne9f8b44c-c507-45a1-8d76-66d886437b8f\nprimary_livelihood.employment\nTRUE\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / e9f8b44c-c507-45a1-8d76-66d886437b8f\n\n\ne9f8b44c-c507-45a1-8d76-66d886437b8f\ntot_expenses\n175000\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / e9f8b44c-c507-45a1-8d76-66d886437b8f\n\n\n994a60b8-e640-425c-9774-160651d7af04\nprimary_livelihood.employment\nTRUE\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / 994a60b8-e640-425c-9774-160651d7af04\n\n\n994a60b8-e640-425c-9774-160651d7af04\ntot_expenses\n175000\nprimary_livelihood is employment but expenses less than 200000\ncheck_1\ncheck_1 / 994a60b8-e640-425c-9774-160651d7af04\n\n\n\n\n\n\nThe log returns :\n\nuuid\nquestion: for all variables in columns_to_clean\n\nold value: for all variables in columns_to_clean\n\nissue\ncheck_id: logical check identifier\ncheck_binding: the combination of the check_id and the uuid.\n\nOne check can be flagged in several rows, in the example above, for each uuid, the primary_livelihood and tot_expenses are flagged.\nFormat for the check_to_perform should take the format based on tidyverse. That format is as if a new indicator is create with a mutate. That new indicator should be a logical (i.e. TRUE or FALSE) with TRUE being the value to flag.\n\nmy_raw_dataset %&gt;% \n  dplyr::mutate(xxx =  primary_livelihood.employment == 1 & tot_expenses &lt; 200000) %&gt;% \n  dplyr::select(X_uuid, xxx, primary_livelihood.employment, tot_expenses) %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\nX_uuid\nxxx\nprimary_livelihood.employment\ntot_expenses\n\n\n\ndcf2753a-6ea2-40f5-b493-3527931ef96c\nFALSE\nFALSE\n250000\n\n\n8790ce5c-1c35-41a2-b3c0-538f937d5397\nFALSE\nTRUE\n750000\n\n\nbb818e04-9c40-408e-919f-6b40ff1fdbb3\nFALSE\nFALSE\n250000\n\n\n28b90cbb-2cf0-41c5-9ee1-1c719c0d4c02\nFALSE\nTRUE\n600000\n\n\n7f2a0c6a-529b-481f-963f-a96dca2ec034\nFALSE\nTRUE\n500000\n\n\nb4f92064-12ea-4970-b0f5-fd309de1dda3\nFALSE\nFALSE\n650000\n\n\n\n\n\n\nThe checked dataset will be return with extra columns, i.e. a logical variable with the name of the check_id.\n\nexample_logic$checked_dataset[1:6,tail(names(example_logic$checked_dataset))]\n\n\n\n\nX_notes\nX_status\nX_submitted_by\nX_index\ncheck_1\ncheck_2\n\n\n\n[]\nsubmitted_via_web\nreach_irq\n1\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n2\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n3\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n4\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n5\nFALSE\nFALSE\n\n\n[]\nsubmitted_via_web\nreach_irq\n6\nFALSE\nFALSE\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you don’t include columns_to_clean the check_logical_with_list function will try to guess the variables. Not guarantee it will read or pick the correct names.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "03 - Checks with logical list"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-03-logical-with-lists.html#downloads",
    "href": "01-cleaning/01-cleaning-03-logical-with-lists.html#downloads",
    "title": "03 - Checks with logical list",
    "section": "Downloads",
    "text": "Downloads\n\n01 - example - check_list",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "03 - Checks with logical list"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-02-tables-for-maps.html",
    "href": "08-outputs-part2/08-outputs-02-tables-for-maps.html",
    "title": "02 - Tables for maps",
    "section": "",
    "text": "library(presentresults)\nlibrary(dplyr)\nresults_table &lt;- expand.grid(analysis_var = c(\"msni_in_need\", \"comp_health_in_need\", \"comp_prot_in_need\", \"comp_edu_in_need\", \"comp_foodsec_in_need\",\"comp_wash_in_need\",        \"comp_snfi_in_need\"),\n                             analysis_var_value = c(1,0),\n                             group_var = \"admin1\",\n                             group_var_value = c(\"PCODE1\", \"PCODE2\"))\n\nset.seed(12344)\nresults_table$stat &lt;-runif(nrow(results_table))\nThis vignette will show an example of how to create a table for the MSNA Indicator Maps 1.2 tool.",
    "crumbs": [
      "Outputs - part 2",
      "02 - Tables for maps"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-02-tables-for-maps.html#create_table_for_map",
    "href": "08-outputs-part2/08-outputs-02-tables-for-maps.html#create_table_for_map",
    "title": "02 - Tables for maps",
    "section": "create_table_for_map",
    "text": "create_table_for_map\nLa tabla de resultados (generada aleatoriamente) que se muestra a continuación presenta los resultados en formato largo para 7 indicadores y a nivel administrativo 1:\n\n\nmsni_in_need: Puntaje del Índice de Necesidades Multisectoriales\n\n\ncomp_health_in_need: Puntaje compuesto sectorial de Salud\n\n\ncomp_prot_in_need: Puntaje compuesto sectorial de Protección\n\n\ncomp_edu_in_need: Puntaje compuesto sectorial de Educación\n\n\ncomp_foodsec_in_need: Puntaje compuesto sectorial de Seguridad Alimentaria\n\n\ncomp_wash_in_need: Puntaje compuesto sectorial de Agua, Saneamiento e Higiene\n\n\ncomp_snfi_in_need: Puntaje compuesto sectorial de Refugio y Artículos No Alimentarios\n\n\nadmin1: PCODE1 y PCODE2.\n\nLa columna stat representa los porcentajes.\n\nhead(results_table)\n\n\n\n\n\n\n\n\n\n\n\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\n\n\n\nmsni_in_need\n1\nadmin1\nPCODE1\n0.0647109\n\n\ncomp_health_in_need\n1\nadmin1\nPCODE1\n0.9305904\n\n\ncomp_prot_in_need\n1\nadmin1\nPCODE1\n0.0554359\n\n\ncomp_edu_in_need\n1\nadmin1\nPCODE1\n0.0628720\n\n\ncomp_foodsec_in_need\n1\nadmin1\nPCODE1\n0.1882063\n\n\ncomp_wash_in_need\n1\nadmin1\nPCODE1\n0.7435970\n\n\n\n\n\n\nMaps can only show one information per admin level. First thing is to filter the results table for the information to get the information to be map. In the example, the analysis variable value can be 1 or 0, where 1 means “in need”, and 0 means “not in need”. The map will show the percentages of household in needs, the results will be filtered for 1. Then the function create_table_for_map can be used.\n\nresults_table_filtered &lt;- results_table |&gt; \n  filter(analysis_var_value == \"1\")\n\nresults_table_recoded_5_classes &lt;- results_table_filtered %&gt;% \n  create_table_for_map(number_classes = 5)\n\nresults_table_recoded_5_classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup_var_value\nmsni_in_need\ncomp_health_in_need\ncomp_prot_in_need\ncomp_edu_in_need\ncomp_foodsec_in_need\ncomp_wash_in_need\ncomp_snfi_in_need\n\n\n\nPCODE1\n2\n5\n2\n2\n2\n4\n4\n\n\nPCODE2\n3\n2\n3\n3\n3\n5\n2\n\n\n\n\n\n\nIf you want to use 6 classes, set the argument number_classes to 6.\n\nresults_table_filtered %&gt;% \n  create_table_for_map(number_classes = 6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup_var_value\nmsni_in_need\ncomp_health_in_need\ncomp_prot_in_need\ncomp_edu_in_need\ncomp_foodsec_in_need\ncomp_wash_in_need\ncomp_snfi_in_need\n\n\n\nPCODE1\n2\n6\n2\n2\n2\n5\n4\n\n\nPCODE2\n3\n2\n3\n4\n4\n6\n2\n\n\n\n\n\n\nThere can be 5 or 6 classes as follow:\n\n\n5 classes\n\n\nClass\nValue\n\n\n\n1\n0\n\n\n2\n&lt;= 25%\n\n\n3\n&lt;= 50%\n\n\n4\n&lt;= 75%\n\n\n5\n&lt;= 100%\n\n\nempty\nAnything else\n\n\n\n\n\n\n6 classes\n\n\nClass\nValue\n\n\n\n1\n0\n\n\n2\n&lt;= 20%\n\n\n3\n&lt;= 40%\n\n\n4\n&lt;= 60%\n\n\n5\n&lt;= 80%\n\n\n6\n&lt;= 100%\n\n\nempty\nAnything else",
    "crumbs": [
      "Outputs - part 2",
      "02 - Tables for maps"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-02-tables-for-maps.html#troubleshooting",
    "href": "08-outputs-part2/08-outputs-02-tables-for-maps.html#troubleshooting",
    "title": "02 - Tables for maps",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you have more than one value per indicator and admin level, you should get a warning from tidyr. You can use it to explore where the problem lies.\n\nresults_table %&gt;% \n  create_table_for_map()\n\nWarning: Values from `stat_recoded` are not uniquely identified; output will contain\nlist-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(group_var_value, analysis_var)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup_var_value\nmsni_in_need\ncomp_health_in_need\ncomp_prot_in_need\ncomp_edu_in_need\ncomp_foodsec_in_need\ncomp_wash_in_need\ncomp_snfi_in_need\n\n\n\nPCODE1\n2, 4\n5, 3\n2, 5\n2, 5\n2, 3\n4, 4\n4, 4\n\n\nPCODE2\n3, 5\n2, 2\n3, 3\n3, 5\n3, 4\n5, 3\n2, 3\n\n\n\n\n\n\n\nresults_table |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(group_var_value, analysis_var)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\n\n\ngroup_var_value\nanalysis_var\nn\n\n\n\nPCODE1\nmsni_in_need\n2\n\n\nPCODE1\ncomp_health_in_need\n2\n\n\nPCODE1\ncomp_prot_in_need\n2\n\n\nPCODE1\ncomp_edu_in_need\n2\n\n\nPCODE1\ncomp_foodsec_in_need\n2\n\n\nPCODE1\ncomp_wash_in_need\n2\n\n\nPCODE1\ncomp_snfi_in_need\n2\n\n\nPCODE2\nmsni_in_need\n2\n\n\nPCODE2\ncomp_health_in_need\n2\n\n\nPCODE2\ncomp_prot_in_need\n2\n\n\nPCODE2\ncomp_edu_in_need\n2\n\n\nPCODE2\ncomp_foodsec_in_need\n2\n\n\nPCODE2\ncomp_wash_in_need\n2\n\n\nPCODE2\ncomp_snfi_in_need\n2\n\n\n\n\n\n\nIn this case there are 2 values for each combination of group_var_value and analysis_var.\n\nresults_table |&gt;\n  filter(group_var_value == \"PCODE1\" & analysis_var == \"msni_in_need\")\n\n\n\n\n\n\n\n\n\n\n\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\n\n\n\nmsni_in_need\n1\nadmin1\nPCODE1\n0.0647109\n\n\nmsni_in_need\n0\nadmin1\nPCODE1\n0.6411115\n\n\n\n\n\n\nThere are two values, maps can only show one. The results table should be filtered to one value only.\nThis is section comes from this vignette.",
    "crumbs": [
      "Outputs - part 2",
      "02 - Tables for maps"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-01-ggplot-theme.html",
    "href": "08-outputs-part2/08-outputs-01-ggplot-theme.html",
    "title": "01 - ggplot2 theme",
    "section": "",
    "text": "library(presentresults)\nlibrary(ggplot2)\nThe aim of the themes is to help giving an “IMPACT” touch to the graphs, not to create them. The graph should already be created, i.e. type of plots, and the correct aesthetics, labeling, etc.\nThe following example aims to plot the percentages of households by category of water sources, by gender of the head of households (This a dummy dataset).",
    "crumbs": [
      "Outputs - part 2",
      "01 - ggplot2 theme"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-01-ggplot-theme.html#barplot-without-formating",
    "href": "08-outputs-part2/08-outputs-01-ggplot-theme.html#barplot-without-formating",
    "title": "01 - ggplot2 theme",
    "section": "Barplot without formating",
    "text": "Barplot without formating\n\ndata_to_plot &lt;- presentresults::presentresults_MSNA2024_labelled_results_table |&gt;\n  dplyr::filter(\n    analysis_var == \"wash_drinking_water_source_cat\",\n    group_var == \"hoh_gender\", \n    group_var_value %in% c(\"male\", \"female\")\n  ) |&gt; \n  dplyr::mutate(label_analysis_var_value = factor(label_analysis_var_value,\n                                                  levels = c(\"Improved\",\n                                                             \"Unimproved\",\n                                                             \"Surface water\",\n                                                             \"Undefined\")))\n\ninitialplot &lt;- data_to_plot %&gt;%\n  ggplot2::ggplot() +\n  ggplot2::geom_col(\n    ggplot2::aes(\n      x = label_analysis_var_value,\n      y = stat,\n      fill = label_group_var_value\n    ),\n    position = \"dodge\"\n  ) +\n  ggplot2::labs(\n    title = stringr::str_wrap(unique(data_to_plot$indicator), 50),\n    x = stringr::str_wrap(unique(data_to_plot$label_analysis_var), 50),\n    fill = stringr::str_wrap(unique(data_to_plot$label_group_var), 20)\n  )\n\n\ninitialplot\n\n\n\nInitial plot without theme.",
    "crumbs": [
      "Outputs - part 2",
      "01 - ggplot2 theme"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-01-ggplot-theme.html#theme_barplot",
    "href": "08-outputs-part2/08-outputs-01-ggplot-theme.html#theme_barplot",
    "title": "01 - ggplot2 theme",
    "section": "theme_barplot",
    "text": "theme_barplot\ntheme_barplot will give REACH color palette to the bar plot, put the y-axis to 0 to 100%.\n\ninitialplot + \n  theme_barplot()\n\n\n\nInitial plot without theme_barplot",
    "crumbs": [
      "Outputs - part 2",
      "01 - ggplot2 theme"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-01-ggplot-theme.html#theme_impact",
    "href": "08-outputs-part2/08-outputs-01-ggplot-theme.html#theme_impact",
    "title": "01 - ggplot2 theme",
    "section": "theme_impact",
    "text": "theme_impact\ntheme_impact will change the background and color of the title.\n\ninitialplot + \n  theme_barplot() +\n  theme_impact(\"reach\")\n\n\n\nInitial plot without theme_barplot and theme_impact",
    "crumbs": [
      "Outputs - part 2",
      "01 - ggplot2 theme"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-01-ggplot-theme.html#other-palettes",
    "href": "08-outputs-part2/08-outputs-01-ggplot-theme.html#other-palettes",
    "title": "01 - ggplot2 theme",
    "section": "Other palettes",
    "text": "Other palettes\n\ninitialplot + \n  theme_barplot(palette = impact_palettes$impact_palette) +\n  theme_impact(\"impact\")\n\n\n\nInitial plot without theme_barplot and theme_impact set with IMPACT theme\n\n\n\nSome palettes are available in the impact_palettes object.\n\nimpact_palettes\n\n$reach_palette\n[1] \"#58585A\" \"#EE5859\" \"#D2CBB8\" \"#c7c8ca\"\n\n$impact_palette\n[1] \"#000000\" \"#315975\" \"#58585A\"\n\n$agora_palette\n[1] \"#581522\" \"#023C40\" \"#4F9C35\" \"#F56741\" \"#F6ECD0\"\n\n$tol_palette\n[1] \"#322288\" \"#505050\" \"#44AA99\" \"#88CCEE\" \"#DDCC77\" \"#EE5859\" \"#AA4499\"\n[8] \"#721621\"\n\n$high_contrast_tol_palette\n[1] \"#275587\" \"#CEA936\" \"#A35464\"\n\n$wong_palette\n[1] \"#EE5859\" \"#E69F00\" \"#56B4E9\" \"#322288\" \"#F0E442\" \"#0072B2\" \"#505050\"\n[8] \"#CC79A7\"\n\n$divergent\n[1] \"#F15B22\" \"#F58120\" \"#FBAB35\" \"#209EA0\" \"#008083\" \"#0072B2\" \"#016060\"\n\n$divergent_with_neutral\n[1] \"#721621\" \"#D7191C\" \"#FDAE61\" \"#FFFFBF\" \"#97D3C3\" \"#209EA0\" \"#016060\"",
    "crumbs": [
      "Outputs - part 2",
      "01 - ggplot2 theme"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-01-ggplot-theme.html#errors-and-number-of-colors",
    "href": "08-outputs-part2/08-outputs-01-ggplot-theme.html#errors-and-number-of-colors",
    "title": "01 - ggplot2 theme",
    "section": "Errors and number of colors",
    "text": "Errors and number of colors\nThe palette should have enough color to match the scale fill. The impact palette only has 3 colors while the graph needs 4.\n\ndata_to_plot &lt;- presentresults::presentresults_MSNA2024_labelled_results_table |&gt;\n  dplyr::filter(\n    analysis_var == \"snfi_fds_cannot_cat\",\n    group_var == \"hoh_gender\")\n\ninitialplot &lt;- data_to_plot %&gt;%\n  ggplot2::ggplot() +\n  ggplot2::geom_col(\n    ggplot2::aes(\n      x = label_analysis_var_value,\n      y = stat,\n      fill = label_group_var_value\n    ),\n    position = \"dodge\"\n  ) +\n  ggplot2::labs(\n    title = stringr::str_wrap(unique(data_to_plot$indicator), 50),\n    x = stringr::str_wrap(unique(data_to_plot$label_analysis_var), 50),\n    fill = stringr::str_wrap(unique(data_to_plot$label_group_var), 20)\n  )\ninitialplot + \n  theme_barplot(palette = impact_palettes$impact_palette) +\n  theme_impact(\"impact\")\n\nError in `palette()`:\n! Insufficient values in manual scale. 4 needed but only 3 provided.\n\n\nIf you need more colors, have a look at the grDevices::colorRampPalette\n\nfunction_couleur &lt;- grDevices::colorRampPalette(impact_palettes$divergent_with_neutral)\nfunction_couleur(20)\n\n [1] \"#721621\" \"#91161F\" \"#B1171D\" \"#D1181C\" \"#E1402E\" \"#ED6F43\" \"#F99E59\"\n [8] \"#FDBF74\" \"#FED892\" \"#FEF2B0\" \"#EEF8BF\" \"#CDEAC0\" \"#ACDCC2\" \"#8ACDBF\"\n[15] \"#64BCB4\" \"#3FABA9\" \"#1E9A9C\" \"#148788\" \"#0A7374\" \"#016060\"\n\n\nThis section comes from this vignette.",
    "crumbs": [
      "Outputs - part 2",
      "01 - ggplot2 theme"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-04-practice.html",
    "href": "08-outputs-part2/08-outputs-04-practice.html",
    "title": "04 - Practice (8)",
    "section": "",
    "text": "Add IMPACT theme to the following barplot initialplot\n\n\n\nlibrary(presentresults)\nlibrary(dplyr)\n\ndata_to_plot &lt;- presentresults::presentresults_MSNA2024_labelled_results_table |&gt;\n  dplyr::filter(\n    analysis_var == \"wash_sanitation_facility_cat\",\n    group_var == \"admin1\") |&gt; \n  dplyr::mutate(label_analysis_var_value = factor(label_analysis_var_value,\n                                                  levels = c(\"Improved\",\n                                                             \"Unimproved\",\n                                                             \"None\",\n                                                             \"Undefined\")))\ninitialplot &lt;- data_to_plot %&gt;%\n  ggplot2::ggplot() +\n  ggplot2::geom_col(\n    ggplot2::aes(\n      x = label_analysis_var_value,\n      y = stat,\n      fill = label_group_var_value\n    ),\n    position = \"dodge\"\n  ) +\n  ggplot2::labs(\n    title = stringr::str_wrap(unique(data_to_plot$indicator), 50),\n    x = stringr::str_wrap(unique(data_to_plot$label_analysis_var), 50),\n    fill = stringr::str_wrap(unique(data_to_plot$label_group_var), 20)\n  )\n\ninitialplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument palette in theme_barplot?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHave you looked at the object impact_palettes?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument initiative in theme_impact?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\ninitialplot + \n  theme_barplot(palette = impact_palettes$impact_palette) +\n  theme_impact(\"impact\")\n\n\n\n\n\n\nYou have the following results table. You want to create a map that shows the percentages of households using surface water (surface_water, Surface water) as main drinking water source (wash_drinking_water_source_cat, Category of the drinking water source) per admin level 1 (admin1, Admin 1).\nCreate the table that should be share to the GIS team, the table should have 5 classes (0, less than 20%, less than 40%, less than 60%, less than 80% and less than 100%).\n\n\nlibrary(presentresults)\nlibrary(dplyr)\ndata_to_map &lt;- presentresults::presentresults_MSNA2024_labelled_results_table\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you filter data_to_map for only surface_water in wash_drinking_water_source_cat?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you filter data_to_map for only admin1?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\ndata_filtered &lt;- data_to_map |&gt; \n  filter(\n        analysis_var == \"wash_drinking_water_source_cat\",\n        analysis_var_value == \"surface_water\",\n        group_var == \"admin1\"\n)\nresults_table_recoded_5_classes &lt;- data_filtered |&gt; \n  create_table_for_map(number_classes = 5)\n\nresults_table_recoded_5_classes\n\n\n\n\ngroup_var_value\nwash_drinking_water_source_cat\n\n\n\nPCODE1\n2\n\n\nPCODE2\n2\n\n\n\n\n\n\n\n\n\n\n\nTry the tabular html output.\nTry to edit the authors, RCID and the introduction.\n\n\nreach_tabular_html_example1\nreach_tabular_html_example2",
    "crumbs": [
      "Outputs - part 2",
      "04 - Practice (8)"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-04-practice.html#practice-1",
    "href": "08-outputs-part2/08-outputs-04-practice.html#practice-1",
    "title": "04 - Practice (8)",
    "section": "",
    "text": "Add IMPACT theme to the following barplot initialplot\n\n\n\nlibrary(presentresults)\nlibrary(dplyr)\n\ndata_to_plot &lt;- presentresults::presentresults_MSNA2024_labelled_results_table |&gt;\n  dplyr::filter(\n    analysis_var == \"wash_sanitation_facility_cat\",\n    group_var == \"admin1\") |&gt; \n  dplyr::mutate(label_analysis_var_value = factor(label_analysis_var_value,\n                                                  levels = c(\"Improved\",\n                                                             \"Unimproved\",\n                                                             \"None\",\n                                                             \"Undefined\")))\ninitialplot &lt;- data_to_plot %&gt;%\n  ggplot2::ggplot() +\n  ggplot2::geom_col(\n    ggplot2::aes(\n      x = label_analysis_var_value,\n      y = stat,\n      fill = label_group_var_value\n    ),\n    position = \"dodge\"\n  ) +\n  ggplot2::labs(\n    title = stringr::str_wrap(unique(data_to_plot$indicator), 50),\n    x = stringr::str_wrap(unique(data_to_plot$label_analysis_var), 50),\n    fill = stringr::str_wrap(unique(data_to_plot$label_group_var), 20)\n  )\n\ninitialplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument palette in theme_barplot?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHave you looked at the object impact_palettes?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument initiative in theme_impact?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\ninitialplot + \n  theme_barplot(palette = impact_palettes$impact_palette) +\n  theme_impact(\"impact\")",
    "crumbs": [
      "Outputs - part 2",
      "04 - Practice (8)"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-04-practice.html#practice-2",
    "href": "08-outputs-part2/08-outputs-04-practice.html#practice-2",
    "title": "04 - Practice (8)",
    "section": "",
    "text": "You have the following results table. You want to create a map that shows the percentages of households using surface water (surface_water, Surface water) as main drinking water source (wash_drinking_water_source_cat, Category of the drinking water source) per admin level 1 (admin1, Admin 1).\nCreate the table that should be share to the GIS team, the table should have 5 classes (0, less than 20%, less than 40%, less than 60%, less than 80% and less than 100%).\n\n\nlibrary(presentresults)\nlibrary(dplyr)\ndata_to_map &lt;- presentresults::presentresults_MSNA2024_labelled_results_table\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you filter data_to_map for only surface_water in wash_drinking_water_source_cat?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you filter data_to_map for only admin1?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\ndata_filtered &lt;- data_to_map |&gt; \n  filter(\n        analysis_var == \"wash_drinking_water_source_cat\",\n        analysis_var_value == \"surface_water\",\n        group_var == \"admin1\"\n)\nresults_table_recoded_5_classes &lt;- data_filtered |&gt; \n  create_table_for_map(number_classes = 5)\n\nresults_table_recoded_5_classes\n\n\n\n\ngroup_var_value\nwash_drinking_water_source_cat\n\n\n\nPCODE1\n2\n\n\nPCODE2\n2",
    "crumbs": [
      "Outputs - part 2",
      "04 - Practice (8)"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-04-practice.html#practice-3",
    "href": "08-outputs-part2/08-outputs-04-practice.html#practice-3",
    "title": "04 - Practice (8)",
    "section": "",
    "text": "Try the tabular html output.\nTry to edit the authors, RCID and the introduction.",
    "crumbs": [
      "Outputs - part 2",
      "04 - Practice (8)"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-04-practice.html#downloads",
    "href": "08-outputs-part2/08-outputs-04-practice.html#downloads",
    "title": "04 - Practice (8)",
    "section": "",
    "text": "reach_tabular_html_example1\nreach_tabular_html_example2",
    "crumbs": [
      "Outputs - part 2",
      "04 - Practice (8)"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-03-tabular-html.html",
    "href": "08-outputs-part2/08-outputs-03-tabular-html.html",
    "title": "03 - Tabular html",
    "section": "",
    "text": "The folders templates-quarto are example of Quarto projects. They can be used to produce some tables in the html format.\n \nThe params in the header can be change. Use Render after to create the html output.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe following is work in progress. It will later become something like create_html_variable_x_group.\n\n\n\n\nreach_tabular_html_example1\nreach_tabular_html_example2",
    "crumbs": [
      "Outputs - part 2",
      "03 - Tabular html"
    ]
  },
  {
    "objectID": "08-outputs-part2/08-outputs-03-tabular-html.html#downloads",
    "href": "08-outputs-part2/08-outputs-03-tabular-html.html#downloads",
    "title": "03 - Tabular html",
    "section": "",
    "text": "reach_tabular_html_example1\nreach_tabular_html_example2",
    "crumbs": [
      "Outputs - part 2",
      "03 - Tabular html"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-02-add-duration-others.html",
    "href": "01-cleaning/01-cleaning-02-add-duration-others.html",
    "title": "02 - Add, durations and others",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\nmore_logs &lt;- my_raw_dataset %&gt;% \n  check_duplicate(uuid_column = \"X_uuid\") %&gt;% \n  check_soft_duplicates(uuid_column = \"X_uuid\", kobo_survey = my_kobo_survey, sm_separator = \".\") %&gt;%\n  check_outliers(uuid_column = \"X_uuid\") %&gt;%\n  check_value(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "02 - Add, durations and others"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-02-add-duration-others.html#add_duration",
    "href": "01-cleaning/01-cleaning-02-add-duration-others.html#add_duration",
    "title": "02 - Add, durations and others",
    "section": "add_duration",
    "text": "add_duration\n\n\n\n\n\n\nadd_*\n\n\n\n\nadd_* functions will add a variable (column) to the dataset. For example, to add the duration of a survey, to add the food consumption score category, etc.\nadd_* function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nFor example, to check the duration of a survey, there is only the start and end, but not the duration column.\n\n\n\nmore_logs$checked_dataset &lt;- more_logs$checked_dataset %&gt;% \n  add_duration(uuid_column = \"X_uuid\", start_column = \"X.U.FEFF.start\", end_column = \"end\")\nmore_logs$checked_dataset[1:6, c(\"start_date\", \"start_time\", \"end_date\", \"end_time\", \"days_diff\", \"duration\")]\n\n\n\n\n\n\n\n\n\n\n\n\nstart_date\nstart_time\nend_date\nend_time\ndays_diff\nduration\n\n\n\n2021-07-05\n658.57 mins\n2021-07-05\n696.68 mins\n0 days\n38.11\n\n\n2021-07-05\n608.90 mins\n2021-07-05\n641.92 mins\n0 days\n33.02\n\n\n2021-07-05\n682.23 mins\n2021-07-05\n726.43 mins\n0 days\n44.20\n\n\n2021-07-04\n1342.98 mins\n2021-07-04\n1380.15 mins\n0 days\n37.17\n\n\n2021-07-04\n1391.62 mins\n2021-07-05\n18.88 mins\n1 days\n67.26\n\n\n2021-07-05\n617.38 mins\n2021-07-05\n756.52 mins\n0 days\n139.14\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe duration is added to the checked_dataset in the list, not in the my_raw_dataset dataframe. The check_* functions are used in a pipe, so it needs the current dataset to be modified.\n\n\n\n\n\n\n\nWarning\n\n\n\nAt the moment, add_duration takes very specific format. It will change in the future to become more robust and using lubridate.\n\n\ncheck_duration can now be used with the previous checks.\n\nmore_logs &lt;- more_logs %&gt;% \n  check_duration(column_to_check = \"duration\", uuid_column = \"X_uuid\")\n\nAs much as possible, check_* functions take default argument or the functions will be able to guess some information, e.g. the check_outliers function guesses some numerical values. Some functions need more information.",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "02 - Add, durations and others"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-02-add-duration-others.html#othertext-columns",
    "href": "01-cleaning/01-cleaning-02-add-duration-others.html#othertext-columns",
    "title": "02 - Add, durations and others",
    "section": "other/text columns",
    "text": "other/text columns\ncheck_other needs the list of columns to be checked. It currently, it cannot detect the open text question. KOBO tool can be used.\n\nother_columns_to_check &lt;- my_kobo_survey %&gt;% \n  dplyr::filter(type == \"text\") %&gt;% \n  dplyr::filter(name %in% names(my_raw_dataset)) %&gt;%\n  dplyr::pull(name) \n\nmore_logs &lt;- more_logs %&gt;% \n  check_others(uuid_column = \"X_uuid\", columns_to_check = other_columns_to_check)",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "02 - Add, durations and others"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html",
    "href": "01-cleaning/01-cleaning-04-practice.html",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Try the following with a dataset:\n\nPerform a check to spot personal identifiable information\n\n\nlibrary(cleaningtools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_pii\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")\n\n\n\n\n\n\nPerform a check that will look at the percentages of missing value per observation and that will spot any observation that is different.\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try to add a new column with add_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_data_with_missing &lt;- my_raw_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\n  \nmy_data_with_missing %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")\n\nOr if using a log already\n\na_log &lt;- my_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")\na_log$checked_dataset &lt;- a_log$checked_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\na_log %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")\n\n\n\n\n\n\nFill the excel checklist to do the following checks:\n\nhousehold number (variable: num_hh_member) is above 8.\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and the household always treat the drinking water (variable: treat_drink_water, value: always_treat).\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and one of the main reason for the the household to not meet its water needs is the water pressure (variable: access_water_enough_why_not, value: water_pressure, this is a select multiple)\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\ntype\n\n\n\nnum_hh_member\nHow many members are there in your household (including you)?\ninteger\n\n\nwater_source_drinking\nWhat is the main source of water used by your household for drinking?\nselect_one water_sources\n\n\ntreat_drink_water\nDoes your household treat this water in any way to make it safer to drink?\nselect_one treat\n\n\naccess_water_enough_why_not\nWhat are the main reasons your household is not able to meet its water needs?\nselect_multiple barriers_water_needs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\nlist_name\n\n\n\nbottled\nBottled or sachet water\nwater_sources\n\n\nalways_treat\nYes, always treat it before drinking\ntreat\n\n\nwater_pressure\nWater pressure is not high enough/pumps required\nbarriers_water_needs\n\n\n\n\n\n\n\nexercise_check_list &lt;- readxl::read_excel(\"../inputs/01 - example - check_list.xlsx\")\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = exercise_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_check_list &lt;- data.frame(check_id = c(\"check_household number\", \"check_water_treatment\", \"check_3\"),\n                            description = c(\"num_hh_member is big\",\"using bottled water and always treat\",\"using bottled water and main reason is water pressure\"),\n                            check_to_perform = c(\"num_hh_member &gt; 8\",\"water_source_drinking == \\\"bottled\\\" & treat_drink_water == \\\"always_treat\\\"\",\"water_source_drinking == \\\"bottled\\\" & access_water_enough_why_not.water_pressure == TRUE\"),\n                            columns_to_clean = c(\"num_hh_member\",\"water_source_drinking, treat_drink_water\",\"water_source_drinking, access_water_enough_why_not.water_pressure\"))\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = my_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\n\n\n\n\nTry to add duration with audit files.\n\n\n\n\n\n\n\nExpand to get a tip\n\n\n\n\n\nTry create_audit_list() and add_duration_from_audit()\n\n\n\n\n\n01 - example - check_list",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#practice-1",
    "href": "01-cleaning/01-cleaning-04-practice.html#practice-1",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Try the following with a dataset:\n\nPerform a check to spot personal identifiable information\n\n\nlibrary(cleaningtools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_pii\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#practice-2",
    "href": "01-cleaning/01-cleaning-04-practice.html#practice-2",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Perform a check that will look at the percentages of missing value per observation and that will spot any observation that is different.\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nTry the function check_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try to add a new column with add_percentage_missing\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_data_with_missing &lt;- my_raw_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\n  \nmy_data_with_missing %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")\n\nOr if using a log already\n\na_log &lt;- my_raw_dataset %&gt;% \n  check_pii(uuid_column = \"X_uuid\")\na_log$checked_dataset &lt;- a_log$checked_dataset %&gt;% \n  add_percentage_missing(kobo_survey = my_kobo_survey)\na_log %&gt;% \n  check_percentage_missing(uuid_column = \"X_uuid\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#practice-3",
    "href": "01-cleaning/01-cleaning-04-practice.html#practice-3",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Fill the excel checklist to do the following checks:\n\nhousehold number (variable: num_hh_member) is above 8.\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and the household always treat the drinking water (variable: treat_drink_water, value: always_treat).\nthe water source for drinking water is bottled (variable: water_source_drinking, value: bottled) and one of the main reason for the the household to not meet its water needs is the water pressure (variable: access_water_enough_why_not, value: water_pressure, this is a select multiple)\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\ntype\n\n\n\nnum_hh_member\nHow many members are there in your household (including you)?\ninteger\n\n\nwater_source_drinking\nWhat is the main source of water used by your household for drinking?\nselect_one water_sources\n\n\ntreat_drink_water\nDoes your household treat this water in any way to make it safer to drink?\nselect_one treat\n\n\naccess_water_enough_why_not\nWhat are the main reasons your household is not able to meet its water needs?\nselect_multiple barriers_water_needs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::English (en)\nlist_name\n\n\n\nbottled\nBottled or sachet water\nwater_sources\n\n\nalways_treat\nYes, always treat it before drinking\ntreat\n\n\nwater_pressure\nWater pressure is not high enough/pumps required\nbarriers_water_needs\n\n\n\n\n\n\n\nexercise_check_list &lt;- readxl::read_excel(\"../inputs/01 - example - check_list.xlsx\")\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = exercise_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_check_list &lt;- data.frame(check_id = c(\"check_household number\", \"check_water_treatment\", \"check_3\"),\n                            description = c(\"num_hh_member is big\",\"using bottled water and always treat\",\"using bottled water and main reason is water pressure\"),\n                            check_to_perform = c(\"num_hh_member &gt; 8\",\"water_source_drinking == \\\"bottled\\\" & treat_drink_water == \\\"always_treat\\\"\",\"water_source_drinking == \\\"bottled\\\" & access_water_enough_why_not.water_pressure == TRUE\"),\n                            columns_to_clean = c(\"num_hh_member\",\"water_source_drinking, treat_drink_water\",\"water_source_drinking, access_water_enough_why_not.water_pressure\"))\n\nmy_raw_dataset %&gt;% \n    check_logical_with_list(uuid_column = \"X_uuid\",\n                          list_of_check = my_check_list,\n                          check_id_column = \"check_id\",\n                          check_to_perform_column = \"check_to_perform\",\n                          columns_to_clean_column = \"columns_to_clean\",\n                          description_column = \"description\")",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#extra",
    "href": "01-cleaning/01-cleaning-04-practice.html#extra",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "Try to add duration with audit files.\n\n\n\n\n\n\n\nExpand to get a tip\n\n\n\n\n\nTry create_audit_list() and add_duration_from_audit()",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "01-cleaning/01-cleaning-04-practice.html#downloads",
    "href": "01-cleaning/01-cleaning-04-practice.html#downloads",
    "title": "04 - Practice - session 1",
    "section": "",
    "text": "01 - example - check_list",
    "crumbs": [
      "Cleaning - Checking a dataset",
      "04 - Practice - session 1"
    ]
  },
  {
    "objectID": "06-analysis-review/06-analysis-03-extra.html",
    "href": "06-analysis-review/06-analysis-03-extra.html",
    "title": "03 - Review template",
    "section": "",
    "text": "Review templates\nThere are some project templates that can be used to review the analysis. More information on this repository.",
    "crumbs": [
      "Analysis - Reviewing an analysis",
      "03 - Review template"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-01-loa.html",
    "href": "05-analysis-extended/05-analysis-01-loa.html",
    "title": "01 - List of analysis",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\nmy_data &lt;- analysistools::analysistools_MSNA_template_data\n\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)",
    "crumbs": [
      "Analysis - Extended analysis",
      "01 - List of analysis"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-01-loa.html#create_analysis-and-list-of-analysis-loa",
    "href": "05-analysis-extended/05-analysis-01-loa.html#create_analysis-and-list-of-analysis-loa",
    "title": "01 - List of analysis",
    "section": "\ncreate_analysis and list of analysis (loa)",
    "text": "create_analysis and list of analysis (loa)\nList of analysis (loa) is a list with all analysis to be performed. It takes the form of a data frame with minimum 4 columns:\n\n\nanalysis_type : The analysis type that should be performed.\n\nanalysis_var : The analysis variable or dependent variable.\n\ngroup_var : The grouping variable or independent variable.\n\nlevel : The confidence level (expressed between 0 and 1).\n\n\nmy_loa &lt;- analysistools::analysistools_MSNA_template_loa\n\nmy_loa\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nlevel\n\n\n\nprop_select_one\nadmin1\nNA\n0.95\n\n\nmean\nincome_v1_salaried_work\nNA\n0.95\n\n\nmedian\nincome_v1_salaried_work\nNA\n0.95\n\n\nmean\nexpenditure_debt\nNA\n0.95\n\n\nmedian\nexpenditure_debt\nNA\n0.95\n\n\nprop_select_one\nwash_drinkingwatersource\nNA\n0.95\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nNA\n0.95\n\n\nmean\nincome_v1_salaried_work\nadmin1\n0.95\n\n\nmedian\nincome_v1_salaried_work\nadmin1\n0.95\n\n\nmean\nexpenditure_debt\nadmin1\n0.95\n\n\nmedian\nexpenditure_debt\nadmin1\n0.95\n\n\nprop_select_one\nwash_drinkingwatersource\nadmin1\n0.95\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nadmin1\n0.95\n\n\n\n\n\n\nThe loa can be passed as argument to the create_analysis function.\n\nmy_data &lt;- my_data %&gt;% \n  add_weights(sampling_frame, \"admin1\", \"strata\", \"population\")\n\nmy_design &lt;- srvyr::as_survey_design(my_data, weights = \"weights\", strata = \"admin1\")\nmy_results &lt;- create_analysis(my_design, loa = my_loa, sm_separator = \"/\")\n\nThe calculations are made only for the indicators in the loa. That way the analysis can be tailored to specific needs.\n\nhead_results_table &lt;- my_results$results_table %&gt;% \n  head(5)\n\ntail_results_table &lt;- my_results$results_table %&gt;% \n  tail(5)\n\nrbind(head_results_table,tail_results_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nprop_select_one\nadmin1\nadmin1a\nNA\nNA\n0.1666667\n0.1666667\n0.1666667\n31\n100\n16.66667\n100\nprop_select_one @/@ admin1 %/% admin1a @/@ NA %/% NA\n\n\nprop_select_one\nadmin1\nadmin1b\nNA\nNA\n0.3333333\n0.3333333\n0.3333333\n27\n100\n33.33333\n100\nprop_select_one @/@ admin1 %/% admin1b @/@ NA %/% NA\n\n\nprop_select_one\nadmin1\nadmin1c\nNA\nNA\n0.5000000\n0.5000000\n0.5000000\n42\n100\n50.00000\n100\nprop_select_one @/@ admin1 %/% admin1c @/@ NA %/% NA\n\n\nmean\nincome_v1_salaried_work\nNA\nNA\nNA\n20.0472777\n19.6448025\n20.4497529\n100\n100\n100.00000\n100\nmean @/@ income_v1_salaried_work %/% NA @/@ NA %/% NA\n\n\nmedian\nincome_v1_salaried_work\nNA\nNA\nNA\n20.0000000\n20.0000000\n21.0000000\n100\n100\n100.00000\n100\nmedian @/@ income_v1_salaried_work %/% NA @/@ NA %/% NA\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nunreliable_technology\nadmin1\nadmin1c\n0.5000000\n0.3450192\n0.6549808\n21\n42\n25.00000\n50\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% unreliable_technology @/@ admin1 %/% admin1c\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nlack_equipment\nadmin1\nadmin1c\n0.5714286\n0.4180373\n0.7248198\n24\n42\n28.57143\n50\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% lack_equipment @/@ admin1 %/% admin1c\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nother\nadmin1\nadmin1c\n0.4047619\n0.2526185\n0.5569053\n17\n42\n20.23810\n50\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% other @/@ admin1 %/% admin1c\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\ndont_know\nadmin1\nadmin1c\n0.5000000\n0.3450192\n0.6549808\n21\n42\n25.00000\n50\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% dont_know @/@ admin1 %/% admin1c\n\n\nprop_select_multiple\nedu_learning_conditions_reasons_v1\nprefer_not_to_answer\nadmin1\nadmin1c\n0.4285714\n0.2751802\n0.5819627\n18\n42\n21.42857\n50\nprop_select_multiple @/@ edu_learning_conditions_reasons_v1 %/% prefer_not_to_answer @/@ admin1 %/% admin1c",
    "crumbs": [
      "Analysis - Extended analysis",
      "01 - List of analysis"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-02-ratio.html",
    "href": "05-analysis-extended/05-analysis-02-ratio.html",
    "title": "02 - Ratio",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\nmy_data &lt;- analysistools::analysistools_MSNA_template_data\nset.seed(1323)\nmy_data &lt;- my_data |&gt;\n  mutate(num_aged_school_children = round(runif(100, min = 0, max = 5)),\n         num_enrolled_school_children = round(runif(100, min = 0, max = 5)),\n         num_enrolled_school_children = case_when(num_aged_school_children == 0 ~ NA, num_aged_school_children &lt; num_enrolled_school_children ~ num_aged_school_children,\n                                                  TRUE ~ num_enrolled_school_children\n                                                  ))\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\n\nmy_data &lt;- my_data %&gt;% \n  add_weights(sampling_frame, \"admin1\", \"strata\", \"population\")\n\nmy_design &lt;- srvyr::as_survey_design(my_data, weights = \"weights\", strata = \"admin1\")\n\nTo calculate ratio, there are two functions create_analysis_ratio or create_analysis with a loa with more information.\n\nmy_loa_with_ratio &lt;- read.csv(\"../inputs/07 - example - loa_with_ratio.csv\")\n\n\nmy_loa_with_ratio %&gt;% \n  filter(analysis_type == \"ratio\") |&gt;\n  select(analysis_type, analysis_var, group_var, analysis_var_numerator, analysis_var_denominator)\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nanalysis_var_numerator\nanalysis_var_denominator\n\n\n\nratio\nNA\nNA\nnum_enrolled_school_children\nnum_aged_school_children\n\n\nratio\nNA\nadmin1\nnum_enrolled_school_children\nnum_aged_school_children\n\n\n\n\n\n\n\nmy_results_with_ratio &lt;- create_analysis(my_design, loa = my_loa_with_ratio, sm_separator = \"/\")\n\n\nmy_results_with_ratio$results_table %&gt;% \n  filter(analysis_type == \"ratio\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nNA\nNA\n0.6874563\n0.6054471\n0.7694654\n89\n89\n88.12226\n88.12226\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ NA %/% NA\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nadmin1\nadmin1a\n0.6881720\n0.5646192\n0.8117249\n29\n29\n15.59140\n15.59140\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ admin1 %/% admin1a\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nadmin1\nadmin1b\n0.6461538\n0.4939644\n0.7983432\n25\n25\n30.86420\n30.86420\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ admin1 %/% admin1b\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nadmin1\nadmin1c\n0.7173913\n0.5887553\n0.8460273\n35\n35\n41.66667\n41.66667\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ admin1 %/% admin1c\n\n\n\n\n\n\n\ncreate_analysis_ratio has two arguments: numerator_NA_to_0 and filter_denominator_0 that by default are set to TRUE.\n\nnumerator_NA_to_0 will turn all NA of the numerator into 0’s, default TRUE.\nfilter_denominator_0 will remove all rows with 0’s in the denominator, default TRUE.\n\nThe following example show a dataset with the number of children (num_children), the number of children enrolled to a school (num_enrolled) and the number of children attending school on a regular basis (num_attending).\n\nschool_ex &lt;- data.frame(\n  hh = c(\"hh1\", \"hh2\", \"hh3\", \"hh4\"),\n  num_children = c(3, 0, 2, NA),\n  num_enrolled = c(3, NA, 0, NA),\n  num_attending = c(1, NA, NA, NA)\n  )\n\nme_design &lt;- srvyr::as_survey(school_ex)\n\nschool_ex\n\n\n\n\nhh\nnum_children\nnum_enrolled\nnum_attending\n\n\n\nhh1\n3\n3\n1\n\n\nhh2\n0\nNA\nNA\n\n\nhh3\n2\n0\nNA\n\n\nhh4\nNA\nNA\nNA\n\n\n\n\n\n\n\nWhat is the ratio between children attending school and the number of children ?\nHow many households are included in the calculation?\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\nDefault value will give a ratio of 0.2 as there are 1 child out of 5 attending school.\nnumerator: 1 child from hh1 and 0 from hh3.\ndenominator: 3 from hh1 and 2 from hh3. In the hh3, the num_attending is NA because there is a skip logic, there cannot be a child attending as none are enrolled.\nBy default, the function has the argument numerator_NA_to_0 set to TRUE to turn that NA into a 0.\nn and n_total are 2 as 2 households were included in the calculation. hh2 was not included in the calculation of totals. The argument filter_denominator_0 set to TRUE removes that row.\n\ncreate_analysis_ratio(me_design,\n  analysis_var_numerator = \"num_attending\",\n  analysis_var_denominator = \"num_children\") %&gt;%\n  select(analysis_type, analysis_var, stat, n, n_total, analysis_key)\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nstat\nn\nn_total\nanalysis_key\n\n\nratio\nnum_attending %/% num_children\n0.2\n2\n2\nratio @/@ num_attending %/% NA -/- num_children %/% NA @/@ NA %/% NA\n\n\n\n\n\n\n\n\n\nWhat will be the ratio if only numerator_NA_to_0 is set to FALSE ?\nHow many households are included in the calculation?\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\nRatio will be 1/3, as hh3 with 2 children and NA for attending will be removed with the na.rm = T inside the survey_ratio calculation.\nn and n_total is 1 as only 1 household was used.\n\ncreate_analysis_ratio(me_design,\n                      analysis_var_numerator = \"num_attending\",\n                      analysis_var_denominator = \"num_children\",\n                      numerator_NA_to_0 = FALSE) %&gt;% \n  select(analysis_type, analysis_var, stat, n, n_total, analysis_key)\n\nWarning: There were 2 warnings in `dplyr::summarise()`.\nThe first warning was:\nℹ In argument: `srvyr::survey_ratio(...)`.\nCaused by warning in `qt()`:\n! NaNs produced\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nstat\nn\nn_total\nanalysis_key\n\n\nratio\nnum_attending %/% num_children\n0.3333333\n1\n1\nratio @/@ num_attending %/% NA -/- num_children %/% NA @/@ NA %/% NA\n\n\n\n\n\n\n\n\n\nWhat will be the ratio if only filter_denominator_0 is set to FALSE ?\nHow many households are included in the calculation?\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\nratio will be 0.2 as there are 1 child out of 5 attending school. The number of household counted, n and n_total, is equal to 3 instead 2. The household with 0 child is counted in the totals. (01 + 0 + 0) / (3 + 0 + 2)\n\ncreate_analysis_ratio(me_design,\n                      analysis_var_numerator = \"num_attending\",\n                      analysis_var_denominator = \"num_children\",\n                      filter_denominator_0 = FALSE)  %&gt;% \n  select(analysis_type, analysis_var, stat, n, n_total, analysis_key)\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nstat\nn\nn_total\nanalysis_key\n\n\nratio\nnum_attending %/% num_children\n0.2\n3\n3\nratio @/@ num_attending %/% NA -/- num_children %/% NA @/@ NA %/% NA\n\n\n\n\n\n\n\n\n\n\n07 - example - loa_with_ratio.csv",
    "crumbs": [
      "Analysis - Extended analysis",
      "02 - Ratio"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-02-ratio.html#create_analysis_ratio",
    "href": "05-analysis-extended/05-analysis-02-ratio.html#create_analysis_ratio",
    "title": "02 - Ratio",
    "section": "",
    "text": "library(analysistools)\nlibrary(dplyr)\n\nmy_data &lt;- analysistools::analysistools_MSNA_template_data\nset.seed(1323)\nmy_data &lt;- my_data |&gt;\n  mutate(num_aged_school_children = round(runif(100, min = 0, max = 5)),\n         num_enrolled_school_children = round(runif(100, min = 0, max = 5)),\n         num_enrolled_school_children = case_when(num_aged_school_children == 0 ~ NA, num_aged_school_children &lt; num_enrolled_school_children ~ num_aged_school_children,\n                                                  TRUE ~ num_enrolled_school_children\n                                                  ))\nsampling_frame &lt;- data.frame(\n  strata = c(\"admin1a\", \"admin1b\", \"admin1c\"),\n  population = c(100000, 200000, 300000)\n)\n\nmy_data &lt;- my_data %&gt;% \n  add_weights(sampling_frame, \"admin1\", \"strata\", \"population\")\n\nmy_design &lt;- srvyr::as_survey_design(my_data, weights = \"weights\", strata = \"admin1\")\n\nTo calculate ratio, there are two functions create_analysis_ratio or create_analysis with a loa with more information.\n\nmy_loa_with_ratio &lt;- read.csv(\"../inputs/07 - example - loa_with_ratio.csv\")\n\n\nmy_loa_with_ratio %&gt;% \n  filter(analysis_type == \"ratio\") |&gt;\n  select(analysis_type, analysis_var, group_var, analysis_var_numerator, analysis_var_denominator)\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nanalysis_var_numerator\nanalysis_var_denominator\n\n\n\nratio\nNA\nNA\nnum_enrolled_school_children\nnum_aged_school_children\n\n\nratio\nNA\nadmin1\nnum_enrolled_school_children\nnum_aged_school_children\n\n\n\n\n\n\n\nmy_results_with_ratio &lt;- create_analysis(my_design, loa = my_loa_with_ratio, sm_separator = \"/\")\n\n\nmy_results_with_ratio$results_table %&gt;% \n  filter(analysis_type == \"ratio\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nNA\nNA\n0.6874563\n0.6054471\n0.7694654\n89\n89\n88.12226\n88.12226\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ NA %/% NA\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nadmin1\nadmin1a\n0.6881720\n0.5646192\n0.8117249\n29\n29\n15.59140\n15.59140\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ admin1 %/% admin1a\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nadmin1\nadmin1b\n0.6461538\n0.4939644\n0.7983432\n25\n25\n30.86420\n30.86420\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ admin1 %/% admin1b\n\n\nratio\nnum_enrolled_school_children %/% num_aged_school_children\nNA %/% NA\nadmin1\nadmin1c\n0.7173913\n0.5887553\n0.8460273\n35\n35\n41.66667\n41.66667\nratio @/@ num_enrolled_school_children %/% NA -/- num_aged_school_children %/% NA @/@ admin1 %/% admin1c\n\n\n\n\n\n\n\ncreate_analysis_ratio has two arguments: numerator_NA_to_0 and filter_denominator_0 that by default are set to TRUE.\n\nnumerator_NA_to_0 will turn all NA of the numerator into 0’s, default TRUE.\nfilter_denominator_0 will remove all rows with 0’s in the denominator, default TRUE.\n\nThe following example show a dataset with the number of children (num_children), the number of children enrolled to a school (num_enrolled) and the number of children attending school on a regular basis (num_attending).\n\nschool_ex &lt;- data.frame(\n  hh = c(\"hh1\", \"hh2\", \"hh3\", \"hh4\"),\n  num_children = c(3, 0, 2, NA),\n  num_enrolled = c(3, NA, 0, NA),\n  num_attending = c(1, NA, NA, NA)\n  )\n\nme_design &lt;- srvyr::as_survey(school_ex)\n\nschool_ex\n\n\n\n\nhh\nnum_children\nnum_enrolled\nnum_attending\n\n\n\nhh1\n3\n3\n1\n\n\nhh2\n0\nNA\nNA\n\n\nhh3\n2\n0\nNA\n\n\nhh4\nNA\nNA\nNA\n\n\n\n\n\n\n\nWhat is the ratio between children attending school and the number of children ?\nHow many households are included in the calculation?\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\nDefault value will give a ratio of 0.2 as there are 1 child out of 5 attending school.\nnumerator: 1 child from hh1 and 0 from hh3.\ndenominator: 3 from hh1 and 2 from hh3. In the hh3, the num_attending is NA because there is a skip logic, there cannot be a child attending as none are enrolled.\nBy default, the function has the argument numerator_NA_to_0 set to TRUE to turn that NA into a 0.\nn and n_total are 2 as 2 households were included in the calculation. hh2 was not included in the calculation of totals. The argument filter_denominator_0 set to TRUE removes that row.\n\ncreate_analysis_ratio(me_design,\n  analysis_var_numerator = \"num_attending\",\n  analysis_var_denominator = \"num_children\") %&gt;%\n  select(analysis_type, analysis_var, stat, n, n_total, analysis_key)\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nstat\nn\nn_total\nanalysis_key\n\n\nratio\nnum_attending %/% num_children\n0.2\n2\n2\nratio @/@ num_attending %/% NA -/- num_children %/% NA @/@ NA %/% NA\n\n\n\n\n\n\n\n\n\nWhat will be the ratio if only numerator_NA_to_0 is set to FALSE ?\nHow many households are included in the calculation?\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\nRatio will be 1/3, as hh3 with 2 children and NA for attending will be removed with the na.rm = T inside the survey_ratio calculation.\nn and n_total is 1 as only 1 household was used.\n\ncreate_analysis_ratio(me_design,\n                      analysis_var_numerator = \"num_attending\",\n                      analysis_var_denominator = \"num_children\",\n                      numerator_NA_to_0 = FALSE) %&gt;% \n  select(analysis_type, analysis_var, stat, n, n_total, analysis_key)\n\nWarning: There were 2 warnings in `dplyr::summarise()`.\nThe first warning was:\nℹ In argument: `srvyr::survey_ratio(...)`.\nCaused by warning in `qt()`:\n! NaNs produced\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nstat\nn\nn_total\nanalysis_key\n\n\nratio\nnum_attending %/% num_children\n0.3333333\n1\n1\nratio @/@ num_attending %/% NA -/- num_children %/% NA @/@ NA %/% NA\n\n\n\n\n\n\n\n\n\nWhat will be the ratio if only filter_denominator_0 is set to FALSE ?\nHow many households are included in the calculation?\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\nratio will be 0.2 as there are 1 child out of 5 attending school. The number of household counted, n and n_total, is equal to 3 instead 2. The household with 0 child is counted in the totals. (01 + 0 + 0) / (3 + 0 + 2)\n\ncreate_analysis_ratio(me_design,\n                      analysis_var_numerator = \"num_attending\",\n                      analysis_var_denominator = \"num_children\",\n                      filter_denominator_0 = FALSE)  %&gt;% \n  select(analysis_type, analysis_var, stat, n, n_total, analysis_key)\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nstat\nn\nn_total\nanalysis_key\n\n\nratio\nnum_attending %/% num_children\n0.2\n3\n3\nratio @/@ num_attending %/% NA -/- num_children %/% NA @/@ NA %/% NA",
    "crumbs": [
      "Analysis - Extended analysis",
      "02 - Ratio"
    ]
  },
  {
    "objectID": "05-analysis-extended/05-analysis-02-ratio.html#downloads",
    "href": "05-analysis-extended/05-analysis-02-ratio.html#downloads",
    "title": "02 - Ratio",
    "section": "",
    "text": "07 - example - loa_with_ratio.csv",
    "crumbs": [
      "Analysis - Extended analysis",
      "02 - Ratio"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html",
    "href": "03-composition/03-composition-03-practice.html",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "library(impactR4PHU)\nlibrary(addindicators)\nlibrary(dplyr)\n\n\n\nAdd the food consumption matrix score to the dataset. The food consumption matrix score is a food security indicator that uses the food consumption score, household hunger score and the reduced coping strategy index.\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::english\ntype\n\n\n\nrCSILessQlty\nDuring the last 7 days, were there days (and, if so, how many) when your household had to rely on less preferred and less expensive food to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIBorrow\nDuring the last 7 days, were there days (and, if so, how many) when your household had to borrow food or rely on help from a relative or friend to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealSize\nDuring the last 7 days, were there days (and, if so, how many) when your household had to limit portion size of meals at meal times to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealAdult\nDuring the last 7 days, were there days (and, if so, how many) when your household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealNb\nDuring the last 7 days, were there days (and, if so, how many) when your household had to reduce number of meals eaten in a day to cope with a lack of food or money to buy it?\ninteger\n\n\n\n\n\n\n\nlibrary(impactR4PHU)\nlibrary(addindicators)\nlibrary(dplyr)\n\n\nexercise_data &lt;- addindicators::addindicators_MSNA_template_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  )\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function add_fcm_phase?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nThe food consumption matrix needs 3 indicators, FCS, rCSI, HHS.\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHave you used the correct HHS category variable?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_answer &lt;- exercise_data %&gt;% \n  add_rcsi(\n    fsl_rcsi_lessquality = \"rCSILessQlty\",\n    fsl_rcsi_borrow = \"rCSIBorrow\",\n    fsl_rcsi_mealsize = \"rCSIMealSize\",\n    fsl_rcsi_mealadult = \"rCSIMealAdult\",\n    fsl_rcsi_mealnb = \"rCSIMealNb\"\n  ) %&gt;%\n  add_fcm_phase(\n  )\n\n\n\n\n\n\n\nYou receive a dataset, you need to review the following four indicators.\n\nFood Consumption Score: fsl_fcs_score, fsl_fcs_cat\n\nHousehold Hunger Score: hhs_score, hhs_cat\n\n\n\n\nDon’t forget to write the review.\n\ndataset_to_review &lt;- read.csv(\"../inputs/06 - exercise - dataset_to_review.csv\")\n\ndataset_without_indicators &lt;- addindicators::addindicators_MSNA_template_data\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_variables\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was the FSC created?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was coded the category for the HHS? Names in the dataset are: “hhs_cat”, “hhs_score” Names created with add_hhs are: “fsl_hhs_cat”, “fsl_hhs_score”\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_review &lt;- dataset_without_indicators %&gt;% \n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  ) %&gt;% \n  select(uuid, fsl_fcs_cat, fsl_fcs_score, fsl_hhs_cat, fsl_hhs_score)\ndataset_to_review &lt;- full_join(dataset_to_review, my_review, by = \"uuid\")\n\nreview &lt;- dataset_to_review %&gt;% \n  review_variables(columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\", \"hhs_cat\", \"hhs_score\"),\n                   columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\", \"fsl_hhs_cat\", \"fsl_hhs_score\"))\n\nreview$review_table %&gt;% \n  group_by(variable,review_check,review_comment) %&gt;% \n  tally()\n\n\nThere are 10 fcs categories that are different.\nThere are 100 HHS categories that are different\n\n\nreview$dataset %&gt;% \n  filter(!review_check_fsl_fcs_cat.x) %&gt;% \n  select(uuid, review_comment_fsl_fcs_cat.x, fsl_fcs_score.x, fsl_fcs_cat.x, fsl_fcs_cat.y)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nreview_comment_fsl_fcs_cat.x\nfsl_fcs_score.x\nfsl_fcs_cat.x\nfsl_fcs_cat.y\n\n\n\nf1b9ec67-20db-47404d-a3ada0-1a37e5c49d02\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\ne21a34f5-1a46-42404b-b7b6be-7bc9286d0f13\nDifferent results\n36.0\nBorderline\nAcceptable\n\n\n42dc8573-e2d0-43484b-aaada2-c37ef865d041\nDifferent results\n39.0\nBorderline\nAcceptable\n\n\nfcd69a08-498f-4c4b47-989799-743cbe5fd960\nDifferent results\n36.5\nBorderline\nAcceptable\n\n\n4d1cae02-49e0-484c4e-8f8d8c-a97dec246310\nDifferent results\n41.0\nBorderline\nAcceptable\n\n\na8319ceb-857c-434142-b9b8bc-7905684fc1d3\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\n6d1acb45-cfb6-4b4441-87888f-e2a4756d30f9\nDifferent results\n38.0\nBorderline\nAcceptable\n\n\n0dea8527-2ab9-4e4844-88868e-8379e514ca2b\nDifferent results\n40.0\nBorderline\nAcceptable\n\n\n7e94afc5-af0b-4a4c46-bebcb7-9f60d1e53a47\nDifferent results\n37.0\nBorderline\nAcceptable\n\n\nb719ef08-bdf5-474240-858d8a-a12bc65d349e\nDifferent results\n41.5\nBorderline\nAcceptable\n\n\n\n\n\n\n\nFood Consumption Score have different categories, what threshold were used to compute the FCS? Maybe 28-42?\n\n\nreview$dataset %&gt;% \n  filter(!review_check_hhs_cat) %&gt;% \n  select(hhs_cat, fsl_hhs_cat) %&gt;% \n  table(useNA = \"ifany\")\n\n              fsl_hhs_cat\nhhs_cat        Little to No Moderate Severe\n  moderate                0       29      0\n  no_or_little           58        0      0\n  severe                  0        0     13\n\n\n\nHHS is fine. Labeling is different\n\n\n\n\n\n\ndataset_to_review",
    "crumbs": [
      "Composition - Adding indicators",
      "03 - Practice (3)"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html#practice-1",
    "href": "03-composition/03-composition-03-practice.html#practice-1",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "Add the food consumption matrix score to the dataset. The food consumption matrix score is a food security indicator that uses the food consumption score, household hunger score and the reduced coping strategy index.\n\n\n\n\n\n\n\n\n\n\n\nname\nlabel::english\ntype\n\n\n\nrCSILessQlty\nDuring the last 7 days, were there days (and, if so, how many) when your household had to rely on less preferred and less expensive food to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIBorrow\nDuring the last 7 days, were there days (and, if so, how many) when your household had to borrow food or rely on help from a relative or friend to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealSize\nDuring the last 7 days, were there days (and, if so, how many) when your household had to limit portion size of meals at meal times to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealAdult\nDuring the last 7 days, were there days (and, if so, how many) when your household had to restrict consumption by adults in order for small children to eat to cope with a lack of food or money to buy it?\ninteger\n\n\nrCSIMealNb\nDuring the last 7 days, were there days (and, if so, how many) when your household had to reduce number of meals eaten in a day to cope with a lack of food or money to buy it?\ninteger\n\n\n\n\n\n\n\nlibrary(impactR4PHU)\nlibrary(addindicators)\nlibrary(dplyr)\n\n\nexercise_data &lt;- addindicators::addindicators_MSNA_template_data %&gt;%\n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  )\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function add_fcm_phase?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nThe food consumption matrix needs 3 indicators, FCS, rCSI, HHS.\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHave you used the correct HHS category variable?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_answer &lt;- exercise_data %&gt;% \n  add_rcsi(\n    fsl_rcsi_lessquality = \"rCSILessQlty\",\n    fsl_rcsi_borrow = \"rCSIBorrow\",\n    fsl_rcsi_mealsize = \"rCSIMealSize\",\n    fsl_rcsi_mealadult = \"rCSIMealAdult\",\n    fsl_rcsi_mealnb = \"rCSIMealNb\"\n  ) %&gt;%\n  add_fcm_phase(\n  )",
    "crumbs": [
      "Composition - Adding indicators",
      "03 - Practice (3)"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html#practice-2",
    "href": "03-composition/03-composition-03-practice.html#practice-2",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "You receive a dataset, you need to review the following four indicators.\n\nFood Consumption Score: fsl_fcs_score, fsl_fcs_cat\n\nHousehold Hunger Score: hhs_score, hhs_cat\n\n\n\n\nDon’t forget to write the review.\n\ndataset_to_review &lt;- read.csv(\"../inputs/06 - exercise - dataset_to_review.csv\")\n\ndataset_without_indicators &lt;- addindicators::addindicators_MSNA_template_data\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_variables\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was the FSC created?\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nHow was coded the category for the HHS? Names in the dataset are: “hhs_cat”, “hhs_score” Names created with add_hhs are: “fsl_hhs_cat”, “fsl_hhs_score”\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nmy_review &lt;- dataset_without_indicators %&gt;% \n  add_fcs(\n  cutoffs = \"normal\",\n  fsl_fcs_cereal = \"fs_fcs_cereals_grains_roots_tubers\",\n  fsl_fcs_legumes = \"fs_fcs_beans_nuts\",\n  fsl_fcs_veg = \"fs_fcs_vegetables_leaves\",\n  fsl_fcs_fruit = \"fs_fcs_fruit\",\n  fsl_fcs_meat = \"fs_fcs_meat_fish_eggs\",\n  fsl_fcs_dairy = \"fs_fcs_dairy\",\n  fsl_fcs_sugar = \"fs_fcs_sugar\",\n  fsl_fcs_oil = \"fs_fcs_oil_fat_butter\"\n  ) %&gt;%\n  add_hhs(\n  fsl_hhs_nofoodhh = \"fs_hhs_nofood_yn\",\n  fsl_hhs_nofoodhh_freq = \"fs_hhs_nofood_freq\",\n  fsl_hhs_sleephungry = \"fs_hhs_sleephungry_yn\",\n  fsl_hhs_sleephungry_freq = \"fs_hhs_sleephungry_freq\",\n  fsl_hhs_alldaynight = \"fs_hhs_daynoteating_yn\",\n  fsl_hhs_alldaynight_freq = \"fs_hhs_daynoteating_freq\",\n  yes_answer = \"yes\",\n  no_answer = \"no\",\n  rarely_answer = \"rarely_1_2\",\n  sometimes_answer = \"sometimes_3_10\",\n  often_answer = \"often_10_times\"\n  ) %&gt;% \n  select(uuid, fsl_fcs_cat, fsl_fcs_score, fsl_hhs_cat, fsl_hhs_score)\ndataset_to_review &lt;- full_join(dataset_to_review, my_review, by = \"uuid\")\n\nreview &lt;- dataset_to_review %&gt;% \n  review_variables(columns_to_review = c(\"fsl_fcs_cat.x\", \"fsl_fcs_score.x\", \"hhs_cat\", \"hhs_score\"),\n                   columns_to_compare_with = c(\"fsl_fcs_cat.y\", \"fsl_fcs_score.y\", \"fsl_hhs_cat\", \"fsl_hhs_score\"))\n\nreview$review_table %&gt;% \n  group_by(variable,review_check,review_comment) %&gt;% \n  tally()\n\n\nThere are 10 fcs categories that are different.\nThere are 100 HHS categories that are different\n\n\nreview$dataset %&gt;% \n  filter(!review_check_fsl_fcs_cat.x) %&gt;% \n  select(uuid, review_comment_fsl_fcs_cat.x, fsl_fcs_score.x, fsl_fcs_cat.x, fsl_fcs_cat.y)\n\n\n\n\n\n\n\n\n\n\n\nuuid\nreview_comment_fsl_fcs_cat.x\nfsl_fcs_score.x\nfsl_fcs_cat.x\nfsl_fcs_cat.y\n\n\n\nf1b9ec67-20db-47404d-a3ada0-1a37e5c49d02\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\ne21a34f5-1a46-42404b-b7b6be-7bc9286d0f13\nDifferent results\n36.0\nBorderline\nAcceptable\n\n\n42dc8573-e2d0-43484b-aaada2-c37ef865d041\nDifferent results\n39.0\nBorderline\nAcceptable\n\n\nfcd69a08-498f-4c4b47-989799-743cbe5fd960\nDifferent results\n36.5\nBorderline\nAcceptable\n\n\n4d1cae02-49e0-484c4e-8f8d8c-a97dec246310\nDifferent results\n41.0\nBorderline\nAcceptable\n\n\na8319ceb-857c-434142-b9b8bc-7905684fc1d3\nDifferent results\n37.5\nBorderline\nAcceptable\n\n\n6d1acb45-cfb6-4b4441-87888f-e2a4756d30f9\nDifferent results\n38.0\nBorderline\nAcceptable\n\n\n0dea8527-2ab9-4e4844-88868e-8379e514ca2b\nDifferent results\n40.0\nBorderline\nAcceptable\n\n\n7e94afc5-af0b-4a4c46-bebcb7-9f60d1e53a47\nDifferent results\n37.0\nBorderline\nAcceptable\n\n\nb719ef08-bdf5-474240-858d8a-a12bc65d349e\nDifferent results\n41.5\nBorderline\nAcceptable\n\n\n\n\n\n\n\nFood Consumption Score have different categories, what threshold were used to compute the FCS? Maybe 28-42?\n\n\nreview$dataset %&gt;% \n  filter(!review_check_hhs_cat) %&gt;% \n  select(hhs_cat, fsl_hhs_cat) %&gt;% \n  table(useNA = \"ifany\")\n\n              fsl_hhs_cat\nhhs_cat        Little to No Moderate Severe\n  moderate                0       29      0\n  no_or_little           58        0      0\n  severe                  0        0     13\n\n\n\nHHS is fine. Labeling is different",
    "crumbs": [
      "Composition - Adding indicators",
      "03 - Practice (3)"
    ]
  },
  {
    "objectID": "03-composition/03-composition-03-practice.html#downloads",
    "href": "03-composition/03-composition-03-practice.html#downloads",
    "title": "03 - Practice (3)",
    "section": "",
    "text": "dataset_to_review",
    "crumbs": [
      "Composition - Adding indicators",
      "03 - Practice (3)"
    ]
  },
  {
    "objectID": "03-composition/03-composition-04-extra.html",
    "href": "03-composition/03-composition-04-extra.html",
    "title": "04 - impactR4PHU and humind",
    "section": "",
    "text": "impactR4PHU and humind\nThe functions about public health checks and indicators are more updated on the impactR4PHU. More information on this repository. The functions about the Multi Sector Needs Index are in humind. More information on this repository.",
    "crumbs": [
      "Composition - Adding indicators",
      "04 - impactR4PHU and humind"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-03-practice.html",
    "href": "07-outputs-part1/07-outputs-03-practice.html",
    "title": "03 - Practice (7)",
    "section": "",
    "text": "Add labels to the following results table.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(presentresults)\nlabel_exercise_results &lt;- readxl::read_excel(\"../inputs/11 - exercise - label.xlsx\", sheet = \"results_table\")\nlabel_exercise_kobo_survey &lt;- readxl::read_excel(\"../inputs/11 - exercise - label.xlsx\", sheet = \"kobo_survey\")\nlabel_exercise_kobo_choices &lt;- readxl::read_excel(\"../inputs/11 - exercise - label.xlsx\", sheet = \"kobo_choices\")\n\n\nhead(label_exercise_results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nprop_select_one\nfcs_cat\nlow\nlocation %/% population\nlocationA %/% displaced\n0.2580645\n0.1006681\n0.4154609\n8\n31\n8\n31\nprop_select_one @/@ fcs_cat %/% low @/@ location %/% locationA -/- population %/% displaced\n\n\nprop_select_one\nfcs_cat\nmedium\nlocation %/% population\nlocationA %/% displaced\n0.3225806\n0.1544312\n0.4907301\n10\n31\n10\n31\nprop_select_one @/@ fcs_cat %/% medium @/@ location %/% locationA -/- population %/% displaced\n\n\nprop_select_one\nfcs_cat\nhigh\nlocation %/% population\nlocationA %/% displaced\n0.4193548\n0.2418567\n0.5968530\n13\n31\n13\n31\nprop_select_one @/@ fcs_cat %/% high @/@ location %/% locationA -/- population %/% displaced\n\n\nprop_select_one\nfcs_cat\nlow\nlocation %/% population\nlocationA %/% non-displaced\n0.2500000\n0.0729795\n0.4270205\n6\n24\n6\n24\nprop_select_one @/@ fcs_cat %/% low @/@ location %/% locationA -/- population %/% non-displaced\n\n\nprop_select_one\nfcs_cat\nmedium\nlocation %/% population\nlocationA %/% non-displaced\n0.3750000\n0.1770851\n0.5729149\n9\n24\n9\n24\nprop_select_one @/@ fcs_cat %/% medium @/@ location %/% locationA -/- population %/% non-displaced\n\n\nprop_select_one\nfcs_cat\nhigh\nlocation %/% population\nlocationA %/% non-displaced\n0.3750000\n0.1770851\n0.5729149\n9\n24\n9\n24\nprop_select_one @/@ fcs_cat %/% high @/@ location %/% locationA -/- population %/% non-displaced\n\n\n\n\n\n\n\nhead(label_exercise_kobo_survey)\n\n\n\n\ntype\nname\nlabel\n\n\n\nselect_one fcs_cat\nfcs_cat\nFood Consumption Score\n\n\nselect_one lcs_cat\nlcs_cat\nLiving Coping Strategy Index\n\n\nselect_one location\nlocation\nLocation\n\n\nselect_one population\npopulation\nPopulation Group\n\n\n\n\n\n\n\nhead(label_exercise_kobo_choices)\n\n\n\n\nlist_name\nname\nlabel\n\n\n\nfcs_cat\nlow\nPoor\n\n\nfcs_cat\nmedium\nBorderline\n\n\nfcs_cat\nhigh\nAcceptable\n\n\nlcs_cat\nnone\nNone\n\n\nlcs_cat\nstress\nStress\n\n\nlcs_cat\nemergency\nEmergency\n\n\n\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument label_column in review_kobo_labels and create_label_dictionary ?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nreview_kobo_labels_results &lt;- review_kobo_labels(label_exercise_kobo_survey,\n                                                 label_exercise_kobo_choices,\n                                                 results_table = label_exercise_results, \n                                                 label_column = \"label\"\n)\n\nlabel_dictionary &lt;- create_label_dictionary(label_exercise_kobo_survey, \n                                            label_exercise_kobo_choices, \n                                            results_table = label_exercise_results, \n                                            label_column = \"label\")\n\nresults_table_labeled &lt;- add_label_columns_to_results_table(\n  label_exercise_results,\n  label_dictionary\n)\n\n\n\n\n\n\nCreate an excel table with the strata in the rows and the variables in the columns.\n\n\nlibrary(presentresults)\nlibrary(dplyr)\n\n\nexercise_outputs &lt;- readxl::read_excel(\"../inputs/10 - exercise - analysis_to_review.xlsx\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_outputs %&gt;% \n  create_table_group_x_variable() %&gt;% \n  create_xlsx_group_x_variable(file_path = \"../outputs/06 - correction - group_x_variable_table.xlsx\", overwrite = T) \n\n\n\n\n\n\n11 - exercise - analysis_to_review\n10 - exercise - analysis_to_review\n06 - correction - group_x_variable_table",
    "crumbs": [
      "Outputs - part 1",
      "03 - Practice (7)"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-03-practice.html#practice-1",
    "href": "07-outputs-part1/07-outputs-03-practice.html#practice-1",
    "title": "03 - Practice (7)",
    "section": "",
    "text": "Add labels to the following results table.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(presentresults)\nlabel_exercise_results &lt;- readxl::read_excel(\"../inputs/11 - exercise - label.xlsx\", sheet = \"results_table\")\nlabel_exercise_kobo_survey &lt;- readxl::read_excel(\"../inputs/11 - exercise - label.xlsx\", sheet = \"kobo_survey\")\nlabel_exercise_kobo_choices &lt;- readxl::read_excel(\"../inputs/11 - exercise - label.xlsx\", sheet = \"kobo_choices\")\n\n\nhead(label_exercise_results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nprop_select_one\nfcs_cat\nlow\nlocation %/% population\nlocationA %/% displaced\n0.2580645\n0.1006681\n0.4154609\n8\n31\n8\n31\nprop_select_one @/@ fcs_cat %/% low @/@ location %/% locationA -/- population %/% displaced\n\n\nprop_select_one\nfcs_cat\nmedium\nlocation %/% population\nlocationA %/% displaced\n0.3225806\n0.1544312\n0.4907301\n10\n31\n10\n31\nprop_select_one @/@ fcs_cat %/% medium @/@ location %/% locationA -/- population %/% displaced\n\n\nprop_select_one\nfcs_cat\nhigh\nlocation %/% population\nlocationA %/% displaced\n0.4193548\n0.2418567\n0.5968530\n13\n31\n13\n31\nprop_select_one @/@ fcs_cat %/% high @/@ location %/% locationA -/- population %/% displaced\n\n\nprop_select_one\nfcs_cat\nlow\nlocation %/% population\nlocationA %/% non-displaced\n0.2500000\n0.0729795\n0.4270205\n6\n24\n6\n24\nprop_select_one @/@ fcs_cat %/% low @/@ location %/% locationA -/- population %/% non-displaced\n\n\nprop_select_one\nfcs_cat\nmedium\nlocation %/% population\nlocationA %/% non-displaced\n0.3750000\n0.1770851\n0.5729149\n9\n24\n9\n24\nprop_select_one @/@ fcs_cat %/% medium @/@ location %/% locationA -/- population %/% non-displaced\n\n\nprop_select_one\nfcs_cat\nhigh\nlocation %/% population\nlocationA %/% non-displaced\n0.3750000\n0.1770851\n0.5729149\n9\n24\n9\n24\nprop_select_one @/@ fcs_cat %/% high @/@ location %/% locationA -/- population %/% non-displaced\n\n\n\n\n\n\n\nhead(label_exercise_kobo_survey)\n\n\n\n\ntype\nname\nlabel\n\n\n\nselect_one fcs_cat\nfcs_cat\nFood Consumption Score\n\n\nselect_one lcs_cat\nlcs_cat\nLiving Coping Strategy Index\n\n\nselect_one location\nlocation\nLocation\n\n\nselect_one population\npopulation\nPopulation Group\n\n\n\n\n\n\n\nhead(label_exercise_kobo_choices)\n\n\n\n\nlist_name\nname\nlabel\n\n\n\nfcs_cat\nlow\nPoor\n\n\nfcs_cat\nmedium\nBorderline\n\n\nfcs_cat\nhigh\nAcceptable\n\n\nlcs_cat\nnone\nNone\n\n\nlcs_cat\nstress\nStress\n\n\nlcs_cat\nemergency\nEmergency\n\n\n\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the argument label_column in review_kobo_labels and create_label_dictionary ?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nreview_kobo_labels_results &lt;- review_kobo_labels(label_exercise_kobo_survey,\n                                                 label_exercise_kobo_choices,\n                                                 results_table = label_exercise_results, \n                                                 label_column = \"label\"\n)\n\nlabel_dictionary &lt;- create_label_dictionary(label_exercise_kobo_survey, \n                                            label_exercise_kobo_choices, \n                                            results_table = label_exercise_results, \n                                            label_column = \"label\")\n\nresults_table_labeled &lt;- add_label_columns_to_results_table(\n  label_exercise_results,\n  label_dictionary\n)",
    "crumbs": [
      "Outputs - part 1",
      "03 - Practice (7)"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-03-practice.html#practice-2",
    "href": "07-outputs-part1/07-outputs-03-practice.html#practice-2",
    "title": "03 - Practice (7)",
    "section": "",
    "text": "Create an excel table with the strata in the rows and the variables in the columns.\n\n\nlibrary(presentresults)\nlibrary(dplyr)\n\n\nexercise_outputs &lt;- readxl::read_excel(\"../inputs/10 - exercise - analysis_to_review.xlsx\")\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_outputs %&gt;% \n  create_table_group_x_variable() %&gt;% \n  create_xlsx_group_x_variable(file_path = \"../outputs/06 - correction - group_x_variable_table.xlsx\", overwrite = T)",
    "crumbs": [
      "Outputs - part 1",
      "03 - Practice (7)"
    ]
  },
  {
    "objectID": "07-outputs-part1/07-outputs-03-practice.html#downloads",
    "href": "07-outputs-part1/07-outputs-03-practice.html#downloads",
    "title": "03 - Practice (7)",
    "section": "",
    "text": "11 - exercise - analysis_to_review\n10 - exercise - analysis_to_review\n06 - correction - group_x_variable_table",
    "crumbs": [
      "Outputs - part 1",
      "03 - Practice (7)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "01 - R framework with IMPACT Initiatives",
    "section": "",
    "text": "IMPACT R framework\n\nThe IMPACT R framework has been developed to meet the requirements of the IMPACT research cycle.  The ecosystem is a modular framework with two dimensions:\n\na horizontal dimension that focuses on the outcome of a given step, and\na vertical dimension that focuses on the content of a given step.\n\nThe framework is built around:\n\n4 steps:\n\nCleaning: any manipulation to go from the raw data to the clean data\nComposition: any manipulation before the analysis e.g. adding indicators, adding information from loop or main, aok aggregation, etc.\nAnalysis: any manipulation regarding only the analysis\nOutputs: any manipulation to format the outputs.\n\n4 verbs:\n\nAdd: functions that will add a variable (column) to the dataset.\nCheck: functions that will flag values based on a specific check. It will return them in a log. A check_* will return a list: the checked dataset, and the log. The function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nCreate: functions that will create, transform something, e.g. creating a cleaning log with the checks to be filled, create analysis results table, create an output. Outputs from create_* functions outputs can be in different shape, format, etc.\nReview: functions that will review an object by comparing it to standards or another object and flags differences, e.g. reviewing the cleaning by comparing the raw dataset, the clean dataset and the cleaning log, analysis comparing it with another analysis.\n\n2 adjectives:\n\nPipe-able: In the framework, functions of the same family should be pipe-able. In the following case, 2 check_* functions are piped.\nIndependent: At any given step, the user can change tool. Each input and each output of a step should follow the same format and definition.\n\n\nThese elements will help to improve cooperation and collaboration between different teams while allowing modularity to adapt to each context and assessment.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "04-analysis/04-analysis-01-create-analysis.html",
    "href": "04-analysis/04-analysis-01-create-analysis.html",
    "title": "01 - Simple analysis",
    "section": "",
    "text": "The framework is built around 4 steps: cleaning, composition, analysis, outputs\n\n\nCleaning: any manipulation to go from the raw data to the clean data\n\nComposition: any manipulation before the analysis e.g. adding indicators, adding information from loop or main, aok aggregation, etc.\n\nAnalysis: any manipulation regarding only the analysis\n\nOutputs: any manipulation to format the outputs.\n\nThe following section will present some introduction about the analysis.\n\nThe third step of the framework is the analysis. The analysis step aims to create a long table with one result per line and an analysis key. That table is not made for a human to read it but to store some information. Analysis stops at the results table: long format, stat + analysis key\nThe analysis key format is currently :\n\nanalysis type @/@ analysis variable %/% analysis variable value @/@ grouping variable %/% grouping variable value\nanalysis type @/@ dependent variable %/% dependent variable value @/@ independent variable %/% independent variable value\n\nIf there are two or more grouping variables it would look like that\n\nanalysis type @/@ analysis variable %/% analysis variable value @/@ grouping variable 1 %/% grouping variable value 1 -/- grouping variable 2 %/% grouping variable value 2\n\nSame would apply for analysis variable in case of a ratio.\nThe current analysis types are :\n\nmean\nmedian\nprop_select_one: proportion for select one\nprop_select_multiple: proportion for select multiple\nratio\n\n\nAny create_analysis_* function will need a survey to be used, not a dataset. A survey object will be defined with the weights, strata and cluster information if they exists.\n\n\n\n\n\n\ncreate_*\n\n\n\n\ncreate_* functions will create, transform something, e.g. creating a cleaning log with the checks to be filled, create analysis results table, create an output.\nOutputs from create_* functions outputs can be in different shape, format, etc.\ncreate_* function is catch-all.\n\n\n\nlibrary(analysistools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nmy_data &lt;- analysistools_MSNA_template_data\nonly_nas &lt;- analysistools_MSNA_template_data %&gt;%\n  summarise(across(.cols = everything(), .fns = function(x) {\n    sum(is.na(x)) == nrow(analysistools_MSNA_template_data)\n  })) %&gt;%\n  do.call(c, .)\n\nmy_data_shorter &lt;- analysistools_MSNA_template_data[, !only_nas] %&gt;%\n  select(!grep(\"other\", names(analysistools_MSNA_template_data), value = T))\n\n\n\n\n\n\n\n\nNote\n\n\n\nAt the moment, create_analysis breaks where a column only have missing values. They need to be removed beforehand.\n\n\nmy_design &lt;- srvyr::as_survey_design(my_data_shorter, strata = \"admin1\")\n\nmy_analysis &lt;- create_analysis(my_design, sm_separator = \"/\")\n\n\n\n\n\n\n\n\nNote\n\n\n\ncreate_analysis uses a survey design, not a dataset. Survey design object contains the information on the design of the survey, such as stratas, cluster, weights. It is built with srvyr package which is a wrapper around survey package.\n\ncreate_analysis returns a list with:\n\nResults table: a long table with summary statistics per line\nDataset: the dataset used with the survey design\nList of analysis: all the analysis that were performed\n\n\nmy_analysis %&gt;%\n  names()\n\n[1] \"results_table\" \"dataset\"       \"loa\"          \n\n\n\nmy_analysis$results_table %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nprop_select_one\nenum_gender\nfemale\nNA\nNA\n0.33\n0.2356238\n0.4243762\n33\n100\n33\n100\nprop_select_one @/@ enum_gender %/% female @/@ NA %/% NA\n\n\nprop_select_one\nenum_gender\nmale\nNA\nNA\n0.29\n0.1989592\n0.3810408\n29\n100\n29\n100\nprop_select_one @/@ enum_gender %/% male @/@ NA %/% NA\n\n\nprop_select_one\nenum_gender\nother\nNA\nNA\n0.38\n0.2829941\n0.4770059\n38\n100\n38\n100\nprop_select_one @/@ enum_gender %/% other @/@ NA %/% NA\n\n\nprop_select_one\nhoh\nno\nNA\nNA\n0.50\n0.3995960\n0.6004040\n50\n100\n50\n100\nprop_select_one @/@ hoh %/% no @/@ NA %/% NA\n\n\nprop_select_one\nhoh\nyes\nNA\nNA\n0.50\n0.3995960\n0.6004040\n50\n100\n50\n100\nprop_select_one @/@ hoh %/% yes @/@ NA %/% NA\n\n\nprop_select_one\nrespondent_able_to_answer\nno\nNA\nNA\n0.57\n0.4736852\n0.6663148\n57\n100\n57\n100\nprop_select_one @/@ respondent_able_to_answer %/% no @/@ NA %/% NA\n\n\n\n\n\n\n\nmy_analysis$loa %&gt;%\n  head()\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nlevel\n\n\n\nprop_select_one\nenum_gender\nNA\n0.95\n\n\nprop_select_one\nhoh\nNA\n0.95\n\n\nprop_select_one\nrespondent_able_to_answer\nNA\n0.95\n\n\nmean\nrespondent_age\nNA\n0.95\n\n\nmedian\nrespondent_age\nNA\n0.95\n\n\nprop_select_one\nrespondent_gender\nNA\n0.95",
    "crumbs": [
      "Analysis - Simple analysis",
      "01 - Simple analysis"
    ]
  },
  {
    "objectID": "04-analysis/04-analysis-01-create-analysis.html#create_analysis",
    "href": "04-analysis/04-analysis-01-create-analysis.html#create_analysis",
    "title": "01 - Simple analysis",
    "section": "",
    "text": "Any create_analysis_* function will need a survey to be used, not a dataset. A survey object will be defined with the weights, strata and cluster information if they exists.\n\n\n\n\n\n\ncreate_*\n\n\n\n\ncreate_* functions will create, transform something, e.g. creating a cleaning log with the checks to be filled, create analysis results table, create an output.\nOutputs from create_* functions outputs can be in different shape, format, etc.\ncreate_* function is catch-all.\n\n\n\nlibrary(analysistools)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nmy_data &lt;- analysistools_MSNA_template_data\nonly_nas &lt;- analysistools_MSNA_template_data %&gt;%\n  summarise(across(.cols = everything(), .fns = function(x) {\n    sum(is.na(x)) == nrow(analysistools_MSNA_template_data)\n  })) %&gt;%\n  do.call(c, .)\n\nmy_data_shorter &lt;- analysistools_MSNA_template_data[, !only_nas] %&gt;%\n  select(!grep(\"other\", names(analysistools_MSNA_template_data), value = T))\n\n\n\n\n\n\n\n\nNote\n\n\n\nAt the moment, create_analysis breaks where a column only have missing values. They need to be removed beforehand.\n\n\nmy_design &lt;- srvyr::as_survey_design(my_data_shorter, strata = \"admin1\")\n\nmy_analysis &lt;- create_analysis(my_design, sm_separator = \"/\")\n\n\n\n\n\n\n\n\nNote\n\n\n\ncreate_analysis uses a survey design, not a dataset. Survey design object contains the information on the design of the survey, such as stratas, cluster, weights. It is built with srvyr package which is a wrapper around survey package.\n\ncreate_analysis returns a list with:\n\nResults table: a long table with summary statistics per line\nDataset: the dataset used with the survey design\nList of analysis: all the analysis that were performed\n\n\nmy_analysis %&gt;%\n  names()\n\n[1] \"results_table\" \"dataset\"       \"loa\"          \n\n\n\nmy_analysis$results_table %&gt;%\n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanalysis_type\nanalysis_var\nanalysis_var_value\ngroup_var\ngroup_var_value\nstat\nstat_low\nstat_upp\nn\nn_total\nn_w\nn_w_total\nanalysis_key\n\n\n\nprop_select_one\nenum_gender\nfemale\nNA\nNA\n0.33\n0.2356238\n0.4243762\n33\n100\n33\n100\nprop_select_one @/@ enum_gender %/% female @/@ NA %/% NA\n\n\nprop_select_one\nenum_gender\nmale\nNA\nNA\n0.29\n0.1989592\n0.3810408\n29\n100\n29\n100\nprop_select_one @/@ enum_gender %/% male @/@ NA %/% NA\n\n\nprop_select_one\nenum_gender\nother\nNA\nNA\n0.38\n0.2829941\n0.4770059\n38\n100\n38\n100\nprop_select_one @/@ enum_gender %/% other @/@ NA %/% NA\n\n\nprop_select_one\nhoh\nno\nNA\nNA\n0.50\n0.3995960\n0.6004040\n50\n100\n50\n100\nprop_select_one @/@ hoh %/% no @/@ NA %/% NA\n\n\nprop_select_one\nhoh\nyes\nNA\nNA\n0.50\n0.3995960\n0.6004040\n50\n100\n50\n100\nprop_select_one @/@ hoh %/% yes @/@ NA %/% NA\n\n\nprop_select_one\nrespondent_able_to_answer\nno\nNA\nNA\n0.57\n0.4736852\n0.6663148\n57\n100\n57\n100\nprop_select_one @/@ respondent_able_to_answer %/% no @/@ NA %/% NA\n\n\n\n\n\n\n\nmy_analysis$loa %&gt;%\n  head()\n\n\n\n\nanalysis_type\nanalysis_var\ngroup_var\nlevel\n\n\n\nprop_select_one\nenum_gender\nNA\n0.95\n\n\nprop_select_one\nhoh\nNA\n0.95\n\n\nprop_select_one\nrespondent_able_to_answer\nNA\n0.95\n\n\nmean\nrespondent_age\nNA\n0.95\n\n\nmedian\nrespondent_age\nNA\n0.95\n\n\nprop_select_one\nrespondent_gender\nNA\n0.95",
    "crumbs": [
      "Analysis - Simple analysis",
      "01 - Simple analysis"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html",
    "href": "02-cleaning/02-cleaning-04-practice.html",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\n\n\n\nExport the cleaning log you have created previously. The previous log is loaded below.\n\n\nprevious_exercise_log &lt;- readRDS(\"../inputs/03 - exercise - previous_log.RDS\")\n\nprevious_exercise_log %&gt;% names()\n\n[1] \"checked_dataset\"        \"percentage_missing_log\" \"potential_PII\"         \n[4] \"logical_all\"           \n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_combined_log\n\n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_xlsx_cleaning_log\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nprevious_exercise_log %&gt;% \n  create_combined_log() %&gt;%\n  create_xlsx_cleaning_log(output_path = \"../outputs/03 - correction - cleaning_log.xlsx\", \n                           kobo_survey = my_kobo_survey,\n                           kobo_choices = my_kobo_choice,\n                           sm_dropdown_type = \"logical\",\n                           use_dropdown = TRUE)\n\n\n\n\n\n\nCreate the clean data from the raw dataset and the filled cleaning.\n\n\nexercise_filled_log &lt;- readxl::read_excel(\"../inputs/04 - exercise - cleaning_log - filled.xlsx\", sheet = \"cleaning_log\")\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function create_clean_data\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function recreate_parent_column\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_clean_dataset &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                            raw_data_uuid_column = \"X_uuid\",\n                                            cleaning_log = exercise_filled_log, \n                                            cleaning_log_uuid_column = \"uuid\",\n                                            cleaning_log_question_column = \"question\",\n                                            cleaning_log_new_value_column = \"new_value\",\n                                            cleaning_log_change_type_column = \"change_type\")\n\n\nexercise_clean_dataset2 &lt;- recreate_parent_column(exercise_clean_dataset,\n                                                  uuid_column = \"X_uuid\", \n                                                  kobo_survey = my_kobo_survey,\n                                                  kobo_choices = my_kobo_choice,\n                                                  cleaning_log_to_append = exercise_filled_log)\n\n\n\n\n\n\nReview the cleaning below, if there is someone else doing the exercise, you can try to review someone’s cleaning.\n\n\nexercise3_clean_dataset &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\")\n\nexercise3_cleaning_log &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\", sheet = 2)\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_cleaning\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you separate the cleaning log?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise3_deletion_log &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type == \"remove_survey\")\n\nexercise3_log_no_deletion &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type != \"remove_survey\") %&gt;% \n  filter(!uuid %in% exercise3_deletion_log$uuid)\n\nreview_of_cleaning &lt;- review_cleaning(raw_dataset = my_raw_dataset,\n                                      raw_dataset_uuid_column = \"X_uuid\", \n                                      clean_dataset = exercise3_clean_dataset,\n                                      clean_dataset_uuid_column = \"X_uuid\",\n                                      cleaning_log = exercise3_log_no_deletion, \n                                      cleaning_log_uuid_column = \"uuid\",\n                                      cleaning_log_question_column = \"question\",\n                                      cleaning_log_new_value_column = \"new_value\",\n                                      cleaning_log_change_type_column = \"change_type\", \n                                      cleaning_log_old_value_column = \"old_value\", \n                                      deletion_log = exercise3_deletion_log, \n                                      deletion_log_uuid_column = \"uuid\"\n)\n\n\n\n\n\n\n03 - exercise - previous_log\n03 - correction - cleaning_log.xlsx\n04 - exercise - cleaning_log - filled.xlsx\n05 - exercise - clean dataset for review",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#practice-1",
    "href": "02-cleaning/02-cleaning-04-practice.html#practice-1",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "Export the cleaning log you have created previously. The previous log is loaded below.\n\n\nprevious_exercise_log &lt;- readRDS(\"../inputs/03 - exercise - previous_log.RDS\")\n\nprevious_exercise_log %&gt;% names()\n\n[1] \"checked_dataset\"        \"percentage_missing_log\" \"potential_PII\"         \n[4] \"logical_all\"           \n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_combined_log\n\n\n\n\n\n\n\n\n\nExpand to get a hint.\n\n\n\n\n\nDid you try the function create_xlsx_cleaning_log\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nprevious_exercise_log %&gt;% \n  create_combined_log() %&gt;%\n  create_xlsx_cleaning_log(output_path = \"../outputs/03 - correction - cleaning_log.xlsx\", \n                           kobo_survey = my_kobo_survey,\n                           kobo_choices = my_kobo_choice,\n                           sm_dropdown_type = \"logical\",\n                           use_dropdown = TRUE)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#practice-2",
    "href": "02-cleaning/02-cleaning-04-practice.html#practice-2",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "Create the clean data from the raw dataset and the filled cleaning.\n\n\nexercise_filled_log &lt;- readxl::read_excel(\"../inputs/04 - exercise - cleaning_log - filled.xlsx\", sheet = \"cleaning_log\")\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function create_clean_data\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function recreate_parent_column\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise_clean_dataset &lt;- create_clean_data(raw_dataset = my_raw_dataset,\n                                            raw_data_uuid_column = \"X_uuid\",\n                                            cleaning_log = exercise_filled_log, \n                                            cleaning_log_uuid_column = \"uuid\",\n                                            cleaning_log_question_column = \"question\",\n                                            cleaning_log_new_value_column = \"new_value\",\n                                            cleaning_log_change_type_column = \"change_type\")\n\n\nexercise_clean_dataset2 &lt;- recreate_parent_column(exercise_clean_dataset,\n                                                  uuid_column = \"X_uuid\", \n                                                  kobo_survey = my_kobo_survey,\n                                                  kobo_choices = my_kobo_choice,\n                                                  cleaning_log_to_append = exercise_filled_log)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#practice-3",
    "href": "02-cleaning/02-cleaning-04-practice.html#practice-3",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "Review the cleaning below, if there is someone else doing the exercise, you can try to review someone’s cleaning.\n\n\nexercise3_clean_dataset &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\")\n\nexercise3_cleaning_log &lt;- readxl::read_excel(\"../inputs/05 - exercise - clean dataset for review.xlsx\", sheet = 2)\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you try the function review_cleaning\n\n\n\n\n\n\n\n\n\nExpand to get a hint\n\n\n\n\n\nDid you separate the cleaning log?\n\n\n\n\n\n\n\n\n\nExpand to get the answer\n\n\n\n\n\n\nexercise3_deletion_log &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type == \"remove_survey\")\n\nexercise3_log_no_deletion &lt;- exercise3_cleaning_log %&gt;% \n  filter(change_type != \"remove_survey\") %&gt;% \n  filter(!uuid %in% exercise3_deletion_log$uuid)\n\nreview_of_cleaning &lt;- review_cleaning(raw_dataset = my_raw_dataset,\n                                      raw_dataset_uuid_column = \"X_uuid\", \n                                      clean_dataset = exercise3_clean_dataset,\n                                      clean_dataset_uuid_column = \"X_uuid\",\n                                      cleaning_log = exercise3_log_no_deletion, \n                                      cleaning_log_uuid_column = \"uuid\",\n                                      cleaning_log_question_column = \"question\",\n                                      cleaning_log_new_value_column = \"new_value\",\n                                      cleaning_log_change_type_column = \"change_type\", \n                                      cleaning_log_old_value_column = \"old_value\", \n                                      deletion_log = exercise3_deletion_log, \n                                      deletion_log_uuid_column = \"uuid\"\n)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-04-practice.html#downloads",
    "href": "02-cleaning/02-cleaning-04-practice.html#downloads",
    "title": "04 - Practice (2)",
    "section": "",
    "text": "03 - exercise - previous_log\n03 - correction - cleaning_log.xlsx\n04 - exercise - cleaning_log - filled.xlsx\n05 - exercise - clean dataset for review",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "04 - Practice (2)"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html",
    "title": "01 - Create a cleaning log",
    "section": "",
    "text": "library(cleaningtools)\nlibrary(dplyr)\n\nmy_raw_dataset &lt;- cleaningtools::cleaningtools_raw_data\nmy_kobo_survey &lt;- cleaningtools::cleaningtools_survey\nmy_kobo_choice &lt;- cleaningtools::cleaningtools_choices\nThis section continues with the cleaning step.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_combined_log",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_combined_log",
    "title": "01 - Create a cleaning log",
    "section": "create_combined_log",
    "text": "create_combined_log\ncreate_combined_log will combined all the logs from a list into one. It will also add 2 columns that will be used for the cleaning.\n\nnames(more_logs)\n\n[1] \"checked_dataset\"    \"duplicate_log\"      \"soft_duplicate_log\"\n[4] \"potential_outliers\" \"flaged_value\"       \"duration_log\"      \n[7] \"other_log\"          \"logical_all\"       \n\nmy_combined_log &lt;- create_combined_log(more_logs)\n\nList of element to combine- checked_dataset, duplicate_log, soft_duplicate_log, potential_outliers, flaged_value, duration_log, other_log, logical_all\n\ntypeof(my_combined_log)\n\n[1] \"list\"\n\nnames(my_combined_log)\n\n[1] \"checked_dataset\" \"cleaning_log\"   \n\nmy_combined_log$cleaning_log %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nold_value\nquestion\nissue\ncheck_id\ncheck_binding\nchange_type\nnew_value\n\n\n\nb5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\n86\nage_respondent_r\noutlier (normal distribution)\nNA\nage_respondent_r / b5b1d37a-e27a-4c35-a0f5-2cde9d6dfd06\nNA\nNA\n\n\n956b5ed0-5a62-41b7-aec3-af93fbc5b494\n84\nage_respondent_r\noutlier (normal distribution)\nNA\nage_respondent_r / 956b5ed0-5a62-41b7-aec3-af93fbc5b494\nNA\nNA\n\n\n97ad6294-30c6-454e-a0b3-42126415b767\n18\nage_respondent_r\noutlier (log distribution)\nNA\nage_respondent_r / 97ad6294-30c6-454e-a0b3-42126415b767\nNA\nNA\n\n\ne005e719-57c4-44a3-ac2f-5d6d1ff68831\n18\nage_respondent_r\noutlier (log distribution)\nNA\nage_respondent_r / e005e719-57c4-44a3-ac2f-5d6d1ff68831\nNA\nNA\n\n\nc9aaa542-118f-4e42-93de-fb0916572541\n19\nnum_hh_member\noutlier (normal distribution)\nNA\nnum_hh_member / c9aaa542-118f-4e42-93de-fb0916572541\nNA\nNA\n\n\n48e8896b-d1be-4600-8839-2d8b994ebcfb\n19\nnum_hh_member\noutlier (normal distribution)\nNA\nnum_hh_member / 48e8896b-d1be-4600-8839-2d8b994ebcfb\nNA\nNA\n\n\n\n\n\n\nThe cleaning log contains all the columns from all the logs from more_logs with in addition:\n\ncheck_binding is filled for all rows.\nchange_type (empty)\nnew_value (empty)",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#add_info_to_cleaning_log",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#add_info_to_cleaning_log",
    "title": "01 - Create a cleaning log",
    "section": "add_info_to_cleaning_log",
    "text": "add_info_to_cleaning_log\nIf more information from the dataset should be added, the function add_info_to_cleaning_log can help.\n\n\n\n\n\n\nadd_*\n\n\n\n\nadd_* functions will add a variable (column) to the dataset. For example, to add the duration of a survey, to add the food consumption score category, etc.\nadd_* function takes a dataset as input and returns the dataset + the new indicator (and any intermediate steps used for the calculation).\nFor example, to check the duration of a survey, there is only the start and end, but not the duration column.\n\n\n\nmy_combined_log &lt;- my_combined_log %&gt;% \n  add_info_to_cleaning_log(dataset_uuid_column = \"X_uuid\", \n                           information_to_add = \"enumerator_num\")\n\nmy_combined_log$cleaning_log %&gt;% \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuuid\nold_value\nquestion\nissue\ncheck_id\ncheck_binding\nchange_type\nnew_value\nenumerator_num\n\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nلا اعلم\nwater_supply_other_neighbourhoods_why\nrecode other\nNA\nwater_supply_other_neighbourhoods_why / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nلا ارى جدوى من ذلك\nprefer_not_engage_other\nrecode other\nNA\nprefer_not_engage_other / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\nالسلطات ليست مهتمة بالخدمات\ntrust_water_office_why_not\nrecode other\nNA\ntrust_water_office_why_not / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n019bc718-c06a-46b8-bba8-c84f6c6efbd5\n247.20\nduration\nDuration is lower or higher than the thresholds\nNA\nduration / 019bc718-c06a-46b8-bba8-c84f6c6efbd5\nNA\nNA\n12\n\n\n03183d24-0275-43fe-8976-d076f29de590\nعدم توفير خدمه المياه في المنطقه وضعف في تزويد خدمه وعدد ساعات اقل تجهيز للبيوت\nwater_supply_other_neighbourhoods_why\nrecode other\nNA\nwater_supply_other_neighbourhoods_why / 03183d24-0275-43fe-8976-d076f29de590\nNA\nNA\n2\n\n\n03183d24-0275-43fe-8976-d076f29de590\n10\npay_water_charges_amount\noutlier (log distribution)\nNA\npay_water_charges_amount / 03183d24-0275-43fe-8976-d076f29de590\nNA\nNA\n2",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_xlsx_cleaning_log",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#create_xlsx_cleaning_log",
    "title": "01 - Create a cleaning log",
    "section": "create_xlsx_cleaning_log",
    "text": "create_xlsx_cleaning_log\n\ncreate_xlsx_cleaning_log(my_combined_log,\n                         sm_dropdown_type = \"logical\",\n                         output_path =  \"../outputs/01 - example - cleaning-log-no-kobo.xlsx\")\n\ncreate_xlsx_cleaning_log will write an excel file with:\n\nchecked_dataset tab: the checked dataset, with additional columns if any.\ncleaning_log tab: the combined log with the change_type column with a data validation rules.\nreadme tab: change_type values definition.\n\nThere are 4 actions possible:\n\nchange_response: Change the response to new.value\nblank_response: Remove and NA the response\nremove_survey: Delete the survey\nno_action: No action to take.\n\nThis log will have to be filled in with actions to take and new value if needed.\n\ncreate_xlsx_cleaning_log(my_combined_log,\n                         kobo_survey = my_kobo_survey,\n                         kobo_choices = my_kobo_choice,\n                         use_dropdown = T,\n                         sm_dropdown_type = \"logical\",\n                         output_path =  \"../outputs/02 - example - cleaning-log-with-kobo.xlsx\")\n\nIf the KOBO information are provided and the use_dropdown argument is set to TRUE, new_value will have a data validation rule based on the KOBO options.\n\n\n\n\n\n\nNote\n\n\n\nSelect multiple dummy columns (TRUE/FALSE or 1/0) are flagged and used later for the cleaning, not the parent column.",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  },
  {
    "objectID": "02-cleaning/02-cleaning-01-create-cleaning-log.html#downloads",
    "href": "02-cleaning/02-cleaning-01-create-cleaning-log.html#downloads",
    "title": "01 - Create a cleaning log",
    "section": "Downloads",
    "text": "Downloads\n\n01 - example - check_list\n01 - example - cleaning-log-no-kobo.xlsx\n02 - example - cleaning-log-with-kobo.xlsx",
    "crumbs": [
      "Cleaning - Creating a clean dataset",
      "01 - Create a cleaning log"
    ]
  }
]